#!/usr/bin/env python3
"""
æ£€æŸ¥æ–‡æ¡£ä¸­çš„è¶…é“¾æ¥æ˜¯å¦æœ‰æ•ˆ
"""
import os
import re
from pathlib import Path
from collections import defaultdict

def find_markdown_files(root_dir):
    """æŸ¥æ‰¾æ‰€æœ‰ markdown æ–‡ä»¶"""
    md_files = []
    for root, dirs, files in os.walk(root_dir):
        # è·³è¿‡éšè—ç›®å½•å’ŒæŸäº›ç›®å½•
        dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'node_modules']]

        for file in files:
            if file.endswith('.md'):
                md_files.append(os.path.join(root, file))
    return md_files

def extract_links(content, file_path):
    """ä»æ–‡æ¡£å†…å®¹ä¸­æå–æ‰€æœ‰é“¾æ¥"""
    links = []

    # Markdown é“¾æ¥æ ¼å¼: [text](url)
    markdown_links = re.findall(r'\[([^\]]+)\]\(([^\)]+)\)', content)
    for text, url in markdown_links:
        links.append({
            'text': text,
            'url': url,
            'type': 'markdown',
            'file': file_path
        })

    # HTML é“¾æ¥æ ¼å¼: <a href="url">
    html_links = re.findall(r'<a\s+href=["\']([^"\']+)["\']', content)
    for url in html_links:
        links.append({
            'text': '',
            'url': url,
            'type': 'html',
            'file': file_path
        })

    return links

def classify_link(url):
    """åˆ†ç±»é“¾æ¥ç±»å‹"""
    if url.startswith('http://') or url.startswith('https://'):
        return 'external'
    elif url.startswith('#'):
        return 'anchor'
    elif url.startswith('mailto:'):
        return 'email'
    else:
        return 'internal'

def check_internal_link(link_url, source_file, root_dir):
    """æ£€æŸ¥å†…éƒ¨é“¾æ¥æ˜¯å¦æœ‰æ•ˆ"""
    # ç§»é™¤é”šç‚¹éƒ¨åˆ†
    if '#' in link_url:
        file_part, anchor = link_url.split('#', 1)
    else:
        file_part = link_url
        anchor = None

    # ç©ºé“¾æ¥ï¼ˆçº¯é”šç‚¹ï¼‰
    if not file_part:
        return True, None

    # è®¡ç®—ç»å¯¹è·¯å¾„
    source_dir = os.path.dirname(source_file)
    target_path = os.path.normpath(os.path.join(source_dir, file_part))

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if os.path.exists(target_path):
        return True, None
    else:
        return False, f"æ–‡ä»¶ä¸å­˜åœ¨: {target_path}"

def check_anchor_in_file(file_path, anchor):
    """æ£€æŸ¥æ–‡ä»¶ä¸­æ˜¯å¦å­˜åœ¨æŒ‡å®šçš„é”šç‚¹"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æŸ¥æ‰¾æ ‡é¢˜ï¼ˆ# å¼€å¤´çš„è¡Œï¼‰
        headings = re.findall(r'^#+\s+(.+)$', content, re.MULTILINE)

        # å°†æ ‡é¢˜è½¬æ¢ä¸ºé”šç‚¹æ ¼å¼ï¼ˆå°å†™ï¼Œç©ºæ ¼è½¬è¿å­—ç¬¦ï¼‰
        anchors = []
        for heading in headings:
            # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œè½¬å°å†™ï¼Œç©ºæ ¼è½¬è¿å­—ç¬¦
            anchor_text = re.sub(r'[^\w\s-]', '', heading.lower())
            anchor_text = re.sub(r'[\s]+', '-', anchor_text)
            anchors.append(anchor_text)

        # GitHub é£æ ¼çš„é”šç‚¹ï¼ˆç§»é™¤ä¸­æ–‡åçš„å¤„ç†ï¼‰
        anchor_normalized = re.sub(r'[^\w\s-]', '', anchor.lower())
        anchor_normalized = re.sub(r'[\s]+', '-', anchor_normalized)

        return anchor_normalized in anchors
    except Exception as e:
        return False

def main():
    root_dir = '/home/user/APT-Transformer'

    print("ğŸ” å¼€å§‹æ£€æŸ¥æ–‡æ¡£é“¾æ¥...\n")

    # æŸ¥æ‰¾æ‰€æœ‰ markdown æ–‡ä»¶
    md_files = find_markdown_files(root_dir)
    print(f"ğŸ“„ æ‰¾åˆ° {len(md_files)} ä¸ª Markdown æ–‡ä»¶\n")

    # ç»Ÿè®¡ä¿¡æ¯
    total_links = 0
    broken_links = []
    link_types = defaultdict(int)

    # æ£€æŸ¥æ¯ä¸ªæ–‡ä»¶
    for md_file in md_files:
        try:
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶: {md_file} - {e}")
            continue

        # æå–é“¾æ¥
        links = extract_links(content, md_file)
        total_links += len(links)

        # æ£€æŸ¥æ¯ä¸ªé“¾æ¥
        for link in links:
            url = link['url']
            link_type = classify_link(url)
            link_types[link_type] += 1

            # åªæ£€æŸ¥å†…éƒ¨é“¾æ¥
            if link_type == 'internal':
                is_valid, error = check_internal_link(url, md_file, root_dir)
                if not is_valid:
                    rel_path = os.path.relpath(md_file, root_dir)
                    broken_links.append({
                        'file': rel_path,
                        'text': link['text'],
                        'url': url,
                        'error': error
                    })

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "="*80)
    print("ğŸ“Š æ£€æŸ¥ç»“æœç»Ÿè®¡")
    print("="*80)
    print(f"\næ€»é“¾æ¥æ•°: {total_links}")
    print(f"  - å¤–éƒ¨é“¾æ¥: {link_types['external']}")
    print(f"  - å†…éƒ¨é“¾æ¥: {link_types['internal']}")
    print(f"  - é”šç‚¹é“¾æ¥: {link_types['anchor']}")
    print(f"  - é‚®ä»¶é“¾æ¥: {link_types['email']}")

    # æ‰“å°å¤±æ•ˆé“¾æ¥
    if broken_links:
        print(f"\nâŒ å‘ç° {len(broken_links)} ä¸ªå¤±æ•ˆé“¾æ¥:\n")

        # æŒ‰æ–‡ä»¶åˆ†ç»„
        links_by_file = defaultdict(list)
        for link in broken_links:
            links_by_file[link['file']].append(link)

        for file, links in sorted(links_by_file.items()):
            print(f"\nğŸ“„ {file}")
            for link in links:
                print(f"  âŒ [{link['text']}]({link['url']})")
                print(f"     {link['error']}")
    else:
        print("\nâœ… æ‰€æœ‰å†…éƒ¨é“¾æ¥éƒ½æœ‰æ•ˆï¼")

    # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶
    report_path = os.path.join(root_dir, 'LINK_CHECK_REPORT.md')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# æ–‡æ¡£é“¾æ¥æ£€æŸ¥æŠ¥å‘Š\n\n")
        f.write(f"**æ£€æŸ¥æ—¶é—´**: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("## ç»Ÿè®¡ä¿¡æ¯\n\n")
        f.write(f"- æ£€æŸ¥æ–‡ä»¶æ•°: {len(md_files)}\n")
        f.write(f"- æ€»é“¾æ¥æ•°: {total_links}\n")
        f.write(f"  - å¤–éƒ¨é“¾æ¥: {link_types['external']}\n")
        f.write(f"  - å†…éƒ¨é“¾æ¥: {link_types['internal']}\n")
        f.write(f"  - é”šç‚¹é“¾æ¥: {link_types['anchor']}\n")
        f.write(f"  - é‚®ä»¶é“¾æ¥: {link_types['email']}\n")
        f.write(f"- å¤±æ•ˆé“¾æ¥æ•°: {len(broken_links)}\n\n")

        if broken_links:
            f.write("## å¤±æ•ˆé“¾æ¥è¯¦æƒ…\n\n")
            links_by_file = defaultdict(list)
            for link in broken_links:
                links_by_file[link['file']].append(link)

            for file, links in sorted(links_by_file.items()):
                f.write(f"### {file}\n\n")
                for link in links:
                    f.write(f"- âŒ `[{link['text']}]({link['url']})`\n")
                    f.write(f"  - é”™è¯¯: {link['error']}\n\n")
        else:
            f.write("## âœ… æ‰€æœ‰å†…éƒ¨é“¾æ¥éƒ½æœ‰æ•ˆï¼\n\n")

    print(f"\nğŸ“ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: LINK_CHECK_REPORT.md")
    print("="*80)

    return len(broken_links)

if __name__ == '__main__':
    exit_code = main()
    exit(0 if exit_code == 0 else 1)
