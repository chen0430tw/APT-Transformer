# APT-Transformer Performance Profile
# 性能优化版本 - 适合生产训练、快速推理

name: apt-perf
version: 1.0.0
description: "性能优化版本 - 生产环境首选"

# ═══════════════════════════════════════════════════════════
# 继承核心配置
# ═══════════════════════════════════════════════════════════
extends: core.yaml

# ═══════════════════════════════════════════════════════════
# 启用层级
# ═══════════════════════════════════════════════════════════
layers:
  - L0  # 核心层
  - L1  # 性能层

# ═══════════════════════════════════════════════════════════
# 性能层配置（关键）
# ═══════════════════════════════════════════════════════════
performance:
  enabled: true

  # ═════════════════════════════════════════════════════════
  # 虚拟 Blackwell
  # ═════════════════════════════════════════════════════════
  virtual_blackwell:
    enabled: true
    mode: balanced  # performance / balanced / memory

    # GPU Flash 优化
    gpu_flash:
      enabled: true

      # MXFP4 量化
      mxfp4:
        enabled: true
        inference_only: true  # 只在推理时量化
        block_size: 32

      # Triton Kernel 融合
      kernel_fusion:
        enabled: true
        fuse_linear: true
        fuse_layernorm: true

      # Flash Attention
      flash_attention:
        enabled: true
        block_size_m: 128
        block_size_n: 64

    # VGPU Stack（虚拟显存堆叠）
    vgpu_stack:
      enabled: true

      # 自动配置（根据硬件）
      auto_config: true

      # 手动配置（可选）
      levels:
        - name: Level 0
          capacity_mb: 2000
          device: cuda:0
          speed_gbps: 900  # NVLink

        - name: Level 1
          capacity_mb: 8000
          device: cpu
          speed_gbps: 50   # PCIe 4.0

        - name: Level 2
          capacity_mb: 32000
          device: ssd
          speed_gbps: 7    # NVMe

      # LRU 缓存策略
      cache_policy: lru
      auto_promote: true  # 自动提升热数据
      prefetch: true      # 预取

    # MoE 优化
    moe_optimized:
      enabled: false  # 按需启用
      num_experts: 8
      expert_capacity: 1.25
      load_balancing_loss_weight: 0.01

  # ═════════════════════════════════════════════════════════
  # 混合精度训练
  # ═════════════════════════════════════════════════════════
  mixed_precision:
    enabled: true
    dtype: auto  # auto / fp16 / bf16
    loss_scale: dynamic
    loss_scale_window: 1000

  # ═════════════════════════════════════════════════════════
  # 分布式训练
  # ═════════════════════════════════════════════════════════
  distributed:
    enabled: false  # 按需启用
    backend: nccl   # nccl / gloo
    init_method: env://
    find_unused_parameters: false

    # 数据并行
    data_parallel:
      enabled: true
      world_size: 1  # 自动检测

    # 张量并行（大模型）
    tensor_parallel:
      enabled: false
      tp_size: 1

    # 流水线并行（超大模型）
    pipeline_parallel:
      enabled: false
      pp_size: 1

  # ═════════════════════════════════════════════════════════
  # Checkpoint 优化
  # ═════════════════════════════════════════════════════════
  checkpoint:
    # 原子性保存（防止训练中断损坏）
    atomic_save: true

    # 保存策略
    save_interval: 1000
    keep_last_n: 3
    save_optimizer_states: true

    # 异步保存
    async_save: true

  # ═════════════════════════════════════════════════════════
  # 梯度优化
  # ═════════════════════════════════════════════════════════
  gradient:
    # 梯度累积
    accumulation_steps: 4

    # 梯度检查点（节省显存）
    checkpointing: false

    # 梯度压缩（分布式）
    compression:
      enabled: false
      type: fp16  # fp16 / powersgd

# ═══════════════════════════════════════════════════════════
# 训练配置（优化版）
# ═══════════════════════════════════════════════════════════
training:
  # 继承 core.yaml，并覆盖
  batch_size: 64  # 更大批次
  gradient_accumulation_steps: 4
  max_steps: 200000

  # 编译优化（PyTorch 2.0+）
  compile:
    enabled: true
    mode: default  # default / reduce-overhead / max-autotune

# ═══════════════════════════════════════════════════════════
# 输出配置
# ═══════════════════════════════════════════════════════════
output:
  checkpoint_dir: ./checkpoints/perf
  log_dir: ./logs/perf
  tensorboard: true  # 启用 TensorBoard

# ═══════════════════════════════════════════════════════════
# 适用场景
# ═══════════════════════════════════════════════════════════
# - 生产训练：需要快速迭代
# - 大规模推理：低延迟要求
# - 显存受限：GPU 显存不足
# - 分布式训练：多 GPU / 多节点
# - 成本优化：用消费级 GPU 训练大模型
