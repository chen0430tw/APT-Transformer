#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è™šæ‹ŸBlackwell GPUæ€§èƒ½æµ‹è¯•è„šæœ¬
Virtual Blackwell GPU Benchmark Tool

åŠŸèƒ½ï¼š
- è‡ªåŠ¨æ£€æµ‹ç¡¬ä»¶é…ç½®ï¼ˆGPUã€CPUã€å†…å­˜ã€SSDï¼‰
- æµ‹è¯•ä¸åŒè§„æ¨¡æ¨¡å‹çš„æ”¯æŒèƒ½åŠ›
- è¯„ä¼°è™šæ‹ŸGPUå †å æ€§èƒ½
- ç”Ÿæˆè¯¦ç»†æµ‹è¯•æŠ¥å‘Š

ç”¨æ³•ï¼š
    python examples/benchmarks/vblackwell_benchmark.py
    python examples/benchmarks/vblackwell_benchmark.py --quick
    python examples/benchmarks/vblackwell_benchmark.py --detailed
"""

import os
import sys
import time
import json
import argparse
from datetime import datetime
from typing import Dict, List, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

print("=" * 80)
print("ğŸ® è™šæ‹ŸBlackwell GPUæ€§èƒ½æµ‹è¯•å·¥å…·")
print("=" * 80)
print()


class HardwareDetector:
    """ç¡¬ä»¶æ£€æµ‹å™¨"""

    def __init__(self):
        self.info = {
            'gpu': [],
            'cpu': {},
            'memory': {},
            'storage': {}
        }

    def detect_all(self) -> Dict:
        """æ£€æµ‹æ‰€æœ‰ç¡¬ä»¶"""
        print("ğŸ” æ£€æµ‹ç¡¬ä»¶é…ç½®...")
        print()

        self._detect_gpu()
        self._detect_cpu()
        self._detect_memory()
        self._detect_storage()

        return self.info

    def _detect_gpu(self):
        """æ£€æµ‹GPU"""
        print("ğŸ“Š GPUæ£€æµ‹:")

        # å°è¯•æ£€æµ‹CUDA GPU
        try:
            import torch
            if torch.cuda.is_available():
                gpu_count = torch.cuda.device_count()
                print(f"  âœ“ æ£€æµ‹åˆ° {gpu_count} å¼  NVIDIA GPU")

                for i in range(gpu_count):
                    props = torch.cuda.get_device_properties(i)
                    gpu_info = {
                        'id': i,
                        'name': props.name,
                        'total_memory_gb': props.total_memory / (1024**3),
                        'compute_capability': f"{props.major}.{props.minor}",
                        'type': 'cuda'
                    }
                    self.info['gpu'].append(gpu_info)
                    print(f"    GPU {i}: {props.name}")
                    print(f"      - æ˜¾å­˜: {gpu_info['total_memory_gb']:.1f} GB")
                    print(f"      - ç®—åŠ›: {gpu_info['compute_capability']}")
            else:
                print("  âš ï¸  æœªæ£€æµ‹åˆ°CUDA GPU")
        except ImportError:
            print("  âš ï¸  PyTorchæœªå®‰è£…ï¼Œè·³è¿‡CUDAæ£€æµ‹")

        # å°è¯•æ£€æµ‹NPUï¼ˆåä¸ºæ˜‡è…¾ï¼‰
        try:
            import torch_npu
            if torch_npu.npu.is_available():
                npu_count = torch_npu.npu.device_count()
                print(f"  âœ“ æ£€æµ‹åˆ° {npu_count} å¼ åä¸ºæ˜‡è…¾NPU")
                for i in range(npu_count):
                    self.info['gpu'].append({
                        'id': i,
                        'name': 'Huawei Ascend NPU',
                        'type': 'npu'
                    })
        except ImportError:
            pass

        # å¦‚æœæ²¡æœ‰GPU
        if not self.info['gpu']:
            print("  â„¹ï¸  CPU-onlyæ¨¡å¼")
            self.info['gpu'].append({
                'id': 0,
                'name': 'CPU Only',
                'type': 'cpu'
            })

        print()

    def _detect_cpu(self):
        """æ£€æµ‹CPU"""
        print("ğŸ–¥ï¸  CPUæ£€æµ‹:")

        import platform
        import multiprocessing

        self.info['cpu'] = {
            'model': platform.processor() or 'Unknown',
            'cores': multiprocessing.cpu_count(),
            'architecture': platform.machine()
        }

        print(f"  CPUå‹å·: {self.info['cpu']['model']}")
        print(f"  æ ¸å¿ƒæ•°: {self.info['cpu']['cores']}")
        print(f"  æ¶æ„: {self.info['cpu']['architecture']}")
        print()

    def _detect_memory(self):
        """æ£€æµ‹å†…å­˜"""
        print("ğŸ’¾ å†…å­˜æ£€æµ‹:")

        try:
            import psutil
            mem = psutil.virtual_memory()
            self.info['memory'] = {
                'total_gb': mem.total / (1024**3),
                'available_gb': mem.available / (1024**3),
                'used_percent': mem.percent
            }
            print(f"  æ€»å†…å­˜: {self.info['memory']['total_gb']:.1f} GB")
            print(f"  å¯ç”¨å†…å­˜: {self.info['memory']['available_gb']:.1f} GB")
            print(f"  ä½¿ç”¨ç‡: {self.info['memory']['used_percent']:.1f}%")
        except ImportError:
            print("  âš ï¸  psutilæœªå®‰è£…ï¼Œä½¿ç”¨ä¼°ç®—å€¼")
            self.info['memory'] = {
                'total_gb': 16.0,  # é»˜è®¤ä¼°ç®—
                'available_gb': 8.0,
                'used_percent': 50.0
            }
            print("  æ€»å†…å­˜: ~16 GB (ä¼°ç®—)")

        print()

    def _detect_storage(self):
        """æ£€æµ‹å­˜å‚¨"""
        print("ğŸ’¿ å­˜å‚¨æ£€æµ‹:")

        try:
            import psutil
            disk = psutil.disk_usage('/')
            self.info['storage'] = {
                'total_gb': disk.total / (1024**3),
                'free_gb': disk.free / (1024**3),
                'used_percent': disk.percent
            }
            print(f"  æ€»å®¹é‡: {self.info['storage']['total_gb']:.1f} GB")
            print(f"  å¯ç”¨ç©ºé—´: {self.info['storage']['free_gb']:.1f} GB")
            print(f"  ä½¿ç”¨ç‡: {self.info['storage']['used_percent']:.1f}%")
        except ImportError:
            print("  âš ï¸  psutilæœªå®‰è£…ï¼Œè·³è¿‡å­˜å‚¨æ£€æµ‹")
            self.info['storage'] = {
                'total_gb': 500.0,
                'free_gb': 250.0,
                'used_percent': 50.0
            }

        print()


class VirtualBlackwellBenchmark:
    """è™šæ‹ŸBlackwellæ€§èƒ½æµ‹è¯•"""

    def __init__(self, hardware_info: Dict):
        self.hardware_info = hardware_info
        self.results = []

    def run_tests(self, test_mode: str = 'standard'):
        """è¿è¡Œæµ‹è¯•"""
        print("=" * 80)
        print("ğŸ§ª å¼€å§‹è™šæ‹ŸBlackwellæ€§èƒ½æµ‹è¯•")
        print("=" * 80)
        print()

        if test_mode == 'quick':
            test_configs = self._get_quick_tests()
        elif test_mode == 'detailed':
            test_configs = self._get_detailed_tests()
        else:
            test_configs = self._get_standard_tests()

        for i, config in enumerate(test_configs, 1):
            print(f"[æµ‹è¯• {i}/{len(test_configs)}] {config['name']}")
            result = self._run_single_test(config)
            self.results.append(result)
            print()

        return self.results

    def _get_quick_tests(self) -> List[Dict]:
        """å¿«é€Ÿæµ‹è¯•é…ç½®"""
        return [
            {'name': 'å°å‹æ¨¡å‹ (7B)', 'model_size_gb': 14, 'num_gpus': 1},
            {'name': 'ä¸­å‹æ¨¡å‹ (13B)', 'model_size_gb': 26, 'num_gpus': 1},
        ]

    def _get_standard_tests(self) -> List[Dict]:
        """æ ‡å‡†æµ‹è¯•é…ç½®"""
        return [
            {'name': 'å°å‹æ¨¡å‹ (7B, FP16)', 'model_size_gb': 14, 'num_gpus': 1},
            {'name': 'å°å‹æ¨¡å‹ (7B, MXFP4)', 'model_size_gb': 3.5, 'num_gpus': 1},
            {'name': 'ä¸­å‹æ¨¡å‹ (13B, FP16)', 'model_size_gb': 26, 'num_gpus': 1},
            {'name': 'å¤§å‹æ¨¡å‹ (70B, FP16)', 'model_size_gb': 140, 'num_gpus': 1},
            {'name': 'å¤§å‹æ¨¡å‹ (70B, MXFP4)', 'model_size_gb': 35, 'num_gpus': 1},
        ]

    def _get_detailed_tests(self) -> List[Dict]:
        """è¯¦ç»†æµ‹è¯•é…ç½®"""
        return [
            {'name': 'å°å‹æ¨¡å‹ (7B, FP16)', 'model_size_gb': 14, 'num_gpus': 1},
            {'name': 'å°å‹æ¨¡å‹ (7B, MXFP4)', 'model_size_gb': 3.5, 'num_gpus': 1},
            {'name': 'ä¸­å‹æ¨¡å‹ (13B, FP16)', 'model_size_gb': 26, 'num_gpus': 1},
            {'name': 'ä¸­å‹æ¨¡å‹ (13B, MXFP4)', 'model_size_gb': 6.5, 'num_gpus': 1},
            {'name': 'å¤§å‹æ¨¡å‹ (70B, FP16)', 'model_size_gb': 140, 'num_gpus': 1},
            {'name': 'å¤§å‹æ¨¡å‹ (70B, MXFP4)', 'model_size_gb': 35, 'num_gpus': 1},
            {'name': 'è¶…å¤§æ¨¡å‹ (175B, FP16)', 'model_size_gb': 350, 'num_gpus': 4},
            {'name': 'è¶…å¤§æ¨¡å‹ (405B, MXFP4)', 'model_size_gb': 101, 'num_gpus': 4},
        ]

    def _run_single_test(self, config: Dict) -> Dict:
        """è¿è¡Œå•ä¸ªæµ‹è¯•"""
        model_size = config['model_size_gb']
        num_gpus = config['num_gpus']

        # è®¡ç®—è™šæ‹ŸBlackwellé…ç½®
        vb_config = self._calculate_vb_usage(model_size, num_gpus)

        # æ£€æŸ¥æ˜¯å¦å¯è¡Œ
        feasibility = self._check_feasibility(vb_config, num_gpus)

        # ä¼°ç®—æ€§èƒ½
        performance = self._estimate_performance(vb_config, feasibility)

        result = {
            'config': config,
            'vb_config': vb_config,
            'feasibility': feasibility,
            'performance': performance
        }

        self._print_result(result)

        return result

    def _calculate_vb_usage(self, model_size_gb: float, num_gpus: int) -> Dict:
        """è®¡ç®—è™šæ‹ŸBlackwellä½¿ç”¨é‡"""
        # é»˜è®¤å•GPUé…ç½®
        gpu_cache_gb = 2.0
        cpu_cache_gb = 8.0
        ssd_cache_gb = 32.0

        # å¦‚æœæœ‰å®é™…GPUï¼Œè°ƒæ•´GPUç¼“å­˜å¤§å°
        if self.hardware_info['gpu'] and self.hardware_info['gpu'][0]['type'] == 'cuda':
            actual_gpu_mem = self.hardware_info['gpu'][0].get('total_memory_gb', 2.0)
            gpu_cache_gb = min(actual_gpu_mem * 0.8, model_size_gb)  # ä½¿ç”¨80%æ˜¾å­˜

        # åˆ†é…åˆ°å„å±‚çº§
        per_gpu_size = model_size_gb / num_gpus
        remaining = per_gpu_size

        gpu_actual = min(remaining, gpu_cache_gb)
        remaining -= gpu_actual

        cpu_actual = min(remaining, cpu_cache_gb)
        remaining -= cpu_actual

        ssd_actual = min(remaining, ssd_cache_gb)
        remaining -= ssd_actual

        return {
            'gpu_gb': gpu_actual * num_gpus,
            'cpu_gb': cpu_actual * num_gpus,
            'ssd_gb': ssd_actual * num_gpus,
            'overflow_gb': remaining * num_gpus,
            'total_gb': model_size_gb,
            'num_gpus': num_gpus
        }

    def _check_feasibility(self, vb_config: Dict, num_gpus: int) -> Dict:
        """æ£€æŸ¥å¯è¡Œæ€§"""
        hw = self.hardware_info

        # æ£€æŸ¥GPU
        gpu_ok = len(hw['gpu']) >= num_gpus
        if gpu_ok and hw['gpu'][0]['type'] == 'cuda':
            gpu_mem_ok = hw['gpu'][0].get('total_memory_gb', 0) >= vb_config['gpu_gb'] / num_gpus
        else:
            gpu_mem_ok = True  # CPUæ¨¡å¼

        # æ£€æŸ¥CPUå†…å­˜
        cpu_ok = hw['memory']['total_gb'] >= vb_config['cpu_gb'] + 4  # +4GBç³»ç»Ÿå¼€é”€

        # æ£€æŸ¥SSDç©ºé—´
        ssd_ok = hw['storage']['free_gb'] >= vb_config['ssd_gb'] + vb_config['total_gb']

        # æ£€æŸ¥æº¢å‡º
        overflow_ok = vb_config['overflow_gb'] < 0.1  # å®¹å¿å°äº100MBæº¢å‡º

        overall_ok = gpu_ok and gpu_mem_ok and cpu_ok and ssd_ok and overflow_ok

        return {
            'overall': overall_ok,
            'gpu_available': gpu_ok,
            'gpu_memory': gpu_mem_ok,
            'cpu_memory': cpu_ok,
            'storage': ssd_ok,
            'no_overflow': overflow_ok
        }

    def _estimate_performance(self, vb_config: Dict, feasibility: Dict) -> Dict:
        """ä¼°ç®—æ€§èƒ½"""
        if not feasibility['overall']:
            return {
                'score': 0,
                'rating': 'N/A',
                'bottleneck': self._identify_bottleneck(feasibility)
            }

        # è®¡ç®—åˆ†æ•°ï¼ˆ0-100ï¼‰
        gpu_ratio = vb_config['gpu_gb'] / vb_config['total_gb'] if vb_config['total_gb'] > 0 else 0
        cpu_ratio = vb_config['cpu_gb'] / vb_config['total_gb'] if vb_config['total_gb'] > 0 else 0
        ssd_ratio = vb_config['ssd_gb'] / vb_config['total_gb'] if vb_config['total_gb'] > 0 else 0

        # GPUæ•°æ®æœ€å¿«ï¼Œæƒé‡æœ€é«˜
        score = (
            gpu_ratio * 90 +  # GPUç¼“å­˜å‘½ä¸­ç‡æœ€é«˜
            cpu_ratio * 50 +  # CPUä¸­é€Ÿ
            ssd_ratio * 10    # SSDæœ€æ…¢
        )

        # è¯„çº§
        if score >= 80:
            rating = 'ä¼˜ç§€ (Excellent)'
        elif score >= 60:
            rating = 'è‰¯å¥½ (Good)'
        elif score >= 40:
            rating = 'ä¸€èˆ¬ (Fair)'
        elif score >= 20:
            rating = 'è¾ƒå·® (Poor)'
        else:
            rating = 'ä¸æ¨è (Not Recommended)'

        return {
            'score': round(score, 1),
            'rating': rating,
            'gpu_hit_rate': round(gpu_ratio * 100, 1),
            'cpu_hit_rate': round(cpu_ratio * 100, 1),
            'ssd_hit_rate': round(ssd_ratio * 100, 1)
        }

    def _identify_bottleneck(self, feasibility: Dict) -> str:
        """è¯†åˆ«ç“¶é¢ˆ"""
        if not feasibility['gpu_available']:
            return 'GPUæ•°é‡ä¸è¶³'
        if not feasibility['gpu_memory']:
            return 'GPUæ˜¾å­˜ä¸è¶³'
        if not feasibility['cpu_memory']:
            return 'CPUå†…å­˜ä¸è¶³'
        if not feasibility['storage']:
            return 'SSDç©ºé—´ä¸è¶³'
        if not feasibility['no_overflow']:
            return 'æ¨¡å‹å¤§å°è¶…å‡ºè™šæ‹Ÿå®¹é‡ä¸Šé™'
        return 'æœªçŸ¥'

    def _print_result(self, result: Dict):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        config = result['config']
        vb = result['vb_config']
        feas = result['feasibility']
        perf = result['performance']

        print(f"  æ¨¡å‹å¤§å°: {config['model_size_gb']:.1f} GB")
        print(f"  ä½¿ç”¨GPU: {vb['num_gpus']}å¼ ")
        print()
        print(f"  è™šæ‹ŸBlackwellåˆ†é…:")
        print(f"    GPUç¼“å­˜: {vb['gpu_gb']:.2f} GB")
        print(f"    CPUç¼“å­˜: {vb['cpu_gb']:.2f} GB")
        print(f"    SSDç¼“å­˜: {vb['ssd_gb']:.2f} GB")
        if vb['overflow_gb'] > 0.1:
            print(f"    âš ï¸  æº¢å‡º: {vb['overflow_gb']:.2f} GB")
        print()

        if feas['overall']:
            print(f"  âœ… å¯è¡Œæ€§: é€šè¿‡")
            print(f"  ğŸ“Š æ€§èƒ½è¯„åˆ†: {perf['score']}/100 - {perf['rating']}")
            print(f"  ğŸ¯ GPUå‘½ä¸­ç‡: {perf['gpu_hit_rate']:.1f}%")
        else:
            print(f"  âŒ å¯è¡Œæ€§: ä¸é€šè¿‡")
            print(f"  ğŸš« ç“¶é¢ˆ: {perf.get('bottleneck', 'æœªçŸ¥')}")


class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, hardware_info: Dict, results: List[Dict]):
        self.hardware_info = hardware_info
        self.results = results

    def generate(self):
        """ç”ŸæˆæŠ¥å‘Š"""
        print("=" * 80)
        print("ğŸ“„ æµ‹è¯•æŠ¥å‘Š")
        print("=" * 80)
        print()

        self._print_summary()
        self._print_recommendations()
        self._save_json_report()

    def _print_summary(self):
        """æ‰“å°æ±‡æ€»"""
        print("ğŸ“Š æµ‹è¯•æ±‡æ€»:")
        print()

        total = len(self.results)
        passed = sum(1 for r in self.results if r['feasibility']['overall'])

        print(f"  æ€»æµ‹è¯•æ•°: {total}")
        print(f"  é€šè¿‡: {passed}")
        print(f"  å¤±è´¥: {total - passed}")
        print(f"  é€šè¿‡ç‡: {passed/total*100:.1f}%")
        print()

        # æœ€ä½³é…ç½®
        feasible_results = [r for r in self.results if r['feasibility']['overall']]
        if feasible_results:
            best = max(feasible_results, key=lambda r: r['performance']['score'])
            print(f"  ğŸ† æœ€ä½³é…ç½®: {best['config']['name']}")
            print(f"     æ€§èƒ½è¯„åˆ†: {best['performance']['score']}/100")
            print(f"     æ¨¡å‹å¤§å°: {best['config']['model_size_gb']:.1f} GB")
            print()

    def _print_recommendations(self):
        """æ‰“å°å»ºè®®"""
        print("ğŸ’¡ å»ºè®®:")
        print()

        hw = self.hardware_info

        # GPUå»ºè®®
        if hw['gpu'] and hw['gpu'][0]['type'] == 'cuda':
            gpu_mem = hw['gpu'][0].get('total_memory_gb', 0)
            if gpu_mem < 8:
                print("  âš ï¸  GPUæ˜¾å­˜è¾ƒå°ï¼Œå»ºè®®:")
                print("     - ä½¿ç”¨MXFP4é‡åŒ–å‡å°‘75%å†…å­˜å ç”¨")
                print("     - è®­ç»ƒå°å‹æ¨¡å‹ (7B-13B)")
            elif gpu_mem < 24:
                print("  âœ“ GPUæ˜¾å­˜ä¸­ç­‰ï¼Œé€‚åˆ:")
                print("     - è®­ç»ƒä¸­å‹æ¨¡å‹ (13B-30B)")
                print("     - ä½¿ç”¨MXFP4é‡åŒ–è®­ç»ƒ70Bæ¨¡å‹")
            else:
                print("  âœ“ GPUæ˜¾å­˜å……è¶³ï¼Œé€‚åˆ:")
                print("     - è®­ç»ƒå¤§å‹æ¨¡å‹ (70B+)")
                print("     - æˆ–ä½¿ç”¨å¤šGPUè®­ç»ƒè¶…å¤§æ¨¡å‹")
        else:
            print("  â„¹ï¸  CPU-onlyæ¨¡å¼:")
            print("     - æ¨èä½¿ç”¨å°å‹é‡åŒ–æ¨¡å‹ (7B MXFP4)")
            print("     - è€ƒè™‘ä½¿ç”¨äº‘GPUæœåŠ¡")

        print()

        # CPUå†…å­˜å»ºè®®
        cpu_mem = hw['memory']['total_gb']
        if cpu_mem < 16:
            print("  âš ï¸  CPUå†…å­˜è¾ƒå° (<16GB):")
            print("     - å»ºè®®å‡çº§åˆ°32GB")
        elif cpu_mem < 64:
            print("  âœ“ CPUå†…å­˜é€‚ä¸­ (16-64GB)")
        else:
            print("  âœ“ CPUå†…å­˜å……è¶³ (>=64GB)")

        print()

        # å­˜å‚¨å»ºè®®
        storage_free = hw['storage']['free_gb']
        if storage_free < 100:
            print("  âš ï¸  SSDå¯ç”¨ç©ºé—´ä¸è¶³ (<100GB):")
            print("     - å»ºè®®æ¸…ç†ç£ç›˜ç©ºé—´")
            print("     - æˆ–æ·»åŠ é¢å¤–å­˜å‚¨")
        else:
            print("  âœ“ å­˜å‚¨ç©ºé—´å……è¶³")

        print()

    def _save_json_report(self):
        """ä¿å­˜JSONæŠ¥å‘Š"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'hardware': self.hardware_info,
            'results': self.results
        }

        output_file = f"vblackwell_benchmark_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        output_path = os.path.join(os.path.dirname(__file__), output_file)

        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            print(f"ğŸ“ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

        print()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è™šæ‹ŸBlackwell GPUæ€§èƒ½æµ‹è¯•å·¥å…·')
    parser.add_argument('--quick', action='store_true', help='å¿«é€Ÿæµ‹è¯•ï¼ˆä»…2ä¸ªé…ç½®ï¼‰')
    parser.add_argument('--detailed', action='store_true', help='è¯¦ç»†æµ‹è¯•ï¼ˆ8ä¸ªé…ç½®ï¼‰')
    args = parser.parse_args()

    # ç¡®å®šæµ‹è¯•æ¨¡å¼
    if args.quick:
        test_mode = 'quick'
    elif args.detailed:
        test_mode = 'detailed'
    else:
        test_mode = 'standard'

    print(f"æµ‹è¯•æ¨¡å¼: {test_mode.upper()}")
    print()

    # 1. ç¡¬ä»¶æ£€æµ‹
    detector = HardwareDetector()
    hardware_info = detector.detect_all()

    # 2. è¿è¡Œæµ‹è¯•
    benchmark = VirtualBlackwellBenchmark(hardware_info)
    results = benchmark.run_tests(test_mode)

    # 3. ç”ŸæˆæŠ¥å‘Š
    report_gen = ReportGenerator(hardware_info, results)
    report_gen.generate()

    print("=" * 80)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("=" * 80)


if __name__ == '__main__':
    main()
