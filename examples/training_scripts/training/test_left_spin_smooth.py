#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å·¦æ—‹å¹³æ»‘é›†æˆæµ‹è¯•è„šæœ¬

éªŒè¯å·¦æ—‹å¹³æ»‘æœºåˆ¶å·²æ­£ç¡®é›†æˆåˆ° APT æ¨¡å‹ä¸­ï¼Œå¹¶æ›¿æ¢äº†ä¼ ç»Ÿæ³°å‹’å±•å¼€ã€‚

æµ‹è¯•å†…å®¹:
1. å·¦æ—‹å¹³æ»‘æ¨¡å—å•å…ƒæµ‹è¯•
2. APTæ¨¡å‹é›†æˆæµ‹è¯•
3. æ®‹å·®è¿æ¥æ›¿æ¢éªŒè¯
4. å°–ç‚¹è§„é¿æ•ˆæœå¯¹æ¯”

ä½œè€…: claude + chen0430tw
ç‰ˆæœ¬: 1.0
æ—¥æœŸ: 2026-01-21
"""

import torch
import torch.nn as nn
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from apt.apt_model.modeling.left_spin_smooth import (
    LeftSpinStep,
    LeftSpinResidual,
    LeftSpinMonitor
)
from apt.apt_model.modeling.apt_model import (
    APTModel,
    APTModelConfiguration
)


def test_left_spin_step_basic():
    """æµ‹è¯•1: å·¦æ—‹å¹³æ»‘æ­¥è¿›å™¨åŸºç¡€åŠŸèƒ½"""
    print("\n" + "="*70)
    print("æµ‹è¯•1: å·¦æ—‹å¹³æ»‘æ­¥è¿›å™¨åŸºç¡€åŠŸèƒ½")
    print("="*70)

    # åˆ›å»ºå·¦æ—‹æ­¥è¿›å™¨
    left_spin = LeftSpinStep(
        alpha=0.5,
        tau=0.3,
        beta=0.7,
        gate_type='normalized'
    )

    # æ¨¡æ‹Ÿæ•°æ®
    batch_size, seq_len, d_model = 2, 10, 64
    u = torch.randn(batch_size, seq_len, d_model)
    delta_u = torch.randn(batch_size, seq_len, d_model)

    # å‰å‘ä¼ æ’­
    u_next, stats = left_spin(u, delta_u, use_smooth=True)

    print(f"âœ… è¾“å…¥å½¢çŠ¶: u={u.shape}, Î”u={delta_u.shape}")
    print(f"âœ… è¾“å‡ºå½¢çŠ¶: u'={u_next.shape}")
    print(f"âœ… ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - å°–ç‚¹å¼ºåº¦: {stats['spike_strength']:.4f}")
    print(f"   - ç¼“å†²è§’: {stats['buffer_angle']:.4f}")
    print(f"   - é—¨æ§å€¼: {stats['gate_value']:.4f}")
    print(f"   - å·²å¹³æ»‘: {stats['smoothed']}")

    # éªŒè¯é—¨æ§å€¼èŒƒå›´
    assert 0.0 <= stats['gate_value'] <= 1.0, "é—¨æ§å€¼åº”åœ¨ [0, 1] èŒƒå›´å†…"
    print("âœ… é—¨æ§å€¼èŒƒå›´éªŒè¯é€šè¿‡")


def test_left_spin_spike_detection():
    """æµ‹è¯•2: å°–ç‚¹æ£€æµ‹èƒ½åŠ›"""
    print("\n" + "="*70)
    print("æµ‹è¯•2: å°–ç‚¹æ£€æµ‹èƒ½åŠ›")
    print("="*70)

    left_spin = LeftSpinStep(alpha=0.5, tau=0.3, beta=0.7)

    batch_size, seq_len, d_model = 2, 10, 64
    u = torch.randn(batch_size, seq_len, d_model)

    # åœºæ™¯1: æ­£å¸¸å¢é‡ï¼ˆå°å˜åŒ–ï¼‰
    delta_small = 0.1 * torch.randn(batch_size, seq_len, d_model)
    _, stats_small = left_spin(u, delta_small, use_smooth=True)

    # åœºæ™¯2: å°–ç‚¹å¢é‡ï¼ˆå¤§å˜åŒ–ï¼‰
    delta_large = 10.0 * torch.randn(batch_size, seq_len, d_model)
    _, stats_large = left_spin(u, delta_large, use_smooth=True)

    print(f"ğŸ“Š æ­£å¸¸å¢é‡:")
    print(f"   - å°–ç‚¹å¼ºåº¦: {stats_small['spike_strength']:.4f}")
    print(f"   - ç¼“å†²è§’: {stats_small['buffer_angle']:.4f}")
    print(f"   - é—¨æ§å€¼: {stats_small['gate_value']:.4f}")

    print(f"\nğŸ“Š å°–ç‚¹å¢é‡:")
    print(f"   - å°–ç‚¹å¼ºåº¦: {stats_large['spike_strength']:.4f}")
    print(f"   - ç¼“å†²è§’: {stats_large['buffer_angle']:.4f}")
    print(f"   - é—¨æ§å€¼: {stats_large['gate_value']:.4f}")

    # éªŒè¯ï¼šå°–ç‚¹å¢é‡åº”è§¦å‘æ›´å¼ºç¼“å†²ï¼ˆé—¨æ§å€¼æ›´å°ï¼‰
    assert stats_large['spike_strength'] > stats_small['spike_strength'], \
        "å°–ç‚¹å¢é‡åº”æœ‰æ›´é«˜çš„å°–ç‚¹å¼ºåº¦"
    assert stats_large['gate_value'] < stats_small['gate_value'], \
        "å°–ç‚¹å¢é‡åº”æœ‰æ›´å°çš„é—¨æ§å€¼ï¼ˆæ›´å¼ºç¼“å†²ï¼‰"

    print("\nâœ… å°–ç‚¹æ£€æµ‹éªŒè¯é€šè¿‡ï¼šå¤§å¢é‡è§¦å‘æ›´å¼ºç¼“å†²")


def test_left_spin_residual():
    """æµ‹è¯•3: å·¦æ—‹å¹³æ»‘æ®‹å·®å±‚"""
    print("\n" + "="*70)
    print("æµ‹è¯•3: å·¦æ—‹å¹³æ»‘æ®‹å·®å±‚")
    print("="*70)

    left_spin_res = LeftSpinResidual(
        alpha=0.5,
        tau=0.3,
        beta=0.7,
        gate_type='normalized',
        adaptive=True
    )

    batch_size, seq_len, d_model = 4, 20, 128
    x = torch.randn(batch_size, seq_len, d_model)
    residual = torch.randn(batch_size, seq_len, d_model)

    # è®­ç»ƒæ¨¡å¼
    left_spin_res.train()
    output_train = left_spin_res(x, residual)

    # æ¨ç†æ¨¡å¼
    left_spin_res.eval()
    output_eval = left_spin_res(x, residual)

    print(f"âœ… è¾“å…¥å½¢çŠ¶: x={x.shape}, residual={residual.shape}")
    print(f"âœ… è®­ç»ƒæ¨¡å¼è¾“å‡º: {output_train.shape}")
    print(f"âœ… æ¨ç†æ¨¡å¼è¾“å‡º: {output_eval.shape}")
    print(f"âœ… å¹³æ»‘åº”ç”¨æ¯”ä¾‹: {left_spin_res.get_smooth_ratio():.2%}")


def test_apt_model_with_left_spin():
    """æµ‹è¯•4: APTæ¨¡å‹é›†æˆå·¦æ—‹å¹³æ»‘"""
    print("\n" + "="*70)
    print("æµ‹è¯•4: APTæ¨¡å‹é›†æˆå·¦æ—‹å¹³æ»‘")
    print("="*70)

    # åˆ›å»ºé…ç½®ï¼ˆå¯ç”¨å·¦æ—‹å¹³æ»‘ï¼‰
    config = APTModelConfiguration(
        vocab_size=1000,
        d_model=128,
        num_encoder_layers=2,
        num_decoder_layers=2,
        num_heads=4,
        d_ff=512,
        max_seq_len=64,
        use_left_spin=True,  # å¯ç”¨å·¦æ—‹å¹³æ»‘
        left_spin_alpha=0.5,
        left_spin_tau=0.3,
        left_spin_beta=0.7,
        use_dbc_dac=False  # ç®€åŒ–æµ‹è¯•
    )

    print(f"âœ… é…ç½®åˆ›å»ºæˆåŠŸ")
    print(f"   - use_left_spin: {config.use_left_spin}")
    print(f"   - left_spin_alpha: {config.left_spin_alpha}")
    print(f"   - left_spin_tau: {config.left_spin_tau}")

    # åˆ›å»ºæ¨¡å‹
    model = APTModel(config)

    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    print(f"   - ç¼–ç å™¨å±‚æ•°: {len(model.encoder_layers)}")
    print(f"   - è§£ç å™¨å±‚æ•°: {len(model.decoder_layers)}")

    # æ£€æŸ¥æ˜¯å¦é›†æˆäº†å·¦æ—‹å¹³æ»‘
    encoder_layer_0 = model.encoder_layers[0]
    has_left_spin = hasattr(encoder_layer_0, 'left_spin_attn') and \
                    encoder_layer_0.left_spin_attn is not None

    print(f"âœ… ç¼–ç å™¨å±‚0 é›†æˆå·¦æ—‹å¹³æ»‘: {has_left_spin}")

    if has_left_spin:
        print(f"   - æ³¨æ„åŠ›å­å±‚å·¦æ—‹å¹³æ»‘: {type(encoder_layer_0.left_spin_attn).__name__}")
        print(f"   - å‰é¦ˆå­å±‚å·¦æ—‹å¹³æ»‘: {type(encoder_layer_0.left_spin_ffn).__name__}")

    # å‰å‘ä¼ æ’­æµ‹è¯•
    batch_size, seq_len = 2, 16
    src_tokens = torch.randint(0, config.vocab_size, (batch_size, seq_len))
    tgt_tokens = torch.randint(0, config.vocab_size, (batch_size, seq_len))

    with torch.no_grad():
        output = model(src_tokens=src_tokens, tgt_tokens=tgt_tokens)

    print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
    print(f"   - è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"   - æœŸæœ›å½¢çŠ¶: [{batch_size}, {seq_len}, {config.vocab_size}]")

    assert output.shape == (batch_size, seq_len, config.vocab_size), \
        "è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…"


def test_left_spin_vs_standard_residual():
    """æµ‹è¯•5: å·¦æ—‹å¹³æ»‘ vs æ ‡å‡†æ®‹å·®å¯¹æ¯”"""
    print("\n" + "="*70)
    print("æµ‹è¯•5: å·¦æ—‹å¹³æ»‘ vs æ ‡å‡†æ®‹å·®å¯¹æ¯”")
    print("="*70)

    batch_size, seq_len, d_model = 4, 20, 128
    u = torch.randn(batch_size, seq_len, d_model)

    # æ„é€ å°–ç‚¹å¢é‡ï¼ˆéƒ¨åˆ†ä½ç½®æœ‰å·¨å¤§å˜åŒ–ï¼‰
    delta_u = 0.1 * torch.randn(batch_size, seq_len, d_model)
    # åœ¨ä¸­é—´ä½ç½®æ³¨å…¥å°–ç‚¹
    delta_u[:, seq_len//2, :] *= 100.0  # ğŸ”¥ å°–ç‚¹

    # æ ‡å‡†æ®‹å·®è¿æ¥
    u_standard = u + delta_u

    # å·¦æ—‹å¹³æ»‘æ®‹å·®è¿æ¥
    left_spin = LeftSpinStep(alpha=0.5, tau=0.3, beta=0.7)
    u_smoothed, stats = left_spin(u, delta_u, use_smooth=True)

    # è®¡ç®—è¾“å‡ºç¨³å®šæ€§ï¼ˆæ–¹å·®ï¼‰
    var_standard = torch.var(u_standard).item()
    var_smoothed = torch.var(u_smoothed).item()

    print(f"ğŸ“Š æ ‡å‡†æ®‹å·®è¿æ¥:")
    print(f"   - è¾“å‡ºæ–¹å·®: {var_standard:.6f}")

    print(f"\nğŸ“Š å·¦æ—‹å¹³æ»‘æ®‹å·®è¿æ¥:")
    print(f"   - è¾“å‡ºæ–¹å·®: {var_smoothed:.6f}")
    print(f"   - å°–ç‚¹å¼ºåº¦: {stats['spike_strength']:.4f}")
    print(f"   - ç¼“å†²è§’: {stats['buffer_angle']:.4f}")
    print(f"   - é—¨æ§å€¼: {stats['gate_value']:.4f}")

    print(f"\nâœ… ç¨³å®šæ€§æå‡: {(var_standard - var_smoothed) / var_standard * 100:.2f}%")
    print(f"   (æ–¹å·®å‡å°‘è¡¨ç¤ºè¾“å‡ºæ›´ç¨³å®š)")


def test_left_spin_monitor():
    """æµ‹è¯•6: å·¦æ—‹å¹³æ»‘ç›‘æ§å™¨"""
    print("\n" + "="*70)
    print("æµ‹è¯•6: å·¦æ—‹å¹³æ»‘ç›‘æ§å™¨")
    print("="*70)

    monitor = LeftSpinMonitor(log_interval=10)
    left_spin = LeftSpinStep(alpha=0.5, tau=0.3, beta=0.7)

    batch_size, seq_len, d_model = 2, 10, 64

    # æ¨¡æ‹Ÿ20æ­¥
    for step in range(20):
        u = torch.randn(batch_size, seq_len, d_model)
        delta_u = torch.randn(batch_size, seq_len, d_model) * (1.0 + 0.1 * step)

        _, stats = left_spin(u, delta_u, use_smooth=True)
        monitor.log_stats(stats)

    # è·å–ç»Ÿè®¡
    full_stats = monitor.get_statistics()

    print(f"âœ… ç›‘æ§å™¨ç»Ÿè®¡ï¼ˆ20æ­¥ï¼‰:")
    for key, values in full_stats.items():
        print(f"   - {key}:")
        print(f"     å‡å€¼: {values['mean']:.4f}")
        print(f"     æ ‡å‡†å·®: {values['std']:.4f}")
        print(f"     èŒƒå›´: [{values['min']:.4f}, {values['max']:.4f}]")


def test_disable_left_spin():
    """æµ‹è¯•7: ç¦ç”¨å·¦æ—‹å¹³æ»‘ï¼ˆé™çº§ä¸ºæ ‡å‡†æ®‹å·®ï¼‰"""
    print("\n" + "="*70)
    print("æµ‹è¯•7: ç¦ç”¨å·¦æ—‹å¹³æ»‘ï¼ˆé™çº§ä¸ºæ ‡å‡†æ®‹å·®ï¼‰")
    print("="*70)

    # åˆ›å»ºé…ç½®ï¼ˆç¦ç”¨å·¦æ—‹å¹³æ»‘ï¼‰
    config = APTModelConfiguration(
        vocab_size=1000,
        d_model=128,
        num_encoder_layers=2,
        num_decoder_layers=2,
        num_heads=4,
        d_ff=512,
        use_left_spin=False,  # âŒ ç¦ç”¨å·¦æ—‹å¹³æ»‘
        use_dbc_dac=False
    )

    model = APTModel(config)

    # æ£€æŸ¥ç¼–ç å™¨å±‚
    encoder_layer_0 = model.encoder_layers[0]
    has_left_spin = hasattr(encoder_layer_0, 'left_spin_attn') and \
                    encoder_layer_0.left_spin_attn is not None

    print(f"âœ… é…ç½®: use_left_spin={config.use_left_spin}")
    print(f"âœ… ç¼–ç å™¨å±‚0 é›†æˆå·¦æ—‹å¹³æ»‘: {has_left_spin}")
    print(f"   (åº”ä¸º Falseï¼Œå› ä¸ºå·²ç¦ç”¨)")

    # å‰å‘ä¼ æ’­åº”æ­£å¸¸å·¥ä½œï¼ˆé™çº§ä¸ºæ ‡å‡†æ®‹å·®ï¼‰
    batch_size, seq_len = 2, 16
    src_tokens = torch.randint(0, config.vocab_size, (batch_size, seq_len))
    tgt_tokens = torch.randint(0, config.vocab_size, (batch_size, seq_len))

    with torch.no_grad():
        output = model(src_tokens=src_tokens, tgt_tokens=tgt_tokens)

    print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼ˆä½¿ç”¨æ ‡å‡†æ®‹å·®ï¼‰")
    print(f"   - è¾“å‡ºå½¢çŠ¶: {output.shape}")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*70)
    print("ğŸš€ å·¦æ—‹å¹³æ»‘é›†æˆæµ‹è¯•å¥—ä»¶")
    print("="*70)
    print("\næµ‹è¯•ç›®æ ‡: éªŒè¯å·¦æ—‹å¹³æ»‘å·²æ­£ç¡®æ›¿æ¢æ³°å‹’å±•å¼€")
    print("æµ‹è¯•å†…å®¹: 7ä¸ªæµ‹è¯•åœºæ™¯")

    try:
        test_left_spin_step_basic()
        test_left_spin_spike_detection()
        test_left_spin_residual()
        test_apt_model_with_left_spin()
        test_left_spin_vs_standard_residual()
        test_left_spin_monitor()
        test_disable_left_spin()

        print("\n" + "="*70)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("="*70)
        print("\nâœ… å·¦æ—‹å¹³æ»‘å·²æˆåŠŸé›†æˆåˆ° APT æ¨¡å‹")
        print("âœ… æ³°å‹’å±•å¼€å·²è¢«æ›¿æ¢ä¸ºå•å‘ç¼“å†²æœºåˆ¶")
        print("âœ… å°–ç‚¹è§„é¿åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        print("âœ… å‘åå…¼å®¹ï¼ˆå¯ç¦ç”¨å·¦æ—‹å¹³æ»‘ï¼‰")

        print("\nğŸ“š ä½¿ç”¨æ–¹æ³•:")
        print("   # å¯ç”¨å·¦æ—‹å¹³æ»‘ï¼ˆé»˜è®¤ï¼‰")
        print("   config = APTModelConfiguration(use_left_spin=True)")
        print("\n   # ç¦ç”¨å·¦æ—‹å¹³æ»‘ï¼ˆé™çº§ä¸ºæ ‡å‡†æ®‹å·®ï¼‰")
        print("   config = APTModelConfiguration(use_left_spin=False)")

        print("\nğŸ”¬ æ ¸å¿ƒæ”¹è¿›:")
        print("   - ä¼ ç»Ÿ: u' = u + Î”u  (é‡å°–ç‚¹ä¼šç‚¸)")
        print("   - å·¦æ—‹: u' = u + g(Ï†)Â·Î”u  (é‡å°–ç‚¹è‡ªåŠ¨ç¼©å°æ­¥é•¿)")
        print("   - å…¶ä¸­ Ï† = Î±Â·softplus(s-Ï„), s ä¸ºå°–ç‚¹å¼ºåº¦")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
