#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NPUé›†æˆæµ‹è¯• - è™šæ‹ŸBlackwellÃ—åä¸ºæ˜‡è…¾NPU

æµ‹è¯•å†…å®¹ï¼š
1. NPUè®¾å¤‡æ£€æµ‹
2. NPUåç«¯é€‚é…å™¨
3. VGPU Stack NPUæ”¯æŒ
4. Virtual Blackwell NPUä¼˜åŒ–
5. å®Œæ•´è®­ç»ƒæµç¨‹

ä½œè€…: claude + chen0430tw
ç‰ˆæœ¬: 1.0 (Virtual Blackwell NPU Extension)
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
import torch.nn as nn
from typing import Optional

# NPUåç«¯
from apt.perf.optimization.npu_backend import (
    DeviceBackend,
    UnifiedDeviceManager,
    get_device_manager,
    get_unified_backend,
    is_npu_available,
    is_cuda_available,
    get_accelerator_type
)

# è®¾å¤‡ç®¡ç†
from apt.core.system import get_device, get_device_info, memory_cleanup

# Virtual Blackwell
import apt.perf.optimization.vb_global as vb
from apt.perf.optimization.vgpu_stack import create_vgpu_stack


def test_device_detection():
    """æµ‹è¯•1: è®¾å¤‡æ£€æµ‹"""
    print("\n" + "="*70)
    print("æµ‹è¯•1: è®¾å¤‡æ£€æµ‹")
    print("="*70)

    # æ£€æµ‹åŠ é€Ÿå™¨ç±»å‹
    accel_type = get_accelerator_type()
    print(f"âœ“ åŠ é€Ÿå™¨ç±»å‹: {accel_type.upper()}")

    # NPUæ£€æµ‹
    npu_avail = is_npu_available()
    print(f"âœ“ NPUå¯ç”¨: {'æ˜¯' if npu_avail else 'å¦'}")

    # CUDAæ£€æµ‹
    cuda_avail = is_cuda_available()
    print(f"âœ“ CUDAå¯ç”¨: {'æ˜¯' if cuda_avail else 'å¦'}")

    # è·å–è®¾å¤‡ä¿¡æ¯
    device = get_device()
    print(f"âœ“ é»˜è®¤è®¾å¤‡: {device}")

    # è¯¦ç»†è®¾å¤‡ä¿¡æ¯
    info = get_device_info()
    print(f"âœ“ è®¾å¤‡è¯¦æƒ…:")
    print(f"  - è®¾å¤‡ç±»å‹: {info.get('device_type', 'unknown')}")
    print(f"  - è®¾å¤‡åç§°: {info.get('device_name', 'unknown')}")
    print(f"  - è®¾å¤‡æ•°é‡: {info.get('device_count', 0)}")
    if info.get('cuda_version'):
        print(f"  - CUDAç‰ˆæœ¬: {info['cuda_version']}")
    if info.get('npu_version'):
        print(f"  - NPUç‰ˆæœ¬: {info['npu_version']}")

    print("\nâœ… æµ‹è¯•1é€šè¿‡")
    return accel_type, device


def test_device_backend(device: torch.device):
    """æµ‹è¯•2: NPUåç«¯é€‚é…å™¨"""
    print("\n" + "="*70)
    print("æµ‹è¯•2: NPUåç«¯é€‚é…å™¨")
    print("="*70)

    # åˆ›å»ºè®¾å¤‡åç«¯
    backend = DeviceBackend(device)
    print(f"âœ“ åç«¯åˆ›å»º: {backend}")

    # è®¾å¤‡å±æ€§
    print(f"âœ“ è®¾å¤‡ç±»å‹: {backend.device_type}")
    print(f"âœ“ è®¾å¤‡ç´¢å¼•: {backend.device_index}")
    print(f"âœ“ è®¾å¤‡å¯ç”¨: {backend.is_available()}")
    print(f"âœ“ è®¾å¤‡æ•°é‡: {backend.device_count()}")
    print(f"âœ“ è®¾å¤‡åç§°: {backend.get_device_name()}")

    # è®¾å¤‡å±æ€§
    props = backend.get_device_properties()
    print(f"âœ“ è®¾å¤‡å±æ€§:")
    print(f"  - åç§°: {props['name']}")
    print(f"  - ç±»å‹: {props['type']}")
    print(f"  - æ€»å†…å­˜: {props['total_memory'] / (1024**3):.2f} GB")

    # å†…å­˜ä¿¡æ¯
    summary = backend.get_memory_summary()
    print(f"âœ“ å†…å­˜æ‘˜è¦:")
    print(f"  - å·²åˆ†é…: {summary['allocated_mb']:.2f} MB")
    print(f"  - å·²ä¿ç•™: {summary['reserved_mb']:.2f} MB")
    if 'total_mb' in summary:
        print(f"  - æ€»å®¹é‡: {summary['total_mb']:.2f} MB")
        print(f"  - ä½¿ç”¨ç‡: {summary.get('utilization_pct', 0):.2f}%")

    # æµ‹è¯•tensorç§»åŠ¨
    x = torch.randn(10, 10)
    x_device = backend.to_device(x)
    print(f"âœ“ Tensorç§»åŠ¨: {x.device} -> {x_device.device}")

    print("\nâœ… æµ‹è¯•2é€šè¿‡")
    return backend


def test_unified_device_manager():
    """æµ‹è¯•3: ç»Ÿä¸€è®¾å¤‡ç®¡ç†å™¨"""
    print("\n" + "="*70)
    print("æµ‹è¯•3: ç»Ÿä¸€è®¾å¤‡ç®¡ç†å™¨")
    print("="*70)

    # è·å–å…¨å±€ç®¡ç†å™¨
    manager = get_device_manager()
    print(f"âœ“ è®¾å¤‡ç®¡ç†å™¨: {manager}")

    # æ‰€æœ‰è®¾å¤‡
    devices = manager.get_all_devices()
    print(f"âœ“ å¯ç”¨è®¾å¤‡æ•°: {len(devices)}")
    for dev in devices:
        print(f"  - {dev}")

    # æœ€ä½³è®¾å¤‡
    best_device = manager.get_best_device()
    print(f"âœ“ æœ€ä½³è®¾å¤‡: {best_device}")

    # è®¾å¤‡æ‘˜è¦
    summary = manager.get_device_summary()
    print(f"âœ“ è®¾å¤‡æ‘˜è¦:")
    print(f"  - æ€»è®¾å¤‡æ•°: {summary['total_devices']}")
    print(f"  - CUDAè®¾å¤‡: {summary['cuda_devices']}")
    print(f"  - NPUè®¾å¤‡: {summary['npu_devices']}")

    print("\nâœ… æµ‹è¯•3é€šè¿‡")
    return manager


def test_vgpu_stack_npu(device: torch.device):
    """æµ‹è¯•4: VGPU Stack NPUæ”¯æŒ"""
    print("\n" + "="*70)
    print("æµ‹è¯•4: VGPU Stack NPUæ”¯æŒ")
    print("="*70)

    # åˆ›å»ºVGPU Stackï¼ˆè‡ªåŠ¨æ£€æµ‹NPUï¼‰
    stack = create_vgpu_stack()
    print("âœ“ VGPU Stackå·²åˆ›å»º")

    # æ£€æŸ¥å±‚çº§é…ç½®
    stats = stack.get_all_stats()
    print(f"âœ“ å †å å±‚çº§æ•°: {len(stats)}")
    for level_stat in stats:
        print(f"  - Level {level_stat['level']}: {level_stat['device']} "
              f"({level_stat['capacity_mb']:.0f}MB)")

    # æµ‹è¯•tensorå­˜å‚¨
    test_tensor = torch.randn(100, 100).to(device)
    success = stack.put('test_tensor', test_tensor)
    print(f"âœ“ Tensorå­˜å‚¨: {'æˆåŠŸ' if success else 'å¤±è´¥'}")

    # æµ‹è¯•tensorè·å–
    retrieved = stack.get('test_tensor')
    if retrieved is not None:
        print(f"âœ“ Tensorè·å–: æˆåŠŸ (shape={retrieved.shape})")
    else:
        print(f"âœ— Tensorè·å–: å¤±è´¥")

    # ç»Ÿè®¡ä¿¡æ¯
    stats = stack.get_all_stats()
    print(f"âœ“ Level 0ç»Ÿè®¡:")
    print(f"  - å‘½ä¸­ç‡: {stats[0]['hit_rate']*100:.1f}%")
    print(f"  - ç¼“å­˜tensoræ•°: {stats[0]['cached_tensors']}")

    print("\nâœ… æµ‹è¯•4é€šè¿‡")
    return stack


def test_vb_npu_optimization(device: torch.device):
    """æµ‹è¯•5: Virtual Blackwell NPUä¼˜åŒ–"""
    print("\n" + "="*70)
    print("æµ‹è¯•5: Virtual Blackwell NPUä¼˜åŒ–")
    print("="*70)

    # å¯ç”¨VBï¼ˆåº”æ˜¾ç¤ºNPUè®¾å¤‡ï¼‰
    vb.enable_balanced_mode()

    # æ£€æŸ¥çŠ¶æ€
    is_enabled = vb.is_enabled()
    print(f"âœ“ VBå·²å¯ç”¨: {is_enabled}")

    # è·å–é…ç½®
    config = vb.get_config()
    print(f"âœ“ VBé…ç½®:")
    print(f"  - FP4: {config['use_fp4']}")
    print(f"  - Flash Attention: {config['use_flash_attn']}")
    print(f"  - æ··åˆç²¾åº¦: {config['mixed_precision']}")

    # è·å–VGPU Stack
    stack = vb.get_stack()
    print(f"âœ“ VGPU Stack: {'å·²åˆ›å»º' if stack else 'æœªåˆ›å»º'}")

    print("\nâœ… æµ‹è¯•5é€šè¿‡")


def test_simple_model_training(device: torch.device):
    """æµ‹è¯•6: ç®€å•æ¨¡å‹è®­ç»ƒ"""
    print("\n" + "="*70)
    print("æµ‹è¯•6: ç®€å•æ¨¡å‹è®­ç»ƒï¼ˆNPU/GPUï¼‰")
    print("="*70)

    # åˆ›å»ºç®€å•æ¨¡å‹
    class SimpleModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.fc1 = nn.Linear(128, 256)
            self.fc2 = nn.Linear(256, 128)
            self.fc3 = nn.Linear(128, 10)

        def forward(self, x):
            x = torch.relu(self.fc1(x))
            x = torch.relu(self.fc2(x))
            x = self.fc3(x)
            return x

    model = SimpleModel().to(device)
    print(f"âœ“ æ¨¡å‹å·²åˆ›å»ºå¹¶ç§»è‡³ {device}")

    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    criterion = nn.CrossEntropyLoss()

    # è®­ç»ƒå‡ æ­¥
    print("âœ“ å¼€å§‹è®­ç»ƒ...")
    model.train()
    for step in range(5):
        # éšæœºæ•°æ®
        x = torch.randn(32, 128).to(device)
        y = torch.randint(0, 10, (32,)).to(device)

        # å‰å‘ä¼ æ’­
        output = model(x)
        loss = criterion(output, y)

        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        print(f"  Step {step+1}/5: Loss = {loss.item():.4f}")

    print("âœ“ è®­ç»ƒå®Œæˆ")

    # æ¸…ç†å†…å­˜
    memory_cleanup()
    print("âœ“ å†…å­˜å·²æ¸…ç†")

    print("\nâœ… æµ‹è¯•6é€šè¿‡")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*70)
    print("ğŸ§ª è™šæ‹ŸBlackwell NPUé›†æˆæµ‹è¯•")
    print("="*70)

    try:
        # æµ‹è¯•1: è®¾å¤‡æ£€æµ‹
        accel_type, device = test_device_detection()

        # æµ‹è¯•2: è®¾å¤‡åç«¯
        backend = test_device_backend(device)

        # æµ‹è¯•3: ç»Ÿä¸€è®¾å¤‡ç®¡ç†å™¨
        manager = test_unified_device_manager()

        # æµ‹è¯•4: VGPU Stack NPUæ”¯æŒ
        stack = test_vgpu_stack_npu(device)

        # æµ‹è¯•5: VB NPUä¼˜åŒ–
        test_vb_npu_optimization(device)

        # æµ‹è¯•6: æ¨¡å‹è®­ç»ƒ
        test_simple_model_training(device)

        # æœ€ç»ˆæŠ¥å‘Š
        print("\n" + "="*70)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("="*70)
        print(f"âœ… åŠ é€Ÿå™¨ç±»å‹: {accel_type.upper()}")
        print(f"âœ… è®¾å¤‡: {device}")
        print(f"âœ… NPUæ”¯æŒ: {'å·²å¯ç”¨' if is_npu_available() else 'æœªå®‰è£…'}")
        print(f"âœ… Virtual Blackwell: å®Œå…¨å…¼å®¹NPU")
        print("="*70)

    except Exception as e:
        print("\n" + "="*70)
        print("âŒ æµ‹è¯•å¤±è´¥")
        print("="*70)
        print(f"é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    run_all_tests()
