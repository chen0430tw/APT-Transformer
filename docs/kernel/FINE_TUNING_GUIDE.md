# APTæ¨¡å‹å¾®è°ƒï¼ˆFine-tuningï¼‰å®Œæ•´æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

APTæ¨¡å‹å¾®è°ƒæ¨¡å—å®Œå…¨åŸºäºç°æœ‰çš„æ¨¡å—åŒ–ç»„ä»¶æ„å»ºï¼Œæ— éœ€é‡å¤é€ è½®å­ï¼š
- âœ… å¤ç”¨ `checkpoint.load_model()` - åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
- âœ… å¤ç”¨ `trainer` çš„è®­ç»ƒé€»è¾‘
- âœ… å¤ç”¨ `data loading` åŠŸèƒ½
- âœ… å¤ç”¨ `generator` å’Œ `evaluator` æ¨¡å—

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºç¡€å¾®è°ƒ

```bash
# æœ€ç®€å•çš„å¾®è°ƒå‘½ä»¤
python -m apt_model fine-tune \
  --model-path apt_model \
  --data-path finetune_data.txt \
  --save-path apt_model_finetuned
```

### å®Œæ•´é…ç½®å¾®è°ƒ

```bash
python -m apt_model fine-tune \
  --model-path apt_model \
  --data-path train_data.txt \
  --val-data-path val_data.txt \
  --epochs 5 \
  --batch-size 8 \
  --learning-rate 1e-5 \
  --save-path apt_model_finetuned \
  --freeze-embeddings \
  --freeze-encoder-layers 2
```

---

## ğŸ“Š å‚æ•°è¯´æ˜

### å¿…éœ€å‚æ•°

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `--model-path` | é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ | `apt_model` |
| `--data-path` | å¾®è°ƒè®­ç»ƒæ•°æ®è·¯å¾„ | `finetune_data.txt` |

### è®­ç»ƒé…ç½®å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--epochs` | 5 | è®­ç»ƒè½®æ•°ï¼ˆå¾®è°ƒå»ºè®®3-10è½®ï¼‰ |
| `--batch-size` | 8 | æ‰¹æ¬¡å¤§å° |
| `--learning-rate` | 1e-5 | å­¦ä¹ ç‡ï¼ˆå¾®è°ƒå»ºè®®1e-5åˆ°5e-5ï¼‰ |
| `--save-path` | apt_model_finetuned | æ¨¡å‹ä¿å­˜è·¯å¾„ |

### å¾®è°ƒä¸“ç”¨å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--val-data-path` | None | éªŒè¯æ•°æ®è·¯å¾„ |
| `--freeze-embeddings` | False | æ˜¯å¦å†»ç»“embeddingå±‚ |
| `--freeze-encoder-layers` | None | å†»ç»“å‰Nå±‚encoder |
| `--freeze-decoder-layers` | None | å†»ç»“å‰Nå±‚decoder |
| `--early-stopping-patience` | 3 | æ—©åœè€å¿ƒå€¼ |
| `--eval-steps` | 100 | è¯„ä¼°é—´éš”ï¼ˆæ­¥æ•°ï¼‰ |
| `--save-steps` | 500 | ä¿å­˜æ£€æŸ¥ç‚¹é—´éš”ï¼ˆæ­¥æ•°ï¼‰ |
| `--max-samples` | None | æœ€å¤§æ ·æœ¬æ•° |

---

## ğŸ’¡ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šé¢†åŸŸé€‚åº”

å°†é€šç”¨æ¨¡å‹å¾®è°ƒåˆ°ç‰¹å®šé¢†åŸŸï¼ˆå¦‚åŒ»ç–—ã€æ³•å¾‹ã€é‡‘èï¼‰

```bash
python -m apt_model fine-tune \
  --model-path apt_model \
  --data-path medical_texts.txt \
  --epochs 5 \
  --learning-rate 2e-5 \
  --save-path apt_model_medical
```

### åœºæ™¯2ï¼šä»»åŠ¡ä¸“ç²¾

å¾®è°ƒæ¨¡å‹ä»¥æ‰§è¡Œç‰¹å®šä»»åŠ¡

```bash
python -m apt_model fine-tune \
  --model-path apt_model \
  --data-path qa_pairs.txt \
  --val-data-path qa_val.txt \
  --epochs 10 \
  --learning-rate 1e-5 \
  --save-path apt_model_qa
```

### åœºæ™¯3ï¼šå‚æ•°é«˜æ•ˆå¾®è°ƒ

å†»ç»“å¤§éƒ¨åˆ†å±‚ï¼Œåªå¾®è°ƒé¡¶å±‚

```bash
python -m apt_model fine-tune \
  --model-path apt_model \
  --data-path small_dataset.txt \
  --freeze-embeddings \
  --freeze-encoder-layers 4 \
  --freeze-decoder-layers 4 \
  --epochs 5 \
  --learning-rate 3e-5 \
  --save-path apt_model_efficient
```

**å¥½å¤„**ï¼š
- å‡å°‘å¯è®­ç»ƒå‚æ•°
- é™ä½æ˜¾å­˜å ç”¨
- é˜²æ­¢è¿‡æ‹Ÿåˆ
- è®­ç»ƒæ›´å¿«

---

## ğŸ”§ é«˜çº§åŠŸèƒ½

### 1. æ—©åœæœºåˆ¶ï¼ˆEarly Stoppingï¼‰

è‡ªåŠ¨åœæ­¢è®­ç»ƒä»¥é˜²æ­¢è¿‡æ‹Ÿåˆï¼š

```bash
python -m apt_model fine-tune \
  --model-path apt_model \
  --data-path train.txt \
  --val-data-path val.txt \
  --early-stopping-patience 3  # éªŒè¯æŸå¤±3è½®ä¸ä¸‹é™å°±åœæ­¢
```

### 2. å±‚å†»ç»“ç­–ç•¥

#### å†»ç»“Embeddingå±‚
```bash
--freeze-embeddings
```
**é€‚ç”¨åœºæ™¯**ï¼šæ•°æ®é‡å°ã€è¯æ±‡è¡¨ä¸å˜

#### å†»ç»“åº•å±‚
```bash
--freeze-encoder-layers 2  # å†»ç»“encoderå‰2å±‚
--freeze-decoder-layers 2  # å†»ç»“decoderå‰2å±‚
```
**é€‚ç”¨åœºæ™¯**ï¼šä»»åŠ¡ç›¸ä¼¼ã€æ•°æ®é‡å°

#### å®Œå…¨å¾®è°ƒ
ä¸ä½¿ç”¨ä»»ä½•å†»ç»“å‚æ•°
**é€‚ç”¨åœºæ™¯**ï¼šæ•°æ®é‡å¤§ã€ä»»åŠ¡å·®å¼‚å¤§

### 3. å­¦ä¹ ç‡é€‰æ‹©

| åœºæ™¯ | æ¨èå­¦ä¹ ç‡ |
|------|-----------|
| ç›¸ä¼¼ä»»åŠ¡ | 1e-5 |
| ä¸åŒé¢†åŸŸ | 2e-5 ~ 3e-5 |
| å…¨æ–°ä»»åŠ¡ | 3e-5 ~ 5e-5 |
| å°æ•°æ®é›† | 5e-6 ~ 1e-5 |

---

## ğŸ“ æ•°æ®æ ¼å¼

### è®­ç»ƒæ•°æ®æ ¼å¼

æ”¯æŒçº¯æ–‡æœ¬æ–‡ä»¶ï¼Œæ¯è¡Œä¸€ä¸ªæ ·æœ¬ï¼š

```text
äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ã€‚
æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸã€‚
è‡ªç„¶è¯­è¨€å¤„ç†ç”¨äºç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚
...
```

### éªŒè¯æ•°æ®æ ¼å¼

ä¸è®­ç»ƒæ•°æ®ç›¸åŒï¼š

```text
ç¥ç»ç½‘ç»œç”±å¤šä¸ªå±‚ç»„æˆã€‚
å·ç§¯ç¥ç»ç½‘ç»œå¸¸ç”¨äºå›¾åƒå¤„ç†ã€‚
å¾ªç¯ç¥ç»ç½‘ç»œé€‚åˆå¤„ç†åºåˆ—æ•°æ®ã€‚
...
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. æ•°æ®å‡†å¤‡

- âœ… ç¡®ä¿æ•°æ®è´¨é‡é«˜
- âœ… æ•°æ®åº”ä¸ç›®æ ‡ä»»åŠ¡ç›¸å…³
- âœ… å»ºè®®è‡³å°‘1000æ¡æ ·æœ¬
- âœ… å‡†å¤‡éªŒè¯é›†ï¼ˆ10-20%ï¼‰

### 2. è¶…å‚æ•°é€‰æ‹©

**å°æ•°æ®é›†ï¼ˆ< 1000æ ·æœ¬ï¼‰ï¼š**
```bash
--epochs 10 \
--batch-size 4 \
--learning-rate 1e-5 \
--freeze-embeddings \
--freeze-encoder-layers 2
```

**ä¸­ç­‰æ•°æ®é›†ï¼ˆ1000-10000æ ·æœ¬ï¼‰ï¼š**
```bash
--epochs 5 \
--batch-size 8 \
--learning-rate 2e-5 \
--freeze-embeddings
```

**å¤§æ•°æ®é›†ï¼ˆ> 10000æ ·æœ¬ï¼‰ï¼š**
```bash
--epochs 3 \
--batch-size 16 \
--learning-rate 3e-5
```

### 3. ç›‘æ§è®­ç»ƒ

è§‚å¯Ÿä»¥ä¸‹æŒ‡æ ‡ï¼š
- è®­ç»ƒæŸå¤±æ˜¯å¦ä¸‹é™
- éªŒè¯æŸå¤±æ˜¯å¦ä¸‹é™
- ç”Ÿæˆæ ·æœ¬è´¨é‡
- æ˜¯å¦å‡ºç°è¿‡æ‹Ÿåˆ

### 4. é˜²æ­¢è¿‡æ‹Ÿåˆ

- ä½¿ç”¨éªŒè¯é›†å’Œæ—©åœ
- å†»ç»“åº•å±‚
- ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡
- å¢åŠ æ•°æ®å¢å¼º

---

## ğŸ“Š æ•ˆæœè¯„ä¼°

### è‡ªåŠ¨è¯„ä¼°

å¾®è°ƒè¿‡ç¨‹ä¸­ä¼šï¼š
1. å®šæœŸåœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
2. ç”Ÿæˆæ ·æœ¬æ–‡æœ¬
3. è®¡ç®—è´¨é‡è¯„åˆ†
4. ä¿å­˜æœ€ä½³æ¨¡å‹

### ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹

```bash
# è¯„ä¼°å¾®è°ƒåçš„æ¨¡å‹
python -m apt_model evaluate --model-path apt_model_finetuned

# ä¸å¾®è°ƒåçš„æ¨¡å‹èŠå¤©
python -m apt_model chat --model-path apt_model_finetuned
```

---

## ğŸ”¬ ä»£ç ç¤ºä¾‹

### Python API ä½¿ç”¨

```python
from apt_model.training.finetuner import fine_tune_model

# åŸºç¡€å¾®è°ƒ
model, tokenizer, config = fine_tune_model(
    pretrained_model_path="apt_model",
    train_data_path="finetune_data.txt",
    epochs=5,
    learning_rate=1e-5,
    save_path="apt_model_finetuned"
)

# é«˜çº§å¾®è°ƒ
model, tokenizer, config = fine_tune_model(
    pretrained_model_path="apt_model",
    train_data_path="train.txt",
    val_data_path="val.txt",
    epochs=5,
    batch_size=8,
    learning_rate=2e-5,
    freeze_embeddings=True,
    freeze_encoder_layers=2,
    freeze_decoder_layers=2,
    save_path="apt_model_finetuned",
    early_stopping_patience=3,
    eval_steps=100
)
```

### è‡ªå®šä¹‰å¾®è°ƒ

```python
from apt_model.training.finetuner import FineTuner

# åˆ›å»ºå¾®è°ƒå™¨
finetuner = FineTuner("apt_model")

# è‡ªå®šä¹‰å†»ç»“ç­–ç•¥
finetuner.freeze_layers(
    freeze_embeddings=True,
    freeze_encoder_layers=3,
    freeze_decoder_layers=3
)

# æ‰§è¡Œå¾®è°ƒ
model, tokenizer, config = finetuner.fine_tune(
    train_data_path="train.txt",
    val_data_path="val.txt",
    epochs=5,
    batch_size=8,
    learning_rate=2e-5,
    save_path="apt_model_custom"
)
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q: å¾®è°ƒéœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ
A: å–å†³äºæ•°æ®é‡å’Œç¡¬ä»¶ï¼š
- 1000æ ·æœ¬ï¼Œ5è½®ï¼šçº¦30åˆ†é’Ÿï¼ˆGPUï¼‰
- 10000æ ·æœ¬ï¼Œ5è½®ï¼šçº¦3å°æ—¶ï¼ˆGPUï¼‰
- 100000æ ·æœ¬ï¼Œ5è½®ï¼šçº¦24å°æ—¶ï¼ˆGPUï¼‰

### Q: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ
A:
1. å‡å°batch sizeï¼š`--batch-size 4`
2. å†»ç»“æ›´å¤šå±‚ï¼š`--freeze-encoder-layers 4`
3. å‡å°æ•°æ®é‡ï¼š`--max-samples 5000`

### Q: å¦‚ä½•åˆ¤æ–­å¾®è°ƒæ˜¯å¦æˆåŠŸï¼Ÿ
A: è§‚å¯Ÿä»¥ä¸‹æŒ‡æ ‡ï¼š
- è®­ç»ƒæŸå¤±ç¨³å®šä¸‹é™
- éªŒè¯æŸå¤±ä¸‹é™ï¼ˆä¸ä¸Šå‡ï¼‰
- ç”Ÿæˆæ ·æœ¬è´¨é‡æå‡
- ä»»åŠ¡æ€§èƒ½æå‡

### Q: å¾®è°ƒåæ•ˆæœä¸å¥½æ€ä¹ˆåŠï¼Ÿ
A:
1. å¢åŠ è®­ç»ƒæ•°æ®
2. è°ƒæ•´å­¦ä¹ ç‡
3. å¢åŠ è®­ç»ƒè½®æ•°
4. å‡å°‘å†»ç»“çš„å±‚æ•°
5. æ£€æŸ¥æ•°æ®è´¨é‡

### Q: å¦‚ä½•ç»§ç»­å¾®è°ƒå·²å¾®è°ƒçš„æ¨¡å‹ï¼Ÿ
A:
```bash
python -m apt_model fine-tune \
  --model-path apt_model_finetuned \  # ä½¿ç”¨å·²å¾®è°ƒçš„æ¨¡å‹
  --data-path new_data.txt \
  --save-path apt_model_finetuned_v2
```

---

## ğŸ› ï¸ æ¨¡å—åŒ–è®¾è®¡ä¼˜åŠ¿

æœ¬å¾®è°ƒæ¨¡å—å®Œå…¨åŸºäºç°æœ‰ç»„ä»¶ï¼š

```python
# å¤ç”¨çš„æ¨¡å—
from apt_model.training.checkpoint import load_model, save_model     # åŠ è½½ä¿å­˜
from apt_model.data.external_data import load_external_data         # æ•°æ®åŠ è½½
from apt_model.generation.generator import generate_natural_text    # ç”Ÿæˆ
from apt_model.generation.evaluator import evaluate_text_quality    # è¯„ä¼°
from apt_model.utils import get_device, set_seed                    # å·¥å…·
```

**å¥½å¤„**ï¼š
- âœ… ä»£ç å¤ç”¨ï¼Œå‡å°‘å·¥ä½œé‡
- âœ… ç»Ÿä¸€æ¥å£ï¼Œæ˜“äºç»´æŠ¤
- âœ… è´¨é‡ä¿è¯ï¼Œä¹…ç»è€ƒéªŒ
- âœ… æ‰©å±•æ–¹ä¾¿ï¼Œæ¨¡å—åŒ–è®¾è®¡

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [APTæ¨¡å‹è®­ç»ƒæŒ‡å—](../../README.md)
- [Optunaè¶…å‚æ•°ä¼˜åŒ–](../product/OPTUNA_GUIDE.md)
- [Debugæ¨¡å¼ä½¿ç”¨](../../apt/core/config/settings_manager.py)

---

## ğŸ“ ç¤ºä¾‹è„šæœ¬

### ç¤ºä¾‹1ï¼šå¿«é€Ÿå¾®è°ƒ
```bash
#!/bin/bash
# quick_finetune.sh

python -m apt_model fine-tune \
  --model-path apt_model \
  --data-path finetune_data.txt \
  --epochs 3 \
  --learning-rate 2e-5 \
  --save-path apt_model_quick
```

### ç¤ºä¾‹2ï¼šå®Œæ•´å¾®è°ƒ
```bash
#!/bin/bash
# full_finetune.sh

python -m apt_model fine-tune \
  --model-path apt_model \
  --data-path train.txt \
  --val-data-path val.txt \
  --epochs 5 \
  --batch-size 8 \
  --learning-rate 1e-5 \
  --freeze-embeddings \
  --freeze-encoder-layers 2 \
  --early-stopping-patience 3 \
  --eval-steps 100 \
  --save-steps 500 \
  --save-path apt_model_full
```

### ç¤ºä¾‹3ï¼šå‚æ•°é«˜æ•ˆå¾®è°ƒ
```bash
#!/bin/bash
# efficient_finetune.sh

python -m apt_model fine-tune \
  --model-path apt_model \
  --data-path small_dataset.txt \
  --epochs 10 \
  --batch-size 4 \
  --learning-rate 1e-5 \
  --freeze-embeddings \
  --freeze-encoder-layers 4 \
  --freeze-decoder-layers 4 \
  --save-path apt_model_efficient
```

---

**Happy Fine-tuning! ğŸ¯**
