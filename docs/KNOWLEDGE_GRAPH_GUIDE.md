# APTæ¨¡å‹çŸ¥è¯†å›¾è°±ä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

APTæ¨¡å‹ç°å·²é›†æˆè½»é‡çº§çŸ¥è¯†å›¾è°±ï¼ˆKnowledge Graph, KGï¼‰åŠŸèƒ½ï¼Œç»“åˆç»“æ„åŒ–çŸ¥è¯†å’Œéç»“æ„åŒ–æ–‡æ¡£ï¼Œæ˜¾è‘—æå‡ç”Ÿæˆè´¨é‡ã€‚

**æ ¸å¿ƒåŠŸèƒ½:**
- âœ… åŸºäºä¸‰å…ƒç»„çš„çŸ¥è¯†å­˜å‚¨ï¼ˆå®ä½“-å…³ç³»-å®ä½“ï¼‰
- âœ… å¿«é€Ÿæ£€ç´¢å’ŒæŸ¥è¯¢
- âœ… å¤šè·³æ¨ç†
- âœ… ä¸RAGæ— ç¼é›†æˆ
- âœ… è½»é‡çº§è®¾è®¡ï¼Œæ˜“äºä½¿ç”¨

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åˆ›å»ºçŸ¥è¯†å›¾è°±

```python
from apt_model.modeling.knowledge_graph import KnowledgeGraph

# åˆ›å»ºç©ºå›¾è°±
kg = KnowledgeGraph()

# æ·»åŠ ä¸‰å…ƒç»„
kg.add_triple("äººå·¥æ™ºèƒ½", "æ˜¯", "è®¡ç®—æœºç§‘å­¦çš„åˆ†æ”¯")
kg.add_triple("æ·±åº¦å­¦ä¹ ", "æ˜¯", "æœºå™¨å­¦ä¹ çš„å­é¢†åŸŸ")
kg.add_triple("æ·±åº¦å­¦ä¹ ", "ç”¨äº", "å›¾åƒè¯†åˆ«")

print(kg)  # KnowledgeGraph(entities=4, relations=2, triples=3)
```

### 2. ä»æ–‡ä»¶åŠ è½½

```python
from apt_model.modeling.knowledge_graph import create_kg_from_file

# æ–‡ä»¶æ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªä¸‰å…ƒç»„ï¼Œç”¨Tabåˆ†éš”ï¼‰:
# äººå·¥æ™ºèƒ½\tæ˜¯\tè®¡ç®—æœºç§‘å­¦çš„åˆ†æ”¯
# æ·±åº¦å­¦ä¹ \tæ˜¯\tæœºå™¨å­¦ä¹ çš„å­é¢†åŸŸ

kg = create_kg_from_file("knowledge.txt", separator="\t")
```

### 3. æŸ¥è¯¢çŸ¥è¯†

```python
# æŸ¥è¯¢ç»™å®šå¤´å®ä½“çš„æ‰€æœ‰å…³ç³»
triples = kg.query_by_head("æ·±åº¦å­¦ä¹ ")
for t in triples:
    print(f"{t.head} {t.relation} {t.tail}")

# è·å–é‚»å±…å®ä½“
neighbors = kg.get_neighbors("æ·±åº¦å­¦ä¹ ")
print(neighbors)  # ['æœºå™¨å­¦ä¹ çš„å­é¢†åŸŸ', 'å›¾åƒè¯†åˆ«']

# å¤šè·³æ¨ç†
paths = kg.multi_hop_query("æ·±åº¦å­¦ä¹ ", ["æ˜¯", "å±äº"])
```

---

## ğŸ’¡ æ ¸å¿ƒæ¦‚å¿µ

### ä¸‰å…ƒç»„ï¼ˆTripleï¼‰

çŸ¥è¯†å›¾è°±çš„åŸºæœ¬å•ä½ï¼š**(å¤´å®ä½“, å…³ç³», å°¾å®ä½“)**

```python
from apt_model.modeling.knowledge_graph import Triple

triple = Triple(
    head="GPT",
    relation="æ˜¯",
    tail="å¤§è¯­è¨€æ¨¡å‹",
    confidence=0.95,  # ç½®ä¿¡åº¦ï¼ˆå¯é€‰ï¼‰
    metadata={"source": "è®ºæ–‡"}  # å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰
)
```

### ç´¢å¼•ç»“æ„

çŸ¥è¯†å›¾è°±ç»´æŠ¤ä¸‰ç§ç´¢å¼•ä»¥å®ç°å¿«é€ŸæŸ¥è¯¢ï¼š

1. **head_index**: å¤´å®ä½“ â†’ ä¸‰å…ƒç»„åˆ—è¡¨
2. **relation_index**: å…³ç³» â†’ ä¸‰å…ƒç»„åˆ—è¡¨
3. **tail_index**: å°¾å®ä½“ â†’ ä¸‰å…ƒç»„åˆ—è¡¨

---

## ğŸ” æŸ¥è¯¢æ“ä½œ

### 1. åŸºç¡€æŸ¥è¯¢

```python
# æŒ‰å¤´å®ä½“æŸ¥è¯¢
triples = kg.query_by_head("äººå·¥æ™ºèƒ½")

# æŒ‰å…³ç³»æŸ¥è¯¢
triples = kg.query_by_relation("æ˜¯")

# æŒ‰å°¾å®ä½“åå‘æŸ¥è¯¢
triples = kg.query_by_tail("è®¡ç®—æœºç§‘å­¦çš„åˆ†æ”¯")

# ç»„åˆæŸ¥è¯¢ï¼ˆå¤´+å…³ç³» â†’ å°¾ï¼‰
tails = kg.query_by_head_relation("æ·±åº¦å­¦ä¹ ", "ç”¨äº")
print(tails)  # ['å›¾åƒè¯†åˆ«', ...]
```

### 2. é‚»å±…æŸ¥è¯¢

```python
# è·å–æ‰€æœ‰é‚»å±…ï¼ˆä¸é™å…³ç³»ï¼‰
neighbors = kg.get_neighbors("æ·±åº¦å­¦ä¹ ")

# è·å–ç‰¹å®šå…³ç³»çš„é‚»å±…
neighbors = kg.get_neighbors("æ·±åº¦å­¦ä¹ ", relation="æ˜¯")
```

### 3. å¤šè·³æ¨ç†

```python
# æŸ¥æ‰¾ä»"æ·±åº¦å­¦ä¹ "å‡ºå‘ï¼Œä¾æ¬¡ç»è¿‡"æ˜¯"å’Œ"ç”¨äº"å…³ç³»çš„è·¯å¾„
paths = kg.multi_hop_query(
    start_entity="æ·±åº¦å­¦ä¹ ",
    relations=["æ˜¯", "ç”¨äº"],
    max_results=10
)

for path in paths:
    print(" -> ".join(path))
# è¾“å‡º: æ·±åº¦å­¦ä¹  -> æœºå™¨å­¦ä¹  -> æ•°æ®åˆ†æ
```

### 4. è·¯å¾„æŸ¥æ‰¾

```python
# æŸ¥æ‰¾ä¸¤ä¸ªå®ä½“ä¹‹é—´çš„æ‰€æœ‰è·¯å¾„
paths = kg.find_paths(
    start="æ·±åº¦å­¦ä¹ ",
    end="äººå·¥æ™ºèƒ½",
    max_hops=3
)

for path in paths:
    for triple in path:
        print(f"  {triple.head} --[{triple.relation}]--> {triple.tail}")
```

### 5. å­å›¾æå–

```python
# æå–ä»¥ç‰¹å®šå®ä½“ä¸ºä¸­å¿ƒçš„å­å›¾
subgraph = kg.get_subgraph(
    entities=["æ·±åº¦å­¦ä¹ ", "æœºå™¨å­¦ä¹ "],
    max_hops=2
)

print(subgraph)  # KnowledgeGraph(entities=..., relations=..., triples=...)
```

---

## ğŸ¯ ä¸RAGé›†æˆ

### æ–¹æ³•1: ä½¿ç”¨KG-RAGé›†æˆæ¨¡å—

```python
from apt_model.modeling.kg_rag_integration import create_kg_rag_model
from apt_model.training.checkpoint import load_model

# åŠ è½½åŸºç¡€æ¨¡å‹
model, tokenizer, config = load_model("apt_model")

# åˆ›å»ºKG-RAGæ¨¡å‹
kg_rag_model = create_kg_rag_model(
    base_model=model,
    kg_path="knowledge.json",  # çŸ¥è¯†å›¾è°±æ–‡ä»¶
    corpus_path="documents.txt",  # æ–‡æ¡£è¯­æ–™
    fusion_method="weighted",  # èåˆæ–¹æ³•
    kg_weight=0.6,  # KGæƒé‡
    rag_weight=0.4  # RAGæƒé‡
)

# æ„å»ºç´¢å¼•
kg_triples = [
    ("æ·±åº¦å­¦ä¹ ", "æ˜¯", "æœºå™¨å­¦ä¹ çš„åˆ†æ”¯"),
    ("Transformer", "æ˜¯", "æ·±åº¦å­¦ä¹ æ¶æ„"),
    # ...
]
kg_rag_model.build_kg_index(kg_triples)

corpus = ["æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯...", "Transformeræ¨¡å‹..."]
kg_rag_model.build_rag_index(corpus)

# ä½¿ç”¨æ¨¡å‹
outputs = kg_rag_model(input_ids, attention_mask)
print("KGçŸ¥è¯†:", outputs['kg_knowledge'])
print("RAGæ–‡æ¡£:", outputs['rag_docs'])
print("èåˆä¸Šä¸‹æ–‡:", outputs['fused_context'])
```

### æ–¹æ³•2: å¿«é€Ÿåˆ›å»º

```python
from apt_model.modeling.kg_rag_integration import quick_kg_rag

# å‡†å¤‡æ•°æ®
kg_triples = [
    ("äººå·¥æ™ºèƒ½", "æ˜¯", "è®¡ç®—æœºç§‘å­¦"),
    ("æ·±åº¦å­¦ä¹ ", "æ˜¯", "æœºå™¨å­¦ä¹ "),
]

corpus = [
    "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯",
    "æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ä¸­è¡¨ç°å‡ºè‰²"
]

# å¿«é€Ÿåˆ›å»º
model = quick_kg_rag(
    model=base_model,
    kg_triples=kg_triples,
    corpus=corpus
)
```

---

## ğŸ“Š å­˜å‚¨å’ŒåŠ è½½

### ä¿å­˜çŸ¥è¯†å›¾è°±

```python
# ä¿å­˜ä¸ºJSONï¼ˆå¯è¯»ï¼‰
kg.save("knowledge.json")

# ä¿å­˜ä¸ºPickleï¼ˆæ›´å¿«ï¼‰
kg.save("knowledge.pkl")
```

**JSONæ ¼å¼ç¤ºä¾‹:**
```json
{
  "triples": [
    {
      "head": "äººå·¥æ™ºèƒ½",
      "relation": "æ˜¯",
      "tail": "è®¡ç®—æœºç§‘å­¦çš„åˆ†æ”¯",
      "confidence": 1.0,
      "metadata": null
    }
  ],
  "entities": ["äººå·¥æ™ºèƒ½", "è®¡ç®—æœºç§‘å­¦çš„åˆ†æ”¯"],
  "relations": ["æ˜¯"]
}
```

### åŠ è½½çŸ¥è¯†å›¾è°±

```python
from apt_model.modeling.knowledge_graph import KnowledgeGraph

# ä»æ–‡ä»¶åŠ è½½
kg = KnowledgeGraph.load("knowledge.json")

# æˆ–
kg = KnowledgeGraph.load("knowledge.pkl")
```

---

## ğŸ”§ é«˜çº§åŠŸèƒ½

### 1. æ‰¹é‡æ·»åŠ ä¸‰å…ƒç»„

```python
triples = [
    ("A", "å…³ç³»1", "B"),
    ("B", "å…³ç³»2", "C"),
    ("C", "å…³ç³»3", "D", 0.9),  # å¸¦ç½®ä¿¡åº¦
]

kg.add_triples_batch(triples)
```

### 2. è½¬æ¢ä¸ºæ–‡æœ¬

```python
# è‡ªç„¶è¯­è¨€æ ¼å¼
text = kg.to_text(format='natural')
print(text)
# è¾“å‡º:
# äººå·¥æ™ºèƒ½ æ˜¯ è®¡ç®—æœºç§‘å­¦çš„åˆ†æ”¯
# æ·±åº¦å­¦ä¹  æ˜¯ æœºå™¨å­¦ä¹ çš„å­é¢†åŸŸ

# ç»“æ„åŒ–æ ¼å¼
text = kg.to_text(format='structured')
print(text)
# è¾“å‡º:
# (äººå·¥æ™ºèƒ½, æ˜¯, è®¡ç®—æœºç§‘å­¦çš„åˆ†æ”¯)
# (æ·±åº¦å­¦ä¹ , æ˜¯, æœºå™¨å­¦ä¹ çš„å­é¢†åŸŸ)
```

### 3. ç»Ÿè®¡ä¿¡æ¯

```python
stats = kg.stats()
print(stats)
# {
#   'num_entities': 10,
#   'num_relations': 5,
#   'num_triples': 20,
#   'avg_degree': 4.0,
#   'relations_list': ['æ˜¯', 'æœ‰', 'ç”¨äº', ...]
# }
```

### 4. ä»æ–‡æœ¬æå–ä¸‰å…ƒç»„

```python
from apt_model.modeling.knowledge_graph import extract_triples_from_text

text = "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„å­é¢†åŸŸã€‚Transformeræ˜¯æ·±åº¦å­¦ä¹ æ¶æ„ã€‚"
triples = extract_triples_from_text(text)

for triple in triples:
    print(triple)
# ('æ·±åº¦å­¦ä¹ ', 'æ˜¯', 'æœºå™¨å­¦ä¹ çš„å­é¢†åŸŸ')
# ('Transformer', 'æ˜¯', 'æ·±åº¦å­¦ä¹ æ¶æ„')
```

**æ³¨æ„**: è¿™æ˜¯åŸºäºè§„åˆ™çš„ç®€å•æå–ï¼Œå¤æ‚åœºæ™¯å»ºè®®ä½¿ç”¨ä¸“é—¨çš„ä¿¡æ¯æŠ½å–æ¨¡å‹ã€‚

---

## ğŸ¨ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: é¢†åŸŸçŸ¥è¯†å¢å¼º

```python
# åŒ»ç–—é¢†åŸŸçŸ¥è¯†å›¾è°±
medical_kg = KnowledgeGraph()
medical_kg.add_triple("é˜¿å¸åŒ¹æ—", "ç”¨äºæ²»ç–—", "å¤´ç—›")
medical_kg.add_triple("é˜¿å¸åŒ¹æ—", "å±äº", "éç”¾ä½“æŠ—ç‚è¯")
medical_kg.add_triple("å¤´ç—›", "æ˜¯", "ç¥ç»ç³»ç»Ÿç—‡çŠ¶")

# æŸ¥è¯¢è¯ç‰©ç›¸å…³çŸ¥è¯†
treatments = medical_kg.query_by_relation("ç”¨äºæ²»ç–—")
```

### åœºæ™¯2: é—®ç­”ç³»ç»Ÿ

```python
# ç”¨æˆ·é—®é¢˜: "æ·±åº¦å­¦ä¹ å¯ä»¥ç”¨äºä»€ä¹ˆï¼Ÿ"
# 1. æå–å®ä½“: "æ·±åº¦å­¦ä¹ "
# 2. æŸ¥è¯¢KG
applications = kg.query_by_head_relation("æ·±åº¦å­¦ä¹ ", "ç”¨äº")
print("æ·±åº¦å­¦ä¹ å¯ä»¥ç”¨äº:", ", ".join(applications))
```

### åœºæ™¯3: æ¨ç†å¢å¼º

```python
# å¤šè·³æ¨ç†: "ä»€ä¹ˆæŠ€æœ¯å±äºäººå·¥æ™ºèƒ½å¹¶ä¸”ç”¨äºå›¾åƒè¯†åˆ«ï¼Ÿ"

# æ‰¾åˆ°å±äºäººå·¥æ™ºèƒ½çš„æŠ€æœ¯
ai_techs = kg.query_by_relation_tail("å±äº", "äººå·¥æ™ºèƒ½")

# ç­›é€‰ç”¨äºå›¾åƒè¯†åˆ«çš„
for tech in ai_techs:
    uses = kg.query_by_head_relation(tech, "ç”¨äº")
    if "å›¾åƒè¯†åˆ«" in uses:
        print(f"{tech} å±äºäººå·¥æ™ºèƒ½ä¸”ç”¨äºå›¾åƒè¯†åˆ«")
```

### åœºæ™¯4: çŸ¥è¯†è¡¥å…¨

```python
# æ¨æ–­ç¼ºå¤±çš„å…³ç³»
# å·²çŸ¥: A -> B, B -> C
# æ¨æ–­: A -> C (ä¼ é€’å…³ç³»)

paths = kg.find_paths("A", "C", max_hops=2)
if paths:
    print("å­˜åœ¨é—´æ¥å…³ç³»ï¼Œå¯ä»¥è¡¥å…¨")
```

---

## ğŸ“š æ•°æ®æ ¼å¼

### ä¸‰å…ƒç»„æ–‡ä»¶æ ¼å¼

```
# æ ¼å¼: å¤´å®ä½“<Tab>å…³ç³»<Tab>å°¾å®ä½“
äººå·¥æ™ºèƒ½	æ˜¯	è®¡ç®—æœºç§‘å­¦çš„åˆ†æ”¯
æ·±åº¦å­¦ä¹ 	æ˜¯	æœºå™¨å­¦ä¹ çš„å­é¢†åŸŸ
æ·±åº¦å­¦ä¹ 	ç”¨äº	å›¾åƒè¯†åˆ«
Transformer	æ˜¯	æ·±åº¦å­¦ä¹ æ¶æ„
BERT	åŸºäº	Transformer
BERT	ç”¨äº	è‡ªç„¶è¯­è¨€å¤„ç†
```

### JSONæ ¼å¼

```json
{
  "triples": [
    {
      "head": "äººå·¥æ™ºèƒ½",
      "relation": "æ˜¯",
      "tail": "è®¡ç®—æœºç§‘å­¦çš„åˆ†æ”¯",
      "confidence": 1.0,
      "metadata": {"source": "æ•™ç§‘ä¹¦"}
    }
  ]
}
```

---

## ğŸ› ï¸ APIå‚è€ƒ

### KnowledgeGraph ç±»

**åˆå§‹åŒ–:**
```python
kg = KnowledgeGraph()
```

**ä¸»è¦æ–¹æ³•:**

| æ–¹æ³• | è¯´æ˜ |
|------|------|
| `add_triple(head, relation, tail, confidence, metadata)` | æ·»åŠ ä¸‰å…ƒç»„ |
| `add_triples_batch(triples)` | æ‰¹é‡æ·»åŠ  |
| `query_by_head(head)` | æŒ‰å¤´å®ä½“æŸ¥è¯¢ |
| `query_by_relation(relation)` | æŒ‰å…³ç³»æŸ¥è¯¢ |
| `query_by_tail(tail)` | æŒ‰å°¾å®ä½“æŸ¥è¯¢ |
| `get_neighbors(entity, relation)` | è·å–é‚»å±… |
| `multi_hop_query(start, relations, max_results)` | å¤šè·³æŸ¥è¯¢ |
| `find_paths(start, end, max_hops)` | è·¯å¾„æŸ¥æ‰¾ |
| `get_subgraph(entities, max_hops)` | æå–å­å›¾ |
| `save(filepath)` | ä¿å­˜åˆ°æ–‡ä»¶ |
| `load(filepath)` | ä»æ–‡ä»¶åŠ è½½ï¼ˆé™æ€æ–¹æ³•ï¼‰ |
| `stats()` | è·å–ç»Ÿè®¡ä¿¡æ¯ |

### KGRAGWrapper ç±»

**åˆ›å»º:**
```python
from apt_model.modeling.kg_rag_integration import create_kg_rag_model

model = create_kg_rag_model(
    base_model=model,
    kg_path="kg.json",
    corpus_path="docs.txt",
    fusion_method="weighted"
)
```

**ä¸»è¦æ–¹æ³•:**

| æ–¹æ³• | è¯´æ˜ |
|------|------|
| `build_kg_index(triples)` | æ„å»ºKGç´¢å¼• |
| `build_rag_index(corpus, embedding_model)` | æ„å»ºRAGç´¢å¼• |
| `retrieve(query, use_kg, use_rag)` | æ£€ç´¢çŸ¥è¯† |
| `forward(input_ids, attention_mask, ...)` | å‰å‘ä¼ æ’­ |

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. è§„æ¨¡é™åˆ¶

è½»é‡çº§KGé€‚åˆï¼š
- âœ… å®ä½“æ•°: < 100,000
- âœ… ä¸‰å…ƒç»„æ•°: < 1,000,000
- âœ… å†…å­˜å ç”¨: ~100MB-1GB

**å¤§è§„æ¨¡å›¾è°±å»ºè®®ä½¿ç”¨ä¸“ä¸šå›¾æ•°æ®åº“ï¼ˆNeo4j, ArangoDBç­‰ï¼‰**

### 2. æ€§èƒ½ä¼˜åŒ–

```python
# æ‰¹é‡æ·»åŠ æ¯”é€ä¸ªæ·»åŠ å¿«å¾—å¤š
kg.add_triples_batch(triples)  # âœ… æ¨è

for triple in triples:  # âŒ é¿å…
    kg.add_triple(*triple)
```

### 3. æŸ¥è¯¢ä¼˜åŒ–

```python
# ä½¿ç”¨ç´¢å¼•æŸ¥è¯¢ï¼ˆå¿«ï¼‰
triples = kg.query_by_head("å®ä½“")  # O(1)

# éå†æ‰€æœ‰ä¸‰å…ƒç»„ï¼ˆæ…¢ï¼‰
triples = [t for t in kg.triples if t.head == "å®ä½“"]  # O(n)
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. è®¾è®¡é«˜è´¨é‡çš„çŸ¥è¯†å›¾è°±

- âœ… ä½¿ç”¨ä¸€è‡´çš„å‘½åè§„èŒƒ
- âœ… å…³ç³»åç§°åº”æ¸…æ™°æ˜ç¡®
- âœ… æ·»åŠ ç½®ä¿¡åº¦å’Œæ¥æºä¿¡æ¯
- âœ… å®šæœŸæ¸…ç†å’Œæ›´æ–°

### 2. KGä¸RAGçš„æƒè¡¡

**ä½¿ç”¨KGçš„åœºæ™¯:**
- éœ€è¦ç²¾ç¡®çš„å®ä½“å…³ç³»
- éœ€è¦å¤šè·³æ¨ç†
- çŸ¥è¯†ç›¸å¯¹ç»“æ„åŒ–

**ä½¿ç”¨RAGçš„åœºæ™¯:**
- éœ€è¦ä¸°å¯Œçš„ä¸Šä¸‹æ–‡
- çŸ¥è¯†ä»¥è‡ªç„¶è¯­è¨€å½¢å¼å­˜åœ¨
- éœ€è¦çµæ´»æ€§

**KG+RAGèåˆ:**
- æœ€ä½³é€‰æ‹©ï¼šç»“åˆä¸¤è€…ä¼˜åŠ¿
- KGæä¾›ç»“æ„åŒ–éª¨æ¶
- RAGæä¾›è¯¦ç»†å†…å®¹

### 3. èåˆæ–¹æ³•é€‰æ‹©

| æ–¹æ³• | é€‚ç”¨åœºæ™¯ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|----------|------|------|
| `concatenate` | ç®€å•åœºæ™¯ | ç®€å•ç›´æ¥ | å¯èƒ½å†—é•¿ |
| `weighted` | é€šç”¨åœºæ™¯ | å¹³è¡¡ä¸¤è€… | éœ€è°ƒæ•´æƒé‡ |
| `gate` | å¤æ‚åœºæ™¯ | è‡ªé€‚åº” | è®¡ç®—å¼€é”€å¤§ |

---

## ğŸ”¬ ç¤ºä¾‹ä»£ç 

### å®Œæ•´ç¤ºä¾‹: æ„å»ºåŒ»ç–—çŸ¥è¯†é—®ç­”ç³»ç»Ÿ

```python
from apt_model.modeling.knowledge_graph import KnowledgeGraph
from apt_model.modeling.kg_rag_integration import create_kg_rag_model
from apt_model.training.checkpoint import load_model

# 1. åˆ›å»ºåŒ»ç–—çŸ¥è¯†å›¾è°±
medical_kg = KnowledgeGraph()

medical_triples = [
    ("æ„Ÿå†’", "ç—‡çŠ¶åŒ…æ‹¬", "å‘çƒ­"),
    ("æ„Ÿå†’", "ç—‡çŠ¶åŒ…æ‹¬", "å’³å—½"),
    ("æ„Ÿå†’", "å¯ç”¨è¯", "å¯¹ä¹™é…°æ°¨åŸºé…š"),
    ("å¯¹ä¹™é…°æ°¨åŸºé…š", "ç”¨äº", "é€€çƒ­"),
    ("å¯¹ä¹™é…°æ°¨åŸºé…š", "ç”¨äº", "æ­¢ç—›"),
]

medical_kg.add_triples_batch(medical_triples)
medical_kg.save("medical_kg.json")

# 2. å‡†å¤‡åŒ»ç–—æ–‡æ¡£è¯­æ–™
medical_docs = [
    "æ„Ÿå†’æ˜¯ä¸€ç§å¸¸è§çš„å‘¼å¸é“ç–¾ç—…ï¼Œä¸»è¦ç—‡çŠ¶åŒ…æ‹¬å‘çƒ­ã€å’³å—½ã€æµé¼»æ¶•ç­‰ã€‚",
    "å¯¹ä¹™é…°æ°¨åŸºé…šæ˜¯ä¸€ç§å¸¸ç”¨çš„è§£çƒ­é•‡ç—›è¯ï¼Œç”¨äºç¼“è§£æ„Ÿå†’å¼•èµ·çš„å‘çƒ­å’Œå¤´ç—›ã€‚",
    "æ²»ç–—æ„Ÿå†’åº”æ³¨æ„å¤šä¼‘æ¯ã€å¤šå–æ°´ï¼Œå¿…è¦æ—¶å¯æœç”¨é€€çƒ­è¯ç‰©ã€‚"
]

# 3. åŠ è½½æ¨¡å‹å¹¶åˆ›å»ºKG-RAGç³»ç»Ÿ
base_model, tokenizer, config = load_model("apt_model")

kg_rag_model = create_kg_rag_model(
    base_model=base_model,
    kg=medical_kg,
    corpus=medical_docs,
    fusion_method="weighted",
    kg_weight=0.7,  # KGæƒé‡é«˜ä¸€äº›ï¼Œå› ä¸ºåŒ»ç–—çŸ¥è¯†éœ€è¦ç²¾ç¡®æ€§
    rag_weight=0.3
)

# 4. é—®ç­”
question = "æ„Ÿå†’æœ‰å“ªäº›ç—‡çŠ¶ï¼Ÿ"
# ç¼–ç é—®é¢˜ã€æ£€ç´¢çŸ¥è¯†ã€ç”Ÿæˆç­”æ¡ˆ...
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

- **å®Œæ•´æ–‡æ¡£**: [README.md](./README.md)
- **RAGæŒ‡å—**: [rag_integration.py](apt_model/modeling/rag_integration.py)
- **é—®é¢˜åé¦ˆ**: GitHub Issues

---

## ğŸ“ å‚è€ƒèµ„æ–™

- [Knowledge GraphåŸºç¡€](https://en.wikipedia.org/wiki/Knowledge_graph)
- [RAGè®ºæ–‡](https://arxiv.org/abs/2005.11401)
- [Neo4jå›¾æ•°æ®åº“](https://neo4j.com/)

---

**Happy Knowledge Graphing! ğŸš€**
