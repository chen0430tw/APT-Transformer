# APT Model ä½¿ç”¨æ‰‹å†Œ

**APT Model (è‡ªç”Ÿæˆå˜æ¢å™¨)** - ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„PyTorch Transformerè®­ç»ƒå¹³å°

---

## ğŸ“‘ ç›®å½•

1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [å®‰è£…å’Œé…ç½®](#å®‰è£…å’Œé…ç½®)
3. [æ ¸å¿ƒåŠŸèƒ½](#æ ¸å¿ƒåŠŸèƒ½)
4. [WebUIå’ŒAPI](#webuiå’Œapi)
5. [è®­ç»ƒæ¨¡å‹](#è®­ç»ƒæ¨¡å‹)
6. [æ’ä»¶ç³»ç»Ÿ](#æ’ä»¶ç³»ç»Ÿ)
7. [é«˜çº§åŠŸèƒ½](#é«˜çº§åŠŸèƒ½)
8. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

---

## å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# éªŒè¯torchå®‰è£…
python -c "import torch; print(torch.__version__)"

# å¯é€‰ï¼šä¸‹è½½NLPèµ„æºï¼ˆç¦»çº¿ç¯å¢ƒå¯è·³è¿‡ï¼‰
python scripts/download_optional_assets.py

# è¿è¡Œæµ‹è¯•
pytest tests/test_smoke.py
```

### 5åˆ†é’Ÿä¸Šæ‰‹

```bash
# 1. å¯åŠ¨WebUIï¼ˆæ¨èæ–°æ‰‹ï¼‰
python -m apt_model.webui.app --checkpoint-dir ./checkpoints

# 2. æ‰“å¼€æµè§ˆå™¨è®¿é—®
# http://localhost:7860

# 3. æˆ–è€…ä½¿ç”¨API
python -m apt_model.api.server --checkpoint-dir ./checkpoints
# è®¿é—®APIæ–‡æ¡£: http://localhost:8000/docs
```

---

## å®‰è£…å’Œé…ç½®

### ç³»ç»Ÿè¦æ±‚

- **Python**: 3.8+
- **PyTorch**: 1.10+ (æ”¯æŒCPUå’ŒGPU)
- **å†…å­˜**: æœ€ä½4GBï¼Œæ¨è8GB+
- **ç£ç›˜**: 2GB+ (åŒ…å«æ¨¡å‹å’Œæ•°æ®)

### å¯é€‰ä¾èµ–

```bash
# Transformer tokenizerå’ŒNLPå·¥å…·
pip install transformers scikit-learn

# WebUIæ”¯æŒ
pip install gradio

# APIæ”¯æŒ
pip install fastapi uvicorn

# åˆ†å¸ƒå¼è®­ç»ƒ
pip install torch.distributed

# å¯è§†åŒ–
pip install tensorboard matplotlib
```

### ç¦»çº¿ç¯å¢ƒ

é¡¹ç›®æ”¯æŒå®Œå…¨ç¦»çº¿è¿è¡Œï¼Œä¼šè‡ªåŠ¨é™çº§åˆ°æœ¬åœ°èµ„æºï¼š
- Tokenizerä½¿ç”¨å†…ç½®ä¸­æ–‡è¯è¡¨
- è·³è¿‡å¯é€‰ä¾èµ–çš„åŠŸèƒ½
- æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ä¿æŒå¯ç”¨

---

## æ ¸å¿ƒåŠŸèƒ½

### 1. æ¨¡å‹è®­ç»ƒ

```python
from apt_model.training.trainer import train_model

# åŸºç¡€è®­ç»ƒ
model, tokenizer, config = train_model(
    epochs=20,
    batch_size=8,
    learning_rate=3e-5,
    save_path="./my_model"
)
```

### 2. æ–‡æœ¬ç”Ÿæˆ

```python
from apt_model.generation.generator import generate_natural_text

# ç”Ÿæˆæ–‡æœ¬
text, tokens, logits, confidence = generate_natural_text(
    model,
    tokenizer,
    prompt="äººå·¥æ™ºèƒ½",
    max_steps=50,
    temperature=0.8
)
```

### 3. æ¨¡å‹è¯„ä¼°

```python
from apt_model.generation.evaluator import evaluate_text_quality

# è¯„ä¼°æ–‡æœ¬è´¨é‡
score, feedback = evaluate_text_quality(generated_text)
print(f"è´¨é‡è¯„åˆ†: {score}/100 - {feedback}")
```

---

## WebUIå’ŒAPI

### WebUIåŠŸèƒ½

å¯åŠ¨WebUIåå¯ä»¥è®¿é—®4ä¸ªåŠŸèƒ½Tabï¼š

1. **è®­ç»ƒç›‘æ§**: å®æ—¶losså’Œå­¦ä¹ ç‡æ›²çº¿
2. **æ¢¯åº¦ç›‘æ§**: æ¢¯åº¦æµåˆ†æå’Œå¼‚å¸¸æ£€æµ‹
3. **Checkpointç®¡ç†**: åŠ è½½å’Œç®¡ç†æ¨¡å‹æ£€æŸ¥ç‚¹
4. **æ¨ç†æµ‹è¯•**: äº¤äº’å¼æ–‡æœ¬ç”Ÿæˆ

**å¯åŠ¨å‘½ä»¤**:
```bash
# åŸºç¡€å¯åŠ¨
python -m apt_model.webui.app --checkpoint-dir ./checkpoints

# å¸¦è®¤è¯
python -m apt_model.webui.app \
  --checkpoint-dir ./checkpoints \
  --username admin \
  --password your_password
```

### REST API

**10+ APIç«¯ç‚¹**:

| ç«¯ç‚¹ | æ–¹æ³• | åŠŸèƒ½ |
|------|------|------|
| `/api/generate` | POST | å•æ¡æ–‡æœ¬ç”Ÿæˆ |
| `/api/batch_generate` | POST | æ‰¹é‡æ–‡æœ¬ç”Ÿæˆ |
| `/api/training/status` | GET | è®­ç»ƒçŠ¶æ€æŸ¥è¯¢ |
| `/api/training/gradients` | GET | æ¢¯åº¦ä¿¡æ¯ |
| `/api/checkpoints` | GET | Checkpointåˆ—è¡¨ |
| `/api/checkpoints/load` | POST | åŠ è½½Checkpoint |
| `/api/compression/methods` | GET | å¯ç”¨å‹ç¼©æ–¹æ³• |
| `/api/compression/apply` | POST | åº”ç”¨å‹ç¼© |

**å¯åŠ¨å‘½ä»¤**:
```bash
python -m apt_model.api.server --checkpoint-dir ./checkpoints
```

**ä½¿ç”¨ç¤ºä¾‹**:
```bash
# æ–‡æœ¬ç”Ÿæˆ
curl -X POST http://localhost:8000/api/generate \
  -H "X-API-Key: YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "ä½ å¥½", "max_length": 50}'
```

**APIå¯†é’¥**: å¯åŠ¨æ—¶è‡ªåŠ¨ç”Ÿæˆå¹¶æ˜¾ç¤ºåœ¨æ§åˆ¶å°ï¼Œè¯·ä¿å­˜å¥½

---

## è®­ç»ƒæ¨¡å‹

### åŸºç¡€è®­ç»ƒ

```python
from apt_model.training.trainer import train_model

model, tokenizer, config = train_model(
    epochs=20,              # è®­ç»ƒè½®æ•°
    batch_size=8,           # æ‰¹æ¬¡å¤§å°
    learning_rate=3e-5,     # å­¦ä¹ ç‡
    save_path="./model",    # ä¿å­˜è·¯å¾„
    texts=train_texts       # è®­ç»ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰
)
```

### åˆ†å¸ƒå¼è®­ç»ƒ

```bash
# å•æœºå¤šå¡ï¼ˆ4 GPUï¼‰
bash scripts/launch_distributed.sh \
  --num-gpus 4 \
  --batch-size 32 \
  --data-path ./data

# å¤šèŠ‚ç‚¹è®­ç»ƒ
# èŠ‚ç‚¹0 (master)
bash scripts/launch_distributed.sh \
  --num-gpus 4 \
  --num-nodes 2 \
  --node-rank 0 \
  --master-addr 192.168.1.100

# èŠ‚ç‚¹1 (worker)
bash scripts/launch_distributed.sh \
  --num-gpus 4 \
  --num-nodes 2 \
  --node-rank 1 \
  --master-addr 192.168.1.100
```

### Checkpointç®¡ç†

**åŸå­æ€§ä¿å­˜**ï¼ˆé˜²æ­¢checkpointæŸåï¼‰:
```python
from apt_model.training.checkpoint import CheckpointManager

# åˆ›å»ºç®¡ç†å™¨
mgr = CheckpointManager(
    save_dir="./checkpoints",
    model_name="apt_model",
    max_checkpoints=5
)

# ä¿å­˜checkpointï¼ˆä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ä¿è¯åŸå­æ€§ï¼‰
mgr.save_checkpoint(
    model=model,
    optimizer=optimizer,
    epoch=10,
    metrics={'loss': 0.5, 'accuracy': 0.9}
)

# åŠ è½½checkpoint
checkpoint = mgr.load_checkpoint("checkpoint_epoch_10.pt")
model.load_state_dict(checkpoint['model_state_dict'])
```

---

## æ’ä»¶ç³»ç»Ÿ

APT Modelæ‹¥æœ‰å®Œæ•´çš„æ’ä»¶ç”Ÿæ€ç³»ç»Ÿï¼Œæ”¯æŒåŠ¨æ€æ‰©å±•åŠŸèƒ½ã€‚

### å¯ç”¨æ’ä»¶

**ç”Ÿäº§å°±ç»ªæ’ä»¶** (6ä¸ª):
- `BeamSearchPlugin` - Beamæœç´¢è§£ç 
- `ProgramAidedPlugin` - ç¨‹åºè¾…åŠ©æ¨ç†
- `IterativeRefinementPlugin` - è¿­ä»£ä¼˜åŒ–
- `SelfConsistencyPlugin` - è‡ªæ´½æ€§éªŒè¯
- `MultiModalPlugin` - å¤šæ¨¡æ€æ”¯æŒ
- `CompressionPlugin` - æ¨¡å‹å‹ç¼©

**å·¥å…·ç±»æ’ä»¶** (4ä¸ª):
- `GradientMonitor` - æ¢¯åº¦ç›‘æ§
- `VersionManager` - ç‰ˆæœ¬ç®¡ç†
- `ErrorPersistence` - é”™è¯¯æŒä¹…åŒ–
- `ProgressTracking` - è¿›åº¦è¿½è¸ª

### ä½¿ç”¨æ’ä»¶

```python
# ç¤ºä¾‹ï¼šä½¿ç”¨å‹ç¼©æ’ä»¶
from apt_model.plugins.compression_plugin import CompressionPlugin

plugin = CompressionPlugin()

# å¯ç”¨DBCè®­ç»ƒåŠ é€Ÿï¼ˆ20-30%é€Ÿåº¦æå‡ï¼‰
model, optimizer = plugin.enable_dbc_training(
    model=model,
    rank_ratio=0.5,
    apply_to_gradients=True
)

# åº”ç”¨æ¨¡å‹å‹ç¼©
compressed_model = plugin.compress(
    model=model,
    method='quantization',
    params={'bits': 8}
)
```

### å¼€å‘è‡ªå®šä¹‰æ’ä»¶

```python
from apt_model.plugins.base import PluginBase, PluginManifest

class MyPlugin(PluginBase):
    def get_manifest(self) -> PluginManifest:
        return PluginManifest(
            name="my_plugin",
            version="1.0.0",
            description="My custom plugin",
            author="Your Name"
        )

    def on_load(self):
        print("Plugin loaded!")

    def process(self, text: str) -> str:
        # ä½ çš„å¤„ç†é€»è¾‘
        return text.upper()

# ä½¿ç”¨æ’ä»¶
plugin = MyPlugin()
result = plugin.process("hello world")
```

---

## é«˜çº§åŠŸèƒ½

### 1. æ¨¡å‹å‹ç¼©

**5ç§å‹ç¼©æ–¹æ³•**:

```python
from apt_model.plugins.compression_plugin import CompressionPlugin

plugin = CompressionPlugin()

# æ–¹æ³•1: å‰ªæ (Pruning)
compressed = plugin.compress(
    model, method='pruning',
    params={'sparsity': 0.3}
)

# æ–¹æ³•2: é‡åŒ– (Quantization)
compressed = plugin.compress(
    model, method='quantization',
    params={'bits': 8}
)

# æ–¹æ³•3: çŸ¥è¯†è’¸é¦ (Distillation)
compressed = plugin.compress(
    model, method='distillation',
    params={'teacher': teacher_model, 'temperature': 2.0}
)

# æ–¹æ³•4: ä½ç§©åˆ†è§£ (Low-Rank)
compressed = plugin.compress(
    model, method='low_rank',
    params={'rank': 64}
)

# æ–¹æ³•5: DBCè®­ç»ƒåŠ é€Ÿ (æ¨è)
model, optimizer = plugin.enable_dbc_training(
    model, rank_ratio=0.5, apply_to_gradients=True
)
# è®­ç»ƒé€Ÿåº¦æå‡20-30%ï¼
```

### 2. æ¢¯åº¦ç›‘æ§

```python
from apt_model.training.gradient_monitor import GradientMonitor

# åˆ›å»ºç›‘æ§å™¨
monitor = GradientMonitor()

# åœ¨è®­ç»ƒå¾ªç¯ä¸­è®°å½•æ¢¯åº¦
for step, batch in enumerate(dataloader):
    loss.backward()

    # è®°å½•æ¢¯åº¦
    monitor.record_gradients(model, step)

    # æ£€æµ‹å¼‚å¸¸
    anomalies = monitor.detect_anomalies(step)
    if anomalies:
        print(f"æ£€æµ‹åˆ°æ¢¯åº¦å¼‚å¸¸: {anomalies}")

    optimizer.step()

# å¯¼å‡ºæ•°æ®ä¾›WebUIä½¿ç”¨
webui_data = monitor.export_for_webui()
```

### 3. è®­ç»ƒäº‹ä»¶ç³»ç»Ÿ

```python
from apt_model.training.training_events import TrainingEventBus

# åˆ›å»ºäº‹ä»¶æ€»çº¿
event_bus = TrainingEventBus()

# è®¢é˜…äº‹ä»¶
def on_epoch_end(epoch, metrics):
    print(f"Epoch {epoch} ç»“æŸï¼ŒæŒ‡æ ‡: {metrics}")

event_bus.subscribe('epoch_end', on_epoch_end)

# è®­ç»ƒæ—¶ä¼šè‡ªåŠ¨è§¦å‘äº‹ä»¶
# WebUIå¯ä»¥å®æ—¶æ¥æ”¶è¿™äº›äº‹ä»¶
```

### 4. å¤šè¯­è¨€æ”¯æŒ

æ”¯æŒä¸­æ–‡ã€è‹±æ–‡å’Œå¤šè¯­è¨€æ··åˆè®­ç»ƒï¼š

```python
# è‡ªåŠ¨æ£€æµ‹è¯­è¨€
from apt_model.modeling.chinese_tokenizer_integration import get_appropriate_tokenizer

tokenizer, language = get_appropriate_tokenizer(
    texts=train_texts,
    tokenizer_type=None,  # è‡ªåŠ¨é€‰æ‹©
    language=None         # è‡ªåŠ¨æ£€æµ‹
)

print(f"æ£€æµ‹åˆ°è¯­è¨€: {language}")
# è¾“å‡º: æ£€æµ‹åˆ°è¯­è¨€: zh æˆ– en
```

---

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**1. ModuleNotFoundError: No module named 'torch'**

```bash
pip install torch
# æˆ–è€…
pip install torch torchvision torchaudio
```

**2. WebUIæ— æ³•å¯åŠ¨**

```bash
# å®‰è£…gradio
pip install gradio

# æˆ–ä½¿ç”¨APIä»£æ›¿
python -m apt_model.api.server
```

**3. APIå¯†é’¥ä¸¢å¤±**

é‡å¯APIæœåŠ¡å™¨ä¼šé‡æ–°ç”Ÿæˆå¯†é’¥ï¼Œæˆ–è€…ä½¿ç”¨è‡ªå®šä¹‰å¯†é’¥ï¼š
```bash
python -m apt_model.api.server --api-key "your-secret-key"
```

**4. CheckpointåŠ è½½å¤±è´¥**

æ£€æŸ¥checkpointæ˜¯å¦æŸåï¼š
```python
import torch
checkpoint = torch.load("checkpoint.pt")
# å¦‚æœæŠ¥é”™è¯´æ˜æ–‡ä»¶æŸå
```

é¡¹ç›®ä½¿ç”¨åŸå­æ€§ä¿å­˜æœºåˆ¶ï¼Œæ­£å¸¸æƒ…å†µä¸‹checkpointä¸ä¼šæŸåã€‚

**5. è®­ç»ƒé€Ÿåº¦æ…¢**

```python
# ä½¿ç”¨DBCè®­ç»ƒåŠ é€Ÿ
from apt_model.plugins.compression_plugin import CompressionPlugin
plugin = CompressionPlugin()
model, optimizer = plugin.enable_dbc_training(model, rank_ratio=0.5)
# é€Ÿåº¦æå‡20-30%

# ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()

# ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒ
bash scripts/launch_distributed.sh --num-gpus 4
```

**6. å†…å­˜ä¸è¶³**

```python
# å‡å°batch size
train_model(batch_size=4)  # é»˜è®¤æ˜¯8

# å¯ç”¨æ¢¯åº¦ç´¯ç§¯
# åœ¨trainer.pyä¸­ï¼Œaccumulation_steps = 4

# ä½¿ç”¨æ¢¯åº¦checkpoint
model.gradient_checkpointing_enable()
```

### è·å–å¸®åŠ©

1. **æŸ¥çœ‹æ—¥å¿—**: è®­ç»ƒæ—¥å¿—ä¿å­˜åœ¨ `apt_model/log/`
2. **APIæ–‡æ¡£**: http://localhost:8000/docs
3. **æ’ä»¶æ–‡æ¡£**: æŸ¥çœ‹ `apt_model/plugins/README.md`
4. **Issueè¿½è¸ª**: GitHub Issues

---

## é¡¹ç›®ç»“æ„

```
apt_model/
â”œâ”€â”€ config/              # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ apt_config.py
â”‚   â””â”€â”€ multimodal_config.py
â”œâ”€â”€ modeling/            # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ apt_model.py
â”‚   â””â”€â”€ multimodal_model.py
â”œâ”€â”€ training/            # è®­ç»ƒç›¸å…³
â”‚   â”œâ”€â”€ trainer.py
â”‚   â”œâ”€â”€ checkpoint.py
â”‚   â”œâ”€â”€ optimizer.py
â”‚   â””â”€â”€ gradient_monitor.py
â”œâ”€â”€ generation/          # ç”Ÿæˆå’Œæ¨ç†
â”‚   â”œâ”€â”€ generator.py
â”‚   â””â”€â”€ evaluator.py
â”œâ”€â”€ plugins/             # æ’ä»¶ç³»ç»Ÿ
â”‚   â”œâ”€â”€ base.py
â”‚   â”œâ”€â”€ compression_plugin.py
â”‚   â””â”€â”€ version_manager.py
â”œâ”€â”€ api/                 # REST API
â”‚   â””â”€â”€ server.py
â”œâ”€â”€ webui/               # Webç•Œé¢
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ utils/               # å·¥å…·å‡½æ•°
â””â”€â”€ cli/                 # å‘½ä»¤è¡Œå·¥å…·
```

---

## å¿«é€Ÿå‚è€ƒ

### å¸¸ç”¨å‘½ä»¤

```bash
# è®­ç»ƒ
python -m apt_model.training.trainer

# WebUI
python -m apt_model.webui.app --checkpoint-dir ./checkpoints

# API
python -m apt_model.api.server --checkpoint-dir ./checkpoints

# åˆ†å¸ƒå¼
bash scripts/launch_distributed.sh --num-gpus 4

# æµ‹è¯•
pytest tests/

# ä¸‹è½½èµ„æº
python scripts/download_optional_assets.py
```

### å…³é”®é…ç½®å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `d_model` | 768 | æ¨¡å‹ç»´åº¦ |
| `num_heads` | 12 | æ³¨æ„åŠ›å¤´æ•° |
| `num_encoder_layers` | 4 | ç¼–ç å™¨å±‚æ•° |
| `num_decoder_layers` | 4 | è§£ç å™¨å±‚æ•° |
| `max_seq_len` | 128 | æœ€å¤§åºåˆ—é•¿åº¦ |
| `dropout` | 0.2 | Dropoutç‡ |
| `learning_rate` | 3e-5 | å­¦ä¹ ç‡ |

---

## ç‰ˆæœ¬å†å²

- **v1.0.0** - åˆå§‹ç‰ˆæœ¬
  - åŸºç¡€Transformerè®­ç»ƒ
  - ä¸­è‹±æ–‡æ”¯æŒ
  - æ’ä»¶ç³»ç»Ÿ
  - WebUIå’ŒAPI
  - æ¨¡å‹å‹ç¼©
  - åˆ†å¸ƒå¼è®­ç»ƒ

---

**APT Model** - è®©Transformerè®­ç»ƒæ›´ç®€å•ï¼
