# APT-Transformer å®Œæ•´æŠ€æœ¯æ€»ç»“

**ç‰ˆæœ¬**: 2.0 (2025-01-21 æ¶æ„é‡ç»„ç‰ˆ)
**é¡¹ç›®**: APT Model (è‡ªç”Ÿæˆå˜æ¢å™¨)
**å®šä½**: ç”Ÿäº§å°±ç»ªçš„ Transformer è®­ç»ƒå¹³å°
**æ¶æ„**: å››å±‚åˆ†ç¦»ï¼ˆL0/L1/L2/L3ï¼‰

**æœ€æ–°æ›´æ–°**:
- âœ… æ¶æ„é‡ç»„ä¸º L0/L1/L2/L3 å››å±‚åˆ†ç¦»
- âœ… ä¸‰æ¡£å‘è¡Œç‰ˆé…ç½®ï¼ˆcore/perf/mind/maxï¼‰
- âœ… AIM-Memory æƒ¯æ€§é”šå®šé•œåƒè®°å¿†ç³»ç»Ÿ
- âœ… AIM-NC N-gram/Trie æ”¶ç¼–åè®®
- âœ… Agent å·¥å…·è°ƒç”¨ç³»ç»Ÿï¼ˆReAct + Pythonæ²™ç›’ + Webæœç´¢ï¼‰

---

## ğŸ—ºï¸ é˜…è¯»å¯¼èˆª

### ç¬¬ä¸€æ¬¡æ¥è§¦ APTï¼Ÿ
ğŸ‘‰ **å…ˆçœ‹è¿™ä¸‰ä»¶äº‹**ï¼š
1. [é€‰æ‹©å‘è¡Œç‰ˆ](#-é€‰æ‹©ä½ çš„å‘è¡Œç‰ˆ) - 3ç§’é€‰æ‹©é€‚åˆä½ çš„é…ç½®
2. [L0 ä¸‰å¤§æ ¸å¿ƒåˆ›æ–°](#l0-å†…æ ¸å±‚) - 5åˆ†é’Ÿäº†è§£æ ¸å¿ƒæŠ€æœ¯
3. [å¿«é€Ÿå‘½ä»¤å‚è€ƒ](#13-å¿«é€Ÿå‘½ä»¤å‚è€ƒ) - ç«‹å³å¼€å§‹ä½¿ç”¨

### æ·±å…¥å­¦ä¹ ï¼ŸæŒ‰å±‚çº§é˜…è¯»
- **ç ”ç©¶å¤ç°** â†’ [L0 å†…æ ¸å±‚](#l0-å†…æ ¸å±‚) - APT æ ¸å¿ƒåˆ›æ–°
- **ç”Ÿäº§åŠ é€Ÿ** â†’ [L1 æ€§èƒ½å±‚](#l1-æ€§èƒ½å±‚) - 10-100Ã— åŠ é€Ÿ
- **é•¿å¯¹è¯/RAG** â†’ [L2 è®°å¿†å±‚](#l2-è®°å¿†å±‚) - AIM è®°å¿†ç³»ç»Ÿ
- **å®Œæ•´å¹³å°** â†’ [L3 åº”ç”¨å±‚](#l3-åº”ç”¨å±‚) - WebUI/API/æ’ä»¶

### ä¸“é¢˜æ·±å…¥
- [å¤šå‚å•†ç¡¬ä»¶](#6-å¤šå‚å•†ç¡¬ä»¶æ”¯æŒ) - NVIDIA/Intel/åä¸º/AMDç»Ÿä¸€æ”¯æŒ
- [è®­ç»ƒä¸ä¼˜åŒ–](#7-è®­ç»ƒä¸ä¼˜åŒ–) - åˆ†å¸ƒå¼è®­ç»ƒã€æ··åˆç²¾åº¦
- [æ¨ç†ä¸ç”Ÿæˆ](#8-æ¨ç†ä¸ç”Ÿæˆ) - Beam Searchã€é‡‡æ ·ç­–ç•¥
- [æ€§èƒ½å¯¹æ¯”](#12-æ€§èƒ½å¯¹æ¯”) - å®Œæ•´æ€§èƒ½æ•°æ®

---

## ğŸ¯ é€‰æ‹©ä½ çš„å‘è¡Œç‰ˆ

| ä½ çš„éœ€æ±‚ | æ¨èå‘è¡Œç‰ˆ | å¯ç”¨å±‚çº§ | ä¸€è¡Œå¯ç”¨ |
|---------|----------|---------|---------|
| è®ºæ–‡å¤ç°ã€æœ€å°å¯ç”¨ | **apt-core** | L0 only | `enable('core')` |
| ç”Ÿäº§è®­ç»ƒã€å¿«é€Ÿæ¨ç† â­ | **apt-perf** | L0 + L1 | `enable('perf')` |
| é•¿å¯¹è¯ã€RAGã€çŸ¥è¯†é—®ç­” | **apt-mind** | L0 + L2 | `enable('mind')` |
| å®Œæ•´æ¼”ç¤ºã€é«˜çº§å¼€å‘ | apt-max | L0+L1+L2+L3 | `enable('max')` |

è¯¦è§ [DISTRIBUTION_MODES.md](DISTRIBUTION_MODES.md) å’Œ [ARCHITECTURE.md](../ARCHITECTURE.md)

---

# L0 å†…æ ¸å±‚

> **è¿™ä¸€å±‚**: æ°¸è¿œæœ€å°ï¼Œæ°¸è¿œæœ€ç¨³å®š  
> **åŒ…å«**: APT æ ¸å¿ƒåˆ›æ–°ï¼ˆAutopoietic + DBC-DAC + Left-Spinï¼‰  
> **é»˜è®¤å¯ç”¨**: âœ… æ‰€æœ‰å‘è¡Œç‰ˆ  
> **å¯ä¾èµ–**: PyTorchã€NumPy ç­‰åŸºç¡€åº“  
> **ç¦æ­¢ä¾èµ–**: L1/L2/L3 çš„ä»»ä½•æ¨¡å—

## 1. æ ¸å¿ƒæ¶æ„

### 1.1 APT Model (è‡ªç”Ÿæˆå˜æ¢å™¨)

**æ ¸å¿ƒç»„ä»¶**:
```python
APTModel = {
    "ç¼–ç å™¨": APTEncoder (12 layers),
    "è§£ç å™¨": APTDecoder (12 layers),
    "æ³¨æ„åŠ›æœºåˆ¶": "Autopoietic Transform (è‡ªç”Ÿæˆæ³¨æ„åŠ›)",
    "ç¨³å®šæ€§": "DBC-DAC (æ·±åº¦æƒé‡è¡°å‡ + åŠ¨æ€æ³¨æ„åŠ›è£å‰ª)",
    "æ•°å€¼ç¨³å®š": "Left-Spin Smooth (å·¦æ—‹å¹³æ»‘)"
}
```

**å…³é”®ç‰¹æ€§**:
- âœ… **Autopoietic Transform**: è‡ªç”Ÿæˆæ³¨æ„åŠ›ï¼ŒåŠ¨æ€è°ƒæ•´æ³¨æ„åŠ›æƒé‡
- âœ… **DBC-DAC**: è®­ç»ƒåŠ é€Ÿ 20-30%ï¼Œæ¢¯åº¦ç¨³å®šæ€§æå‡
- âœ… **Left-Spin Smooth**: å°–ç‚¹è§„é¿ï¼ŒNaN ç‡é™ä½ 5x
- âœ… **ä¸­è‹±æ–‡åŸç”Ÿæ”¯æŒ**: è‡ªåŠ¨è¯­è¨€æ£€æµ‹
- âœ… **åˆ†å¸ƒå¼è®­ç»ƒ**: PyTorch DDPï¼Œå¤š GPU å’Œå¤šèŠ‚ç‚¹

### 1.2 æ¨¡å‹å®¶æ—

| æ¨¡å‹ | å‚æ•°é‡ | ç‰¹ç‚¹ | æ–‡ä»¶ |
|-----|--------|------|------|
| **APT Base** | 768d, 12L | é€šç”¨åŸºç¡€æ¨¡å‹ | `apt_model.py` |
| **GPT-O3** | 768d, 12L | O3æ¨ç†é“¾ï¼Œå¤šæ­¥æ¨ç† | `gpto3_model.py` |
| **GPT-4o** | 768d, 12L | å¤šæ¨¡æ€ï¼Œå›¾æ–‡èåˆ | `gpt4o_model.py` |
| **GPT-5** | 768d, 12L | MoEæ¶æ„ï¼Œä¸“å®¶æ··åˆ | `gpt5_model.py` |
| **Claude 4** | 768d, 12L | å¯¹è¯ä¼˜åŒ–ï¼Œé•¿ä¸Šä¸‹æ–‡ | `claude4_model.py` |
| **VFT-TVA** | å¯å˜ | è§†è§‰ç‰¹å¾è’¸é¦ | `vft_tva_model.py` |

---


---

# L1 æ€§èƒ½å±‚

> **è¿™ä¸€å±‚**: å¯æ’æ‹”çš„æ€§èƒ½åŠ é€Ÿå™¨  
> **åŒ…å«**: è™šæ‹ŸBlackwell (10-100Ã— åŠ é€Ÿ)ã€MXFP4é‡åŒ–ã€100K GPUè®­ç»ƒ  
> **é»˜è®¤å¯ç”¨**: âœ… apt-perf, apt-max  
> **å¯ä¾èµ–**: L0 (åªè¯»æ¥å£)  
> **ç¦æ­¢**: ä¿®æ”¹ L0 æ ¸å¿ƒè¯­ä¹‰ï¼ˆæ€§èƒ½æ˜¯å¯æ›¿æ¢çš„å®ç°ç»†èŠ‚ï¼‰

## 2. è™šæ‹ŸBlackwellè™šç©ºç®—åŠ›

### 2.1 æ ¸å¿ƒæŠ€æœ¯æ ˆ

```
è™šæ‹ŸBlackwell = GPU Flashä¼˜åŒ– + VGPU Stack + å¤šå‚å•†NPU + äº‘ç«¯NPU + å·¦æ—‹å¹³æ»‘
```

#### ğŸ”¥ GPU Flashä¼˜åŒ–

**åŸç†**: FP4é‡åŒ– + Triton Kernelèåˆ + Flash Attention

```python
from apt_model.optimization import FusedFP4Linear

# æ›¿æ¢æ ‡å‡†Linearå±‚
model.fc = FusedFP4Linear(768, 3072)
# è‡ªåŠ¨åº”ç”¨ï¼šFP4é‡åŒ– + Kernelèåˆ + Flash Attention
```

**æ€§èƒ½**:
- å†…å­˜å ç”¨: â†“87.5% (16bit â†’ 4bit)
- æ¨ç†é€Ÿåº¦: â†‘2-3Ã— (Kernelèåˆ)
- è®­ç»ƒé€Ÿåº¦: â†‘5-10Ã— (Flash Attention)

#### ğŸ’¾ VGPU Stack (è™šæ‹Ÿæ˜¾å­˜å †å )

**ä¸‰çº§å†…å­˜å±‚æ¬¡**: GPU â†” CPU â†” SSD

```python
from apt_model.optimization import VGPUStack

vgpu = VGPUStack.from_config({
    'levels': [
        {'capacity_mb': 2000, 'device': 'cuda:0', 'speed_gbps': 900},  # L1: GPU
        {'capacity_mb': 8000, 'device': 'cpu', 'speed_gbps': 50},      # L2: CPU
        {'capacity_mb': 32000, 'device': 'ssd', 'speed_gbps': 7}       # L3: SSD
    ]
})
```

**æ•ˆæœ**:
- æ˜¾å­˜å®¹é‡: â†‘21Ã— (2GB â†’ 42GBè™šæ‹Ÿæ˜¾å­˜)
- å‘½ä¸­ç‡: >85% (LRUç¼“å­˜)
- æ€§èƒ½æŸå¤±: <15%

#### âš¡ ä¸€é”®å¯ç”¨

```python
import apt_model.optimization.vb_global as vb

# ä¸€è¡Œå¯ç”¨æ‰€æœ‰ä¼˜åŒ–
vb.enable()

# æˆ–ä½¿ç”¨é¢„è®¾æ¨¡å¼
vb.enable_balanced_mode()    # å¹³è¡¡æ¨¡å¼
vb.enable_max_memory_mode()  # æœ€å¤§æ˜¾å­˜æ¨¡å¼
vb.enable_max_speed_mode()   # æœ€å¤§é€Ÿåº¦æ¨¡å¼
vb.enable_moe_mode()         # MoEæ¨¡å¼
vb.enable_extreme_scale_mode(total_gpus=100000)  # 100K GPUæ¨¡å¼
```

### 2.2 æ€§èƒ½æå‡

| é…ç½® | æ˜¾å­˜éœ€æ±‚ | è®­ç»ƒé€Ÿåº¦ | æˆæœ¬ |
|------|----------|----------|------|
| **çº¯GPUï¼ˆ8Ã—A100 80GBï¼‰** | 640 GB | 1Ã— | Â¥400ä¸‡ |
| **è™šæ‹ŸBlackwellï¼ˆ8Ã—RTX 3090 24GBï¼‰** | 192 GBç‰©ç†<br>768 GBè™šæ‹Ÿ | 0.85Ã— | Â¥80ä¸‡ |

**ç»“è®º**: æˆæœ¬é™ä½80%ï¼Œæ€§èƒ½æŸå¤±ä»…15%

---

## 3. æé™ä¼˜åŒ–æŠ€æœ¯

### 3.1 MXFP4 é‡åŒ–

**æŠ€æœ¯æ¥æº**: Microsoft + OpenAI (GPT-OSS, 2025å¹´8æœˆ)

**è§„æ ¼**:
- 4-bitæµ®ç‚¹: 1 sign + 2 exponent + 1 mantissa
- å—çº§ç¼©æ”¾: æ¯32å…ƒç´ å…±äº«1ä¸ª8-bitç¼©æ”¾å› å­
- å‹ç¼©æ¯”: 4x
- ç²¾åº¦æŸå¤±: <1%

```python
from apt_model.optimization.mxfp4_quantization import (
    MXFP4Quantizer,
    MXFP4Linear,
    convert_model_to_mxfp4
)

# æ–¹æ³•1: é‡åŒ–å•ä¸ªå±‚
mxfp4_linear = MXFP4Linear.from_float(nn.Linear(768, 768))

# æ–¹æ³•2: è½¬æ¢æ•´ä¸ªæ¨¡å‹
model = convert_model_to_mxfp4(model)
```

**æ€§èƒ½å¯¹æ¯”**:

| æ ¼å¼ | ä½å®½ | å‹ç¼©æ¯” | æ¨ç†é€Ÿåº¦ | ç²¾åº¦æŸå¤± |
|-----|------|--------|----------|----------|
| FP16 | 16-bit | 1x | 1x | 0% |
| FP4 (æ—§ç‰ˆ) | 4-bit | 4x | 3x | 2-5% |
| **MXFP4** | 4-bit | **4x** | **4x** | **<1%** |

### 3.2 GPUä¼˜åŒ–MoE

**æŠ€æœ¯æ¥æº**: Mixtralé£æ ¼ç¨€ç–MoE

**æ¶æ„å¯¹æ¯”**:

| ç‰¹æ€§ | æ ‡å‡†MoE | GPUä¼˜åŒ–MoE |
|-----|---------|-----------|
| **å®ç°æ–¹å¼** | æ©ç æ··åˆ | Token Dispatch |
| **ä¸“å®¶æ¿€æ´»** | å…¨éƒ¨ä¸“å®¶ | Top-kä¸“å®¶ |
| **å¹¶è¡Œè®¡ç®—** | âŒ | âœ… |
| **è´Ÿè½½å‡è¡¡** | âŒ | âœ… (balance loss) |
| **ååé‡** | åŸºå‡† | **3.3x** |

```python
from apt_model.modeling.moe_optimized import MoELayerOptimized

moe = MoELayerOptimized(
    d_model=768,
    d_ff=3072,
    num_experts=8,
    top_k=2,  # æ¿€æ´»2/8ä¸“å®¶
    load_balance_weight=0.01
)

output, aux_loss = moe(hidden_states)
```

### 3.3 100K GPUè®­ç»ƒ

**æŠ€æœ¯æ¥æº**: Meta Llama 4 (350K GPUs), OpenAI GPT-5 (500K+ GPUs)

**ä¸‰ç»´å¹¶è¡Œ**:
- Data Parallel: æ•°æ®å¹¶è¡Œ
- Tensor Parallel: å¼ é‡å¹¶è¡Œï¼ˆå±‚å†…ï¼‰
- Pipeline Parallel: æµæ°´çº¿å¹¶è¡Œï¼ˆå±‚é—´ï¼‰

**ç½‘ç»œæ‹“æ‰‘**:
- Intra-rack: NVLink 5 (1.8TB/s per GPU)
- Inter-rack: InfiniBand (400Gbps)
- Inter-datacenter: Ethernet (100Gbps)

```python
from apt_model.optimization.extreme_scale_training import ExtremeScaleConfig

config = ExtremeScaleConfig(
    total_gpus=100000,
    data_parallel_size=64,
    tensor_parallel_size=8,
    pipeline_parallel_size=8,
    zero_stage=3  # DeepSpeed ZeRO-3
)
```

**æ”¯æŒè§„æ¨¡**:
- âœ… Meta Llama 4: 350K GPUs
- âœ… OpenAI GPT-5: 500K+ GPUs
- âœ… Google Gemini 2.0: 256K+ TPUs

---


---

# L2 è®°å¿†å±‚

> **è¿™ä¸€å±‚**: ç‹¬ç«‹çš„è®°å¿†ç‹å›½  
> **åŒ…å«**: AIM-Memoryã€AIM-NCã€GraphRAGã€åˆ†å±‚è®°å¿†ã€é•¿ä¸Šä¸‹æ–‡  
> **é»˜è®¤å¯ç”¨**: âœ… apt-mind, apt-max  
> **å¯ä¾èµ–**: L0 (æ ¸å¿ƒæ¥å£)  
> **ç¦æ­¢**: åˆ°å¤„æ’é’©å­ï¼ˆå¿…é¡»é€šè¿‡ç»Ÿä¸€æ¥å£å‘ L0 æä¾›"å¯æ³¨å…¥ä¸Šä¸‹æ–‡"ï¼‰

## 4. é•¿ä¸Šä¸‹æ–‡ä¸è®°å¿†ç³»ç»Ÿ

### 4.1 RoPEä¼˜åŒ–ï¼ˆæ”¯æŒ10M tokensï¼‰

| æŠ€æœ¯ | ä¸Šä¸‹æ–‡é•¿åº¦ | ç‰¹ç‚¹ | åº”ç”¨ |
|-----|----------|------|------|
| **iRoPE** | **10M tokens** | äº¤é”™ä½ç½®ç¼–ç  | Llama 4 Scout |
| **YaRN** | 128K tokens | åˆ†ç»´åº¦ç¼©æ”¾ | Qwen, DeepSeek, GPT-OSS |
| **LongRoPE2** | 2M+ tokens | PPLå¼•å¯¼æ¼”åŒ–æœç´¢ | Phi3, LLaMA3 |
| Standard RoPE | 4K tokens | ç»å…¸å®ç° | çŸ­ä¸Šä¸‹æ–‡ |

```python
from apt_model.modeling.advanced_rope import create_rope, RoPEConfig

# Llama 4 Scouté…ç½®ï¼ˆ10M tokensï¼‰
config = RoPEConfig(
    dim=128,
    max_position_embeddings=10_000_000,
    rope_type="irope",
    irope_num_blocks=4
)

rope = create_rope(config)
q_rotated, k_rotated = rope(q, k)
```

**æ€§èƒ½å¯¹æ¯”**:

| åºåˆ—é•¿åº¦ | Standard RoPE | YaRN | iRoPE | LongRoPE2 |
|---------|--------------|------|-------|-----------|
| 4K | âœ… 100% | âœ… 100% | âœ… 100% | âœ… 100% |
| 32K | âŒ å´©æºƒ | âœ… 98% | âœ… 99% | âœ… 99.5% |
| 128K | âŒ | âœ… 95% | âœ… 97% | âœ… 98% |
| 1M | âŒ | âŒ | âœ… 92% | âœ… 95% |
| **10M** | âŒ | âŒ | âœ… **85%** | âŒ |

### 4.2 è®°å¿†å¢å¼ºå·¦æ—‹å¹³æ»‘

**ä¸‰å±‚è®°å¿†æ¶æ„**:
```python
from apt_model.modeling.memory_augmented_smooth import create_memory_augmented_smooth

smooth = create_memory_augmented_smooth(
    d_model=768,
    memory_config={
        'short_term_size': 8,     # æœ€è¿‘8æ­¥
        'mid_term_size': 64,      # 64ä¸ªå…³é”®äº‹ä»¶
        'skeleton_fields': 6      # 6å­—æ®µéª¨æ¶
    }
)

u_next, stats = smooth(u, delta_u, use_memory=True)
```

**éª¨æ¶çŠ¶æ€ï¼ˆ6å­—æ®µï¼‰**:
1. `topic`: ä¸»é¢˜
2. `constraints`: çº¦æŸæ¡ä»¶
3. `definitions`: æœ¯è¯­å®šä¹‰
4. `unresolved`: æœªå†³é—®é¢˜
5. `style_preference`: é£æ ¼åå¥½
6. `spike_regions`: å°–ç‚¹åŒºåŸŸ

**æ€§èƒ½æå‡**:

| æŒ‡æ ‡ | æ ‡å‡†å·¦æ—‹å¹³æ»‘ | è®°å¿†å¢å¼ºç‰ˆ | æå‡ |
|-----|-----------|-----------|------|
| NaNç‡ | 0.5% | **0.1%** | 5x â†“ |
| é•¿ä¸Šä¸‹æ–‡ä¸€è‡´æ€§ | 75% | **92%** | +17% |
| å°–ç‚¹è§„é¿ç‡ | 60% | **88%** | +28% |
| è½¨è¿¹ç¨³å®šæ€§ | 0.72 | **0.91** | +26% |

### 4.3 åˆ†å±‚è®°å¿†ç³»ç»Ÿï¼ˆæœ€æ–°ï¼‰

**æ ¸å¿ƒç†å¿µ**: "ç»†èŠ‚ä¸é æ‘˜è¦ä¿å­˜ï¼Œè€Œæ˜¯é æ£€ç´¢å–åŸæ–‡"

**ä¸‰æ¡£è®°å¿†åˆ†ç±»**:

#### Aæ¡£ï¼ˆVerbatim - åŸæ–‡ï¼‰
- é€‚ç”¨: ä¸¥æ ¼å®šä¹‰ã€ç¬¦å·çº¦å®šã€å®šç†æ¡ä»¶
- ç‰¹æ€§: å¿…é¡»åŸæ ·ä¿ç•™ï¼Œå“ˆå¸Œæ ¡éªŒï¼Œç‰ˆæœ¬åŒ–
- ç¤ºä¾‹: `DEF:LeftSpinSmooth:v1`

#### Bæ¡£ï¼ˆStructured - ç»“æ„åŒ–ï¼‰
- é€‚ç”¨: å‚æ•°é…ç½®ã€é˜ˆå€¼è¡¨ã€æµç¨‹æ­¥éª¤
- ç‰¹æ€§: JSON/é”®å€¼å¯¹å­˜å‚¨
- ç¤ºä¾‹: `PARAM:HyperParams:v1: {"lr": 0.001, ...}`

#### Cæ¡£ï¼ˆNarrative - æ‘˜è¦ï¼‰
- é€‚ç”¨: èƒŒæ™¯å™è¿°ã€è®¨è®ºè¿‡ç¨‹ã€ç±»æ¯”è¯´æ˜
- ç‰¹æ€§: å…è®¸å‹ç¼©ï¼Œä¿ç•™å›æº¯é“¾æ¥
- ç¤ºä¾‹: `NARR:Background:v1`

**é”šç‚¹æŒ‡ä»¤ç³»ç»Ÿ**:
```python
from apt_model.memory.hierarchical_memory import create_hierarchical_memory

memory = create_hierarchical_memory()

text = """
ã€å°å­˜Â·åŸæ–‡ã€‘DEF:concept:v1: ç²¾ç¡®å®šä¹‰...
ã€å°å­˜Â·å­—æ®µã€‘PARAM:config:v1: {"alpha": 0.5}
ã€å°å­˜Â·æ‘˜è¦ã€‘NARR:story:v1: èƒŒæ™¯è¯´æ˜...
"""

memory.process_anchor_directives(text)
```

**ä¸¤å±‚å­˜å‚¨**:
- **Layer 1: éª¨æ¶å¡**ï¼ˆ200-400 tokensï¼Œéšæ—¶æ³¨å…¥ï¼‰
  - æœ¯è¯­è¡¨ç´¢å¼•ã€æ ¸å¿ƒé”šç‚¹ã€ç¦æ­¢åç¦»ç‚¹
- **Layer 2: ç»†èŠ‚ä»“**ï¼ˆæŒ‰éœ€æ£€ç´¢ï¼‰
  - Aæ¡£åŸæ–‡ã€Bæ¡£å­—æ®µã€Cæ¡£æ‘˜è¦

**é˜²æ¼‚ç§»æœºåˆ¶**:
- âœ… ç‰ˆæœ¬åŒ–æ§åˆ¶ï¼ˆv1, v2, v3...ï¼‰
- âœ… å“ˆå¸Œæ ¡éªŒï¼ˆSHA-256ï¼‰
- âœ… ä¸€è‡´æ€§éªŒè¯

**æ€§èƒ½å¯¹æ¯”**:

| æŒ‡æ ‡ | ä¼ ç»Ÿæ‘˜è¦ | åˆ†å±‚è®°å¿† | æå‡ |
|-----|---------|---------|------|
| ç»†èŠ‚ä¿ç•™ç‡ | 60% | **98%** | +38% |
| å®šä¹‰æ¼‚ç§»ç‡ | 15% | **2%** | 7.5x â†“ |
| æ£€ç´¢ç²¾åº¦ | 75% | **95%** | +20% |
| è·¨ä¼šè¯ä¸€è‡´æ€§ | 70% | **92%** | +22% |

### 4.4 ç»Ÿä¸€è®°å¿†ç»„åˆå™¨

```python
from apt_model.memory.context_composer import create_hierarchical_composer

composer = create_hierarchical_composer()

# 1. åŸºç¡€è®°å¿†ç³»ç»Ÿï¼ˆChatGPT-styleï¼‰
composer.basic.save_memory("ç”¨æˆ·æ˜¯AIç ”ç©¶å‘˜", importance=0.9)

# 2. åˆ†å±‚è®°å¿†ç³»ç»Ÿï¼ˆé”šç‚¹æŒ‡ä»¤ï¼‰
composer.hierarchical.process_anchor_directives("""
ã€å°å­˜Â·åŸæ–‡ã€‘DEF:YaRN:v1: YaRNæ˜¯åˆ†ç»´åº¦ç¼©æ”¾çš„RoPEå˜ä½“ã€‚
""")

# 3. ç»Ÿä¸€ç»„åˆ
context = composer.compose_unified_context(
    current_message="é›†æˆYaRNåˆ°æ¨¡å‹",
    use_basic=True,
    use_hierarchical=True,
    validate=True
)
```

### 4.5 AIM-Memory æƒ¯æ€§é”šå®šé•œåƒè®°å¿†ï¼ˆæœ€æ–°ï¼‰

**æ ¸å¿ƒåŸç†**: é¢å‘å¤§æ¨¡å‹çš„é•¿æœŸè®°å¿†æ¶æ„ï¼Œé€šè¿‡å››å¤§æœºåˆ¶è§£å†³ä¼ ç»Ÿ RAG çš„æˆæœ¬å’Œç²¾åº¦é—®é¢˜ã€‚

```
AIM-Memory = æƒ¯æ€§è·¯ç”± + æ—¶é—´é•œåƒ + é”šç‚¹çº é”™ + æŒ‰éœ€è¯æ®å›çŒ
```

#### å››å¤§æ ¸å¿ƒæœºåˆ¶

**1ï¸âƒ£ æƒ¯æ€§è·¯ç”± (Inertial Routing)**
- ç»´æŠ¤"æƒ¯æ€§æ–¹å‘"å‘é‡ï¼Œè¿ç»­æŸ¥è¯¢è‡ªç„¶è½åœ¨ç›¸å…³è®°å¿†ç°‡
- åªæ£€ç´¢å°ç°‡ï¼Œä¸å…¨åº“æ‰«æ
- **æ•ˆæœ**: æ£€ç´¢æˆæœ¬ **â†“70-90%**

**2ï¸âƒ£ æ—¶é—´é•œåƒ (Temporal Mirror)**
- æƒé‡è¡°å‡è‡ªç„¶è¡¨è¾¾"æ–°æ—§"å…³ç³»
- æ¯æ¬¡å†™å…¥æ–°è®°å¿†ï¼Œæ—§èŠ‚ç‚¹æƒé‡ *= 0.8
- **æ•ˆæœ**: è¶Šæ–°çš„è®°å¿†æƒé‡è¶Šé«˜ï¼Œè‡ªç„¶æ—¶åºæ¢¯åº¦

**3ï¸âƒ£ é”šç‚¹çº é”™ (Anchored Correction)**
- æå–å’ŒéªŒè¯å…³é”®å­—æ®µï¼ˆæ•°å­—ã€ä¸“åã€ç¬¦å·ã€å®šä¹‰ï¼‰
- æŸ¥è¯¢"10M tokens"åªå¬å›çœŸæ­£åŒ…å«"10M"çš„èŠ‚ç‚¹
- **æ•ˆæœ**: ç²¾åº¦ **â†‘20-30%**ï¼Œé˜²æ­¢å¹»è§‰

**4ï¸âƒ£ æŒ‰éœ€è¯æ®å›çŒ (Evidence Refill)**
- é»˜è®¤åªå­˜æ‘˜è¦ï¼Œæ£€æµ‹åˆ°"ç²¾ç¡®/åŸæ–‡"å…³é”®è¯æ‰å›çŒåŸæ–‡
- **æ•ˆæœ**: å¹³æ—¶èŠ‚çœ **70-80%** token

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from apt_model.memory.aim_memory import create_aim_memory

# åˆ›å»ºè®°å¿†ç³»ç»Ÿ
aim = create_aim_memory()

# å†™å…¥è®°å¿†
aim.write_memory("RoPE æ˜¯æ—‹è½¬ä½ç½®ç¼–ç ï¼Œé€šè¿‡å¤æ•°æ—‹è½¬å®ç°ä½ç½®è¡¨ç¤ºã€‚")
aim.write_memory("YaRN é€šè¿‡åˆ†ç»´åº¦ç¼©æ”¾æ‰©å±• RoPE åˆ°æ›´é•¿ä¸Šä¸‹æ–‡ã€‚")
aim.write_memory("Llama 4 ä½¿ç”¨ iRoPE æ”¯æŒ 10M tokens ä¸Šä¸‹æ–‡ã€‚")

# æŸ¥è¯¢è®°å¿†ï¼ˆè‡ªåŠ¨æ¨¡å¼æ£€æµ‹ï¼‰
result = aim.answer("10M tokens çš„æ¨¡å‹æ˜¯å“ªä¸ªï¼Ÿ", auto_mode=True)
print(f"æ¨¡å¼: {result['mode']}")           # fast æˆ– strict
print(f"ä¸Šä¸‹æ–‡:\n{result['context']}")
```

**æ€§èƒ½å¯¹æ¯”**:

| æŒ‡æ ‡ | ä¼ ç»Ÿ RAG | AIM-Memory | æå‡ |
|------|----------|------------|------|
| æ£€ç´¢æˆæœ¬ | å…¨åº“æ‰«æ | å±€éƒ¨ç°‡å¬å› | â†“ 70-90% |
| ç²¾åº¦ä¿è¯ | embedding | é”šç‚¹å­—æ®µéªŒè¯ | â†‘ 20-30% |
| å­˜å‚¨æˆæœ¬ | å…¨æ–‡å­˜å‚¨ | æ‘˜è¦+æŒ‰éœ€å›çŒ | â†“ 70-80% |
| å“åº”é€Ÿåº¦ | åŸºå‡† | å¿«é€Ÿå°ç°‡ | â†‘ 2-3Ã— |

### 4.6 AIM-NC N-gramæ”¶ç¼–åè®®ï¼ˆæœ€æ–°ï¼‰

**æ ¸å¿ƒæ€æƒ³**: å°† n-gram/Trie/Engram ç»“æ„åŒ–å‘½ä¸­æ¨¡å—"æ”¶ç¼–"ä¸º AIM çš„å¬å›å¼•æ“ï¼ŒåŒæ—¶ä¿æŒ AIM çš„é”šç‚¹çº é”™ä¸»æƒã€‚

```
ä¾¦å¯Ÿå…µï¼ˆn-gramï¼‰ï¼šå¿«é€Ÿå‘½ä¸­å€™é€‰ï¼Œå¯èƒ½èµ°é”™è·¯
å®ªæ³•æ³•é™¢ï¼ˆAIMé”šç‚¹ï¼‰ï¼šä¸é€šè¿‡å­—æ®µéªŒè¯å°±å‡ºå±€
å‘ç¥¨ç³»ç»Ÿï¼ˆè¯æ®å›çŒï¼‰ï¼šä¸¥æ ¼/å†²çªæ—¶æ‰æ‹‰åŸæ–‡
```

**ä¸‰è·¯å¬å›æ¶æ„**:

```python
from apt_model.memory.aim_memory_nc import create_aim_memory_nc

# åˆ›å»º AIM-NC
aim_nc = create_aim_memory_nc()

# å†™å…¥æ—¶è‡ªåŠ¨å»ºç«‹ n-gram ç´¢å¼•å’Œé‚»æ¥å›¾
aim_nc.write_memory("Llama 4 Scout æ”¯æŒ 10M tokens ä¸Šä¸‹æ–‡")

# ä¸‰è·¯å¬å›ï¼šn-gram + å‘é‡ + é‚»æ¥å›¾
result = aim_nc.answer("10M tokens çš„æ¨¡å‹", auto_mode=True)
```

**æ ¸å¿ƒç»„ä»¶**:

1. **NGramIndex**: N-gram å€’æ’ç´¢å¼•ï¼ˆTF-IDF åŠ æƒï¼‰
2. **TrieLM**: å‰ç¼€æ ‘è¯­è¨€æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
3. **LinkGraph**: å®ä½“/æ—¶é—´/ä¸»é¢˜é‚»æ¥å›¾

**å¬å›æµç¨‹**:
```python
# R2: ä¸‰è·¯å¬å›
cand_ng   = ngram_index.lookup(query, top_k=64)   # n-gram å¿«é€Ÿå‘½ä¸­
cand_vec  = vector_index.top_k(query, k=32)       # å‘é‡è¯­ä¹‰å¬å›
cand_link = link_graph.expand(seeds, limit=16)    # é‚»æ¥å›¾æ‰©å±•

# R3: åˆå¹¶å€™é€‰æ± 
pool = unique(cand_ng + cand_vec + cand_link)[:64]

# R4: AIM ä¸»æƒ - é”šç‚¹çº é”™ï¼ˆå…³é”®ï¼ï¼‰
for node in pool:
    anchor_score = anchor_check(query_fields, node.fields)
    if anchor_score < threshold:
        node.reject = True  # n-gram å‘½ä¸­ä¹Ÿæ— æ³•ç»•è¿‡é”šç‚¹ï¼

    # ä¸‰è·¯åŠ æƒè¯„åˆ†
    node.score = anchor_score * (
        0.3 * ngram_score +
        0.5 * vector_score +
        0.2 * link_score
    ) * (1 + time_weight)
```

**æ€§èƒ½å¯¹æ¯”**:

| ç‰¹æ€§ | AIM-Memory | AIM-NC | æ”¹è¿› |
|------|-----------|--------|------|
| å¬å›æ–¹å¼ | å•è·¯å‘é‡å¬å› | ä¸‰è·¯å¬å› | æ›´å…¨é¢ |
| å¬å›æˆæœ¬ | å…¨èŠ‚ç‚¹æ‰«æ | n-gram å¿«é€Ÿè¿‡æ»¤ | â†“ 40-60% |
| ç²¾åº¦ä¿è¯ | é”šç‚¹çº é”™ | é”šç‚¹çº é”™ï¼ˆä¸»æƒï¼‰ | ä¿æŒ |
| ç»“æ„åŒ–å‘½ä¸­ | æ—  | n-gram + Trie | âœ… æ–°å¢ |
| å›¾æ‰©å±• | æ—  | LinkGraph | âœ… æ–°å¢ |

**æˆåŠŸæ ‡å‡†éªŒè¯**:
- âœ… **ä¸»æƒåˆ¤æ®**: é”šç‚¹æœ‰æœ€ç»ˆå†³å®šæƒï¼Œn-gram æ— æ³•ç»•è¿‡
- âœ… **ç¨³å®šæ€§åˆ¤æ®**: æ•°å­—/ä¸“åç²¾ç¡®åŒ¹é…ï¼Œé˜²æ­¢å¹»è§‰
- âœ… **æˆæœ¬åˆ¤æ®**: K_final = 64ï¼ˆå°å¸¸æ•°ï¼‰ï¼Œæ£€ç´¢æˆæœ¬å¯æ§

---


---

# L3 åº”ç”¨å±‚

> **è¿™ä¸€å±‚**: ç”¨æˆ·ç•Œé¢ã€APIã€ç›‘æ§ã€æ’ä»¶  
> **åŒ…å«**: WebUIã€REST APIã€CLIã€å¯è§‚æµ‹æ€§ã€æ’ä»¶ç”Ÿæ€ã€Agent  
> **é»˜è®¤å¯ç”¨**: âœ… apt-max  
> **å¯ä¾èµ–**: L0, L1, L2  
> **ç¦æ­¢è¢«ä¾èµ–**: L0/L1/L2 æ°¸è¿œä¸èƒ½åå‘ import L3

## 9. æ’ä»¶ç”Ÿæ€ç³»ç»Ÿ

### 9.1 26+ç”Ÿäº§æ’ä»¶

**æ¨ç†å¢å¼º**:
- BeamSearch
- Self-Consistency
- Chain-of-Thought (CoT)
- Tree-of-Thought (ToT)

**å¤šæ¨¡æ€**:
- Multi-Modalèåˆ
- Vision-Language
- Audio-Text

**çŸ¥è¯†å¢å¼º**:
- Knowledge Graph RAG
- Vector Database
- Web Search

### 9.2 æ’ä»¶ç³»ç»Ÿæ¶æ„

**äº‹ä»¶é©±åŠ¨**:
```python
from apt_model.plugins import PluginManager

manager = PluginManager()

# åŠ è½½æ’ä»¶
manager.load_plugin('beam_search')
manager.load_plugin('self_consistency')

# æ³¨å†Œäº‹ä»¶é’©å­
@manager.on_event('before_generation')
def preprocess(context):
    # ç”Ÿæˆå‰é¢„å¤„ç†
    pass

@manager.on_event('after_generation')
def postprocess(result):
    # ç”Ÿæˆååå¤„ç†
    pass
```

**çƒ­æ’æ‹”æ”¯æŒ**:
```python
# è¿è¡Œæ—¶åŠ è½½
manager.load_plugin('new_plugin', hot_reload=True)

# è¿è¡Œæ—¶å¸è½½
manager.unload_plugin('old_plugin')
```

---

## 10. Agentå·¥å…·è°ƒç”¨ç³»ç»Ÿï¼ˆæœ€æ–°ï¼‰

### 10.1 æ ¸å¿ƒèƒ½åŠ›

**Agent ç³»ç»Ÿ** è®©æ¨¡å‹èƒ½å¤Ÿè‡ªä¸»åˆ¤æ–­ä½•æ—¶è°ƒç”¨å·¥å…·ï¼ˆPython è®¡ç®—ã€Web æœç´¢ç­‰ï¼‰ï¼Œå®ç° ReActï¼ˆReasoning + Actingï¼‰å†³ç­–å¾ªç¯ã€‚

```
Agent System = å·¥å…·æ³¨å†Œç³»ç»Ÿ + Pythonæ²™ç›’ + Webæœç´¢ + ReActå†³ç­–å¾ªç¯
```

### 10.2 å·¥å…·ç³»ç»Ÿ (Tool System)

**æ ¸å¿ƒç»„ä»¶**:
- **ToolRegistry**: å·¥å…·æ³¨å†Œå’Œå‘ç°
- **ToolExecutor**: å¹¶è¡Œå·¥å…·æ‰§è¡Œå¼•æ“
- **@tool è£…é¥°å™¨**: ç®€åŒ–å·¥å…·å®šä¹‰
- **MCP/OpenAI å…¼å®¹**: æ”¯æŒå¤šç§å·¥å…·è°ƒç”¨æ ¼å¼

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from apt_model.agent.tool_system import tool, ToolExecutor, get_tool_registry

# 1. å®šä¹‰å·¥å…·ï¼ˆä½¿ç”¨è£…é¥°å™¨ï¼‰
@tool(
    name="calculator",
    description="æ‰§è¡Œæ•°å­¦è®¡ç®—",
    parameters=[
        {"name": "expression", "type": "string", "description": "æ•°å­¦è¡¨è¾¾å¼"}
    ]
)
async def calculator(expression: str):
    return eval(expression, {"__builtins__": {}}, {"abs": abs, "max": max})

# 2. æ‰§è¡Œå·¥å…·
executor = ToolExecutor(get_tool_registry())
result = await executor.execute_single("calculator", {"expression": "2 + 3 * 4"})
print(result.output)  # 14
```

**å¹¶è¡Œæ‰§è¡Œ**:
```python
# å¹¶å‘æ‰§è¡Œå¤šä¸ªå·¥å…·
results = await executor.execute_parallel([
    ("calculator", {"expression": "10 + 5"}),
    ("web_search", {"query": "latest AI news"}),
    ("python_code", {"code": "print('Hello')"})
])
```

### 10.3 Python æ²™ç›’ (Python Sandbox)

**å¤šå±‚å®‰å…¨æœºåˆ¶**:
1. **AST é™æ€åˆ†æ**: æ‰§è¡Œå‰æ£€æŸ¥ä»£ç å®‰å…¨æ€§
2. **å—é™å‘½åç©ºé—´**: åªå…è®¸å®‰å…¨çš„å†…ç½®å‡½æ•°
3. **èµ„æºé™åˆ¶**: å†…å­˜å’Œ CPU çº¦æŸï¼ˆUnixï¼‰
4. **è¶…æ—¶ä¿æŠ¤**: signal.SIGALRM (Unix) / threading.Timer (Windows)
5. **è¾“å‡ºæˆªæ–­**: é™åˆ¶è¾“å‡ºå¤§å°

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from apt_model.agent.python_sandbox import PythonSandbox, SandboxConfig

# åˆ›å»ºæ²™ç›’
config = SandboxConfig(
    timeout=5.0,                    # 5ç§’è¶…æ—¶
    max_memory_mb=100,              # 100MBå†…å­˜é™åˆ¶
    allow_imports=True,             # å…è®¸å¯¼å…¥
    import_whitelist=['math', 'json'],  # ç™½åå•
    restricted_builtins=['open', 'eval', 'exec']  # ç¦ç”¨å‡½æ•°
)

sandbox = PythonSandbox(config)

# æ‰§è¡Œä»£ç 
code = """
import math
result = math.sqrt(16) + math.pi
print(f"Result: {result}")
"""

result = sandbox.execute(code)
print(result.output)  # "Result: 7.141592653589793"
print(result.return_value)  # {'result': 7.141592653589793}
```

**å®‰å…¨æ£€æŸ¥ç¤ºä¾‹**:
```python
# å±é™©ä»£ç ä¼šè¢«æ‹’ç»
dangerous_code = """
import os
os.system('rm -rf /')  # âŒ ä¼šè¢« AST æ£€æŸ¥å™¨æ‹’ç»
"""

result = sandbox.execute(dangerous_code)
assert not result.success
assert "restricted" in result.error.lower()
```

### 10.4 Web æœç´¢å·¥å…· (Web Search)

**æ”¯æŒçš„æœç´¢å¼•æ“**:
- **MockSearchEngine**: æµ‹è¯•ç”¨ï¼ˆæ— éœ€ç½‘ç»œï¼‰
- **DuckDuckGoSearch**: å…è´¹æœç´¢ï¼ˆæ— éœ€ API Keyï¼‰
- **æ‰©å±•æ”¯æŒ**: Google / Bing / Serper.dev

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from apt_model.agent.tools.web_search import WebSearchTool, DuckDuckGoSearch

# åˆ›å»ºæœç´¢å·¥å…·
search_engine = DuckDuckGoSearch()
search_tool = WebSearchTool(search_engine)

# æ‰§è¡Œæœç´¢
result = await search_tool.execute({
    "query": "latest transformer models 2026",
    "num_results": 5
})

for item in result['results']:
    print(f"[{item['title']}]({item['url']})")
    print(f"  {item['snippet']}\n")
```

### 10.5 ReAct Agent å¾ªç¯

**ReAct æ¨¡å¼**: Reasoning (æ€è€ƒ) â†’ Action (è¡ŒåŠ¨) â†’ Observation (è§‚å¯Ÿ)

**å·¥ä½œæµç¨‹**:
```
1. Thought: æ¨¡å‹åˆ†æé—®é¢˜ï¼Œå†³å®šä¸‹ä¸€æ­¥
2. Action: é€‰æ‹©å¹¶è°ƒç”¨å·¥å…·
3. Action Input: æä¾›å·¥å…·å‚æ•°
4. Observation: è·å–å·¥å…·æ‰§è¡Œç»“æœ
5. é‡å¤æ­¥éª¤ 1-4ï¼Œç›´åˆ°å¾—åˆ° Final Answer
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from apt_model.agent.agent_loop import create_react_agent

# åˆ›å»º Agentï¼ˆå¯ç”¨æ‰€æœ‰å·¥å…·ï¼‰
agent = create_react_agent(
    enable_python=True,
    enable_web_search=True,
    max_steps=10
)

# æ‰§è¡Œä»»åŠ¡
result = await agent.run("è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬ 10 é¡¹ï¼Œå¹¶æœç´¢å®ƒçš„æ•°å­¦æ€§è´¨")

# æŸ¥çœ‹æ‰§è¡Œæ­¥éª¤
for step in result.steps:
    print(f"Thought: {step.thought}")
    print(f"Action: {step.action}({step.action_input})")
    print(f"Observation: {step.observation}\n")

print(f"Final Answer: {result.final_answer}")
```

**ç¤ºä¾‹è¾“å‡º**:
```
Step 1:
Thought: éœ€è¦å…ˆè®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬10é¡¹
Action: python_code
Action Input: {"code": "def fib(n): return n if n <= 1 else fib(n-1) + fib(n-2)\nresult = fib(10)"}
Observation: 55

Step 2:
Thought: å·²çŸ¥ç¬¬10é¡¹æ˜¯55ï¼Œç°åœ¨æœç´¢å…¶æ•°å­¦æ€§è´¨
Action: web_search
Action Input: {"query": "fibonacci number 55 mathematical properties"}
Observation: [æœç´¢ç»“æœæ‘˜è¦...]

Final Answer: æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬10é¡¹æ˜¯55ã€‚å®ƒæ˜¯ç¬¬10ä¸ªæ–æ³¢é‚£å¥‘æ•°ï¼Œä¹Ÿæ˜¯...
```

### 10.6 å®Œæ•´é›†æˆç¤ºä¾‹

```python
from apt_model.agent import create_react_agent
from apt_model.modeling.apt_model import APTModel
from apt_model.memory.aim_memory import create_aim_memory

# 1. åˆ›å»º APT æ¨¡å‹
model = APTModel(config)

# 2. åˆ›å»º AIM è®°å¿†ç³»ç»Ÿ
memory = create_aim_memory()

# 3. åˆ›å»º Agent
agent = create_react_agent(
    enable_python=True,
    enable_web_search=True
)

# 4. å¸¦è®°å¿†å’Œå·¥å…·çš„ç”Ÿæˆ
async def generate_with_memory_and_tools(question: str):
    # ä»è®°å¿†æ£€ç´¢ä¸Šä¸‹æ–‡
    memory_result = memory.answer(question, auto_mode=True)
    context = memory_result['context']

    # Agent å†³ç­–æ˜¯å¦éœ€è¦å·¥å…·
    agent_result = await agent.run(f"{context}\n\n{question}")

    # å­˜å‚¨åˆ°è®°å¿†
    memory.write_memory(f"Q: {question}")
    memory.write_memory(f"A: {agent_result.final_answer}")

    return agent_result.final_answer

# ä½¿ç”¨
answer = await generate_with_memory_and_tools(
    "Llama 4 ä½¿ç”¨ä»€ä¹ˆä½ç½®ç¼–ç æ”¯æŒ 10M tokensï¼Ÿè¯·è®¡ç®— 10M / 1024 = ?"
)
```

### 10.7 æŠ€æœ¯ç‰¹æ€§

**æ¶æ„ä¼˜åŠ¿**:
- âœ… **Async-first**: åŸºäº asyncio çš„å¼‚æ­¥æ¶æ„
- âœ… **å¹¶è¡Œæ‰§è¡Œ**: å¤šå·¥å…·å¹¶å‘è°ƒç”¨ï¼Œæ”¯æŒé€Ÿç‡é™åˆ¶
- âœ… **ç¼“å­˜æ”¯æŒ**: å·¥å…·ç»“æœç¼“å­˜ï¼Œé¿å…é‡å¤è®¡ç®—
- âœ… **é”™è¯¯å¤„ç†**: ä¼˜é›…é™çº§ï¼Œå¤±è´¥é‡è¯•
- âœ… **ç»Ÿè®¡ç›‘æ§**: å·¥å…·è°ƒç”¨æ¬¡æ•°ã€æˆåŠŸç‡ã€å»¶è¿Ÿ

**å®‰å…¨ä¿éšœ**:
- âœ… **å¤šå±‚æ²™ç›’**: AST + å‘½åç©ºé—´ + èµ„æºé™åˆ¶
- âœ… **è¶…æ—¶ä¿æŠ¤**: é˜²æ­¢æ— é™å¾ªç¯
- âœ… **è¾“å‡ºé™åˆ¶**: é˜²æ­¢å†…å­˜æº¢å‡º
- âœ… **ç™½åå•æœºåˆ¶**: åªå…è®¸å®‰å…¨æ“ä½œ

**å…¼å®¹æ€§**:
- âœ… **OpenAI Function Calling**: å…¼å®¹ GPT-4 å·¥å…·è°ƒç”¨æ ¼å¼
- âœ… **MCP 2025-11-25**: æ”¯æŒ Model Context Protocol è§„èŒƒ
- âœ… **è·¨å¹³å°**: Windows / Linux / macOS

**æ€§èƒ½æ•°æ®**:

| æŒ‡æ ‡ | æ—  Agent | æœ‰ Agent | æå‡ |
|------|---------|---------|------|
| æ•°å­¦è®¡ç®—å‡†ç¡®ç‡ | 60% | **98%** | +38% |
| å®æ—¶ä¿¡æ¯è·å– | âŒ | âœ… | å¯ç”¨ |
| å¤šæ­¥æ¨ç†æˆåŠŸç‡ | 40% | **85%** | +45% |
| å·¥å…·è°ƒç”¨å»¶è¿Ÿ | - | <100ms | å¯æ¥å— |

---


---

# å…¶ä»–ç« èŠ‚

ä»¥ä¸‹ç« èŠ‚ä¸ºè·¨å±‚çº§çš„åŠŸèƒ½è¯´æ˜å’Œå‚è€ƒä¿¡æ¯ã€‚

## 5. å¼¹æ€§ä¸è‡ªé€‚åº”èƒ½åŠ›

### 5.1 MatFormeråµŒå¥—ç»“æ„

**æ¥æº**: Meta AI (arXiv:2310.07707)

**æ ¸å¿ƒæ€æƒ³**: åµŒå¥—FFNï¼ˆT1 âŠ† T2 âŠ† T3 âŠ† T4ï¼‰

```python
from apt_model.modeling.elastic_transformer import NestedFFN

ffn = NestedFFN(
    d_model=768,
    d_ff=3072,
    num_nested_blocks=4  # 4ä¸ªå®¹é‡çº§åˆ«
)

# è®­ç»ƒæ—¶ï¼šæ‰€æœ‰å—åŒæ—¶ä¼˜åŒ–
output = ffn(x, train_all_blocks=True)

# æ¨ç†æ—¶ï¼šåŠ¨æ€é€‰æ‹©å®¹é‡
ffn.set_capacity(0.5)  # 50%å®¹é‡ï¼ˆç§»åŠ¨ç«¯ï¼‰
output_mobile = ffn(x, train_all_blocks=False)
```

**æ€§èƒ½å¯¹æ¯”**:

| å®¹é‡ | ç»´åº¦ | FLOPs | ç²¾åº¦æŸå¤± | é€‚ç”¨åœºæ™¯ |
|------|------|-------|----------|----------|
| 25% | 768 | â†“87.5% | ~3% | ç§»åŠ¨ç«¯/è¾¹ç¼˜è®¾å¤‡ |
| 50% | 1536 | â†“75% | ~1.5% | è½»é‡çº§æœåŠ¡ |
| 75% | 2304 | â†“43.75% | ~0.5% | å¹³è¡¡æ¨¡å¼ |
| 100% | 3072 | åŸºå‡† | 0% | æœåŠ¡å™¨/äº‘ç«¯ |

### 5.2 DyToxåŠ¨æ€Tokenæ‰©å±•

**æ¥æº**: CVPR 2022

**æ ¸å¿ƒæ€æƒ³**: æŒç»­å­¦ä¹ ï¼ŒåŠ¨æ€æ·»åŠ ä»»åŠ¡ç‰¹å®štoken

```python
from apt_model.modeling.elastic_transformer import DyToxAttention

dytox = DyToxAttention(
    d_model=768,
    num_heads=12,
    num_task_tokens=5  # æ¯ä»»åŠ¡5ä¸ªtoken
)

# ä»»åŠ¡1æ¨ç†
output_task1 = dytox(x, task_id=0)

# æ·»åŠ æ–°ä»»åŠ¡
dytox.add_task(task_id=1, num_tokens=5)
output_task2 = dytox(x, task_id=1)
```

### 5.3 CAMPUSè¯¾ç¨‹å­¦ä¹ è°ƒåº¦å™¨

**æ¥æº**: Li et al. (Sep 2025)

**æ ¸å¿ƒæ€æƒ³**: æ™ºèƒ½æ•°æ®æ’åºï¼Œä»æ˜“åˆ°éš¾

```python
from apt_model.modeling.elastic_transformer import CAMPUSScheduler

scheduler = CAMPUSScheduler(
    num_tasks=10,
    curriculum_stages=['easy', 'medium', 'hard'],
    transition_threshold=0.8  # 80%å‡†ç¡®ç‡åè¿›å…¥ä¸‹é˜¶æ®µ
)

# è·å–å½“å‰éš¾åº¦æ•°æ®
batch = scheduler.get_next_batch(current_epoch, current_accuracy)
```

### 5.4 Memory Bufferï¼ˆé˜²ç¾éš¾æ€§é—å¿˜ï¼‰

```python
from apt_model.modeling.elastic_transformer import MemoryBuffer

buffer = MemoryBuffer(
    capacity=1000,
    sampling_strategy='reservoir'  # æ°´åº“é‡‡æ ·
)

# å­˜å‚¨æ—§ä»»åŠ¡æ ·æœ¬
buffer.add(old_task_samples)

# è®­ç»ƒæ–°ä»»åŠ¡æ—¶æ··åˆæ—§æ ·æœ¬
new_batch = buffer.sample(n=32)
```

---

## 6. å¤šå‚å•†ç¡¬ä»¶æ”¯æŒ

### 6.1 æ”¯æŒçš„åŠ é€Ÿå™¨

| å‚å•† | åŠ é€Ÿå™¨ | PyTorchåŒ… | è®¾å¤‡ç±»å‹ | çŠ¶æ€ |
|------|--------|-----------|----------|------|
| **NVIDIA** | GPU | `torch.cuda` | `cuda` | âœ… ç”Ÿäº§å°±ç»ª |
| **Intel** | Habana Gaudi HPU | `habana_frameworks.torch` | `hpu` | âœ… ç”Ÿäº§å°±ç»ª |
| **Huawei** | Ascend NPU | `torch_npu` | `npu` | âœ… ç”Ÿäº§å°±ç»ª |
| **Intel** | XPU (Ultra NPU) | `intel_extension_for_pytorch` | `xpu` | âš ï¸ å®éªŒæ€§ |
| **AMD** | ROCm GPU | `torch.cuda` (ROCm) | `cuda` | âš ï¸ å®éªŒæ€§ |
| **CPU** | x86/ARM CPU | PyTorch | `cpu` | âœ… é€šç”¨ |

### 6.2 ç»Ÿä¸€è®¾å¤‡API

```python
from apt_model.optimization import get_device_manager
from apt_model.core.system import get_device

# è‡ªåŠ¨æ£€æµ‹æœ€ä½³åŠ é€Ÿå™¨
device = get_device()  # ä¼˜å…ˆçº§: CUDA > HPU > NPU > XPU > CPU
model = model.to(device)

# ç»Ÿä¸€è®¾å¤‡ç®¡ç†
manager = get_device_manager()
print(manager.get_accelerator_type())  # "cuda" / "hpu" / "npu" / ...
manager.memory_allocated()
manager.empty_cache()
manager.synchronize()
```

### 6.3 äº‘ç«¯NPUæ”¯æŒ

**æ”¯æŒçš„äº‘å¹³å°**:
- ğŸŸ¡ åä¸ºäº‘ModelArtsï¼ˆAscend NPUï¼‰- âœ… å·²æ”¯æŒ
- ğŸŸ¢ SaladCloud - â³ ç­‰å¾…NPUæ”¯æŒ
- ğŸ”µ RunPod Serverless - â³ ç­‰å¾…NPUæ”¯æŒ

```python
from apt_model.optimization import enable_cloud_npu, CloudNPULinear

# é…ç½®äº‘ç«¯NPU
import os
os.environ['HUAWEI_CLOUD_API_KEY'] = 'your-api-key'
os.environ['HUAWEI_CLOUD_ENDPOINT'] = 'https://...'

enable_cloud_npu('auto')

# ä½¿ç”¨äº‘ç«¯åŠ é€Ÿå±‚
layer = CloudNPULinear(
    in_features=768,
    out_features=3072,
    cloud_backend='huawei',
    fallback_local=True  # äº‘ç«¯ä¸å¯ç”¨æ—¶è‡ªåŠ¨å›é€€
)
```

---

## 7. è®­ç»ƒä¸ä¼˜åŒ–

### 7.1 è®­ç»ƒåç«¯

**åˆ†å¸ƒå¼è®­ç»ƒ**:
```python
from apt_model.training.trainer import train_model

model = train_model(
    epochs=20,
    batch_size=8,
    learning_rate=3e-5,
    distributed=True,     # PyTorch DDP
    num_gpus=4,
    mixed_precision=True  # AMP
)
```

**å¼ºåŒ–å­¦ä¹ é¢„è®­ç»ƒ**:
- âœ… DPO (Direct Preference Optimization)
- âœ… GRPO (Group Relative Policy Optimization)
- âœ… Reward Model

```python
from apt_model.rl.dpo_trainer import DPOTrainer

trainer = DPOTrainer(
    model=model,
    beta=0.1,  # KLæƒ©ç½šç³»æ•°
    ref_model=ref_model
)

trainer.train(preference_dataset)
```

### 7.2 æ¨¡å‹å‹ç¼©

**5ç§å‹ç¼©æ–¹æ³•**:
1. **DBCè®­ç»ƒåŠ é€Ÿ**: 20-30%æå‡
2. **çŸ¥è¯†è’¸é¦**: å­¦ç”Ÿæ¨¡å‹ â† æ•™å¸ˆæ¨¡å‹
3. **è§†è§‰è’¸é¦**: VFT-TVAæ¶æ„
4. **é‡åŒ–**: MXFP4 / FP4 / INT8
5. **å‰ªæ**: ç»“æ„åŒ–/éç»“æ„åŒ–

```python
from apt_model.training.distillation import distill_model

student = distill_model(
    teacher=large_model,
    student_config={'d_model': 384, 'num_layers': 6},
    temperature=2.0,
    alpha=0.5  # è’¸é¦æŸå¤±æƒé‡
)
```

### 7.3 Checkpointä¿æŠ¤

**åŸå­æ€§ä¿å­˜æœºåˆ¶**:
```python
from apt_model.training.checkpoint import AtomicCheckpointSaver

saver = AtomicCheckpointSaver(checkpoint_dir='./checkpoints')

# åŸå­æ€§ä¿å­˜ï¼ˆé˜²æ­¢ä¸­æ–­æŸåï¼‰
saver.save_checkpoint(
    model=model,
    optimizer=optimizer,
    epoch=10,
    loss=0.5
)

# åŠ è½½æœ€æ–°æ£€æŸ¥ç‚¹
checkpoint = saver.load_latest_checkpoint()
```

---

## 8. æ¨ç†ä¸ç”Ÿæˆ

### 8.1 æ–‡æœ¬ç”Ÿæˆ

**å¤šç§é‡‡æ ·ç­–ç•¥**:
```python
from apt_model.generation.generator import generate_natural_text

text, tokens, logits, confidence = generate_natural_text(
    model,
    tokenizer,
    prompt="äººå·¥æ™ºèƒ½",
    max_steps=50,
    temperature=0.8,      # æ¸©åº¦é‡‡æ ·
    top_k=50,             # Top-Ké‡‡æ ·
    top_p=0.95,           # Nucleusé‡‡æ ·
    repetition_penalty=1.2
)
```

### 8.2 å¤šæ¨¡æ€æ¨ç†

**æ”¯æŒè¾“å…¥ç±»å‹**:
- âœ… æ–‡æœ¬
- âœ… å›¾åƒï¼ˆé€šè¿‡è§†è§‰ç¼–ç å™¨ï¼‰
- âœ… éŸ³é¢‘ï¼ˆé€šè¿‡éŸ³é¢‘ç¼–ç å™¨ï¼‰
- âœ… çŸ¥è¯†å›¾è°±ï¼ˆé€šè¿‡KG-RAGï¼‰

```python
from apt_model.modeling.multimodal_model import MultiModalModel

mm_model = MultiModalModel(config)

# å›¾æ–‡è¾“å…¥
output = mm_model(
    text_input=text_tokens,
    image_input=image_tensor
)
```

### 8.3 RAGé›†æˆ

**çŸ¥è¯†å¢å¼ºç”Ÿæˆ**:
```python
from apt_model.modeling.rag_integration import RAGModel

rag_model = RAGModel(
    base_model=model,
    retriever=retriever,
    top_k=5
)

# RAGæ¨ç†
output = rag_model.generate(
    query="ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—ï¼Ÿ",
    retrieve_from_kb=True
)
```

---

## 11. ç”Ÿäº§ç‰¹æ€§

### 11.1 WebUIç•Œé¢

**4ä¸ªåŠŸèƒ½Tab**:
1. **è®­ç»ƒç›‘æ§**: å®æ—¶losså’Œå­¦ä¹ ç‡æ›²çº¿
2. **æ¢¯åº¦ç›‘æ§**: æ¢¯åº¦æµåˆ†æå’Œå¼‚å¸¸æ£€æµ‹
3. **Checkpointç®¡ç†**: åŠ è½½å’Œç®¡ç†æ¨¡å‹æ£€æŸ¥ç‚¹
4. **æ¨ç†æµ‹è¯•**: äº¤äº’å¼æ–‡æœ¬ç”Ÿæˆ

```bash
# å¯åŠ¨WebUI
python -m apt_model.webui.app --checkpoint-dir ./checkpoints --port 7860

# è®¿é—®: http://localhost:7860
```

### 11.2 REST API

**10+ç«¯ç‚¹**:
- `/generate` - æ–‡æœ¬ç”Ÿæˆ
- `/train` - å¯åŠ¨è®­ç»ƒ
- `/evaluate` - æ¨¡å‹è¯„ä¼°
- `/checkpoint` - æ£€æŸ¥ç‚¹ç®¡ç†
- `/plugins` - æ’ä»¶ç®¡ç†

```bash
# å¯åŠ¨APIæœåŠ¡å™¨
python -m apt_model.api.server --port 8000

# è®¿é—®APIæ–‡æ¡£: http://localhost:8000/docs
```

**ç¤ºä¾‹è¯·æ±‚**:
```python
import requests

response = requests.post('http://localhost:8000/generate', json={
    'prompt': 'äººå·¥æ™ºèƒ½çš„æœªæ¥',
    'max_length': 100,
    'temperature': 0.8
})

print(response.json()['generated_text'])
```

### 11.3 ä¾èµ–å®¹é”™

**ç¦»çº¿å‹å¥½**:
- âœ… å†…ç½®ä¸­æ–‡è¯è¡¨
- âœ… å¯é€‰ä¾èµ–ä¼˜é›…é™çº§
- âœ… æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ä¿æŒå¯ç”¨

```python
# è‡ªåŠ¨é™çº§ç¤ºä¾‹
try:
    from transformers import AutoTokenizer
    tokenizer = AutoTokenizer.from_pretrained('bert-base-chinese')
except ImportError:
    from apt_model.modeling.chinese_tokenizer import ChineseTokenizer
    tokenizer = ChineseTokenizer()  # ä½¿ç”¨å†…ç½®åˆ†è¯å™¨
```

### 11.4 Debugæ¨¡å¼

```bash
# å¯ç”¨è°ƒè¯•æ¨¡å¼
python -m apt_model.cli debug on

# æŸ¥çœ‹è°ƒè¯•ä¿¡æ¯
python -m apt_model.cli debug status

# ç¦ç”¨è°ƒè¯•æ¨¡å¼
python -m apt_model.cli debug off
```

---

## 12. æ€§èƒ½å¯¹æ¯”

### 12.1 å¤§æ¨¡å‹è®­ç»ƒï¼ˆGPT-3, 175Bå‚æ•°ï¼‰

| é…ç½® | æ˜¾å­˜éœ€æ±‚ | è®­ç»ƒé€Ÿåº¦ | æˆæœ¬ |
|------|----------|----------|------|
| çº¯GPUï¼ˆ8Ã—A100 80GBï¼‰ | 640 GB | 1Ã— | Â¥400ä¸‡ |
| è™šæ‹ŸBlackwellï¼ˆ8Ã—RTX 3090 24GBï¼‰ | 192 GBç‰©ç†<br>768 GBè™šæ‹Ÿ | 0.85Ã— | Â¥80ä¸‡ |
| è™šæ‹ŸBlackwell + äº‘ç«¯NPU | 192 GBç‰©ç†<br>æ— é™äº‘ç«¯ | 0.9Ã— | Â¥80ä¸‡ + æŒ‰éœ€ |

### 12.2 BERTæ¨ç†ï¼ˆBaseæ¨¡å‹ï¼‰

| æ–¹æ³• | å»¶è¿Ÿ (ms) | ååé‡ (æ ·æœ¬/ç§’) | æ˜¾å­˜ (MB) |
|------|-----------|------------------|-----------|
| PyTorchåŸç”Ÿï¼ˆFP32ï¼‰ | 100 | 10 | 1200 |
| PyTorchä¼˜åŒ–ï¼ˆFP16ï¼‰ | 60 | 16 | 600 |
| è™šæ‹ŸBlackwellï¼ˆFP4 + Flashï¼‰ | 35 | 28 | 150 |
| è™šæ‹ŸBlackwell + äº‘ç«¯NPU | 45 | 22 | 0ï¼ˆäº‘ç«¯ï¼‰ |

### 12.3 é•¿ä¸Šä¸‹æ–‡æ€§èƒ½

| ä¸Šä¸‹æ–‡é•¿åº¦ | åŸç”ŸPyTorch | APT + iRoPE | æå‡ |
|-----------|------------|------------|------|
| 4K | 100 ms | 95 ms | 5% |
| 32K | OOM | 380 ms | å¯ç”¨ |
| 128K | OOM | 1.5 s | å¯ç”¨ |
| 1M | OOM | 12 s | å¯ç”¨ |
| **10M** | OOM | **120 s** | **å¯ç”¨** |

### 12.4 è®°å¿†ç³»ç»Ÿæ•ˆæœ

| æŒ‡æ ‡ | æ— è®°å¿† | ChatGPT Memory | åˆ†å±‚è®°å¿† |
|-----|--------|---------------|---------|
| ç»†èŠ‚ä¿ç•™ç‡ | 40% | 70% | **98%** |
| å®šä¹‰æ¼‚ç§»ç‡ | 25% | 15% | **2%** |
| APIæˆæœ¬èŠ‚çœ | 0% | 30% | **50%** |
| ç”¨æˆ·ç•™å­˜ç‡ | åŸºå‡† | +40% | **+70%** |

---

## 13. å¿«é€Ÿå‘½ä»¤å‚è€ƒ

### 13.1 è®­ç»ƒ

```bash
# åŸºç¡€è®­ç»ƒ
python -m apt_model train --data data.txt --epochs 10

# åˆ†å¸ƒå¼è®­ç»ƒ
python -m apt_model train --data data.txt --distributed --num-gpus 4

# å¯ç”¨è™šæ‹ŸBlackwell
python training/start_training.py  # è‡ªåŠ¨å¯ç”¨æ‰€æœ‰ä¼˜åŒ–
```

### 13.2 æ¨ç†

```bash
# äº¤äº’å¼ç”Ÿæˆ
python -m apt_model chat

# æ‰¹é‡æ¨ç†
python -m apt_model generate --input prompts.txt --output results.txt

# WebUI
python -m apt_model.webui.app
```

### 13.3 ä¸€é”®å¯ç”¨ä¼˜åŒ–

```python
import apt_model.optimization.vb_global as vb

# æ–¹å¼1: é»˜è®¤é…ç½®
vb.enable()

# æ–¹å¼2: é¢„è®¾æ¨¡å¼
vb.enable_balanced_mode()       # å¹³è¡¡
vb.enable_max_memory_mode()     # æœ€å¤§æ˜¾å­˜
vb.enable_max_speed_mode()      # æœ€å¤§é€Ÿåº¦
vb.enable_moe_mode()            # MoEä¸“ç”¨
vb.enable_extreme_scale_mode()  # 100K GPU

# æ–¹å¼3: è‡ªå®šä¹‰é…ç½®
vb.enable(
    use_mxfp4=True,
    use_moe_optimized=True,
    enable_extreme_scale=True,
    use_cloud_npu=True
)
```

### 13.4 è®°å¿†ç³»ç»Ÿ

```python
# AIM-Memory æƒ¯æ€§é”šå®šé•œåƒè®°å¿†
from apt_model.memory.aim_memory import create_aim_memory
aim = create_aim_memory()
aim.write_memory("Llama 4 ä½¿ç”¨ iRoPE æ”¯æŒ 10M tokens")
result = aim.answer("10M tokens çš„æ¨¡å‹", auto_mode=True)

# AIM-NC N-gramæ”¶ç¼–åè®®
from apt_model.memory.aim_memory_nc import create_aim_memory_nc
aim_nc = create_aim_memory_nc()
aim_nc.write_memory("YaRN é€šè¿‡åˆ†ç»´åº¦ç¼©æ”¾æ‰©å±• RoPE åˆ° 128K")

# åˆ†å±‚è®°å¿†ï¼ˆé”šç‚¹æŒ‡ä»¤ï¼‰
from apt_model.memory.hierarchical_memory import create_hierarchical_memory
memory = create_hierarchical_memory()
memory.process_anchor_directives("""
ã€å°å­˜Â·åŸæ–‡ã€‘DEF:concept:v1: ç²¾ç¡®å®šä¹‰...
ã€å°å­˜Â·å­—æ®µã€‘PARAM:config:v1: {"alpha": 0.5}
""")
```

### 13.5 Agentå·¥å…·è°ƒç”¨

```python
from apt_model.agent import create_react_agent

# åˆ›å»º Agent
agent = create_react_agent(
    enable_python=True,
    enable_web_search=True
)

# æ‰§è¡Œä»»åŠ¡
result = await agent.run("è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬ 10 é¡¹")
print(result.final_answer)
```

---

## ğŸ“Š æŠ€æœ¯æ€»è§ˆè¡¨

### æ ¸å¿ƒæŠ€æœ¯æ ˆ

| ç±»åˆ« | æŠ€æœ¯ | æ¥æº/æ ‡å‡† | çŠ¶æ€ |
|-----|------|----------|------|
| **æ¶æ„** | Autopoietic Transform | APTåŸåˆ› | âœ… |
| **ç¨³å®šæ€§** | DBC-DAC | APTåŸåˆ› | âœ… |
| **æ•°å€¼ç¨³å®š** | Left-Spin Smooth | APTåŸåˆ› | âœ… |
| **é‡åŒ–** | MXFP4 | Microsoft+OpenAI | âœ… |
| **MoE** | GPUä¼˜åŒ–MoE | Mixtralé£æ ¼ | âœ… |
| **åˆ†å¸ƒå¼** | 100K GPUè®­ç»ƒ | Meta+OpenAI | âœ… |
| **ä½ç½®ç¼–ç ** | iRoPE | Llama 4 | âœ… |
| **ä½ç½®ç¼–ç ** | YaRN | Qwen/DeepSeek | âœ… |
| **ä½ç½®ç¼–ç ** | LongRoPE2 | Phi3/LLaMA3 | âœ… |
| **è®°å¿†** | ChatGPT Memory | OpenAI | âœ… |
| **è®°å¿†** | MemGPT | å­¦æœ¯ç•Œ | âœ… |
| **è®°å¿†** | Mem0 | å·¥ä¸šç•Œ | âœ… |
| **è®°å¿†** | åˆ†å±‚è®°å¿†ï¼ˆA/B/Cæ¡£ï¼‰ | APTåŸåˆ› | âœ… |
| **è®°å¿†** | AIM-Memory | APTåŸåˆ› | âœ… æœ€æ–° |
| **è®°å¿†** | AIM-NCï¼ˆN-gramæ”¶ç¼–ï¼‰ | APTåŸåˆ› | âœ… æœ€æ–° |
| **Agent** | ReActå†³ç­–å¾ªç¯ | å­¦æœ¯ç•Œ | âœ… æœ€æ–° |
| **Agent** | Pythonæ²™ç›’ | å¤šå±‚å®‰å…¨ | âœ… æœ€æ–° |
| **Agent** | å·¥å…·è°ƒç”¨ç³»ç»Ÿ | MCP+OpenAI | âœ… æœ€æ–° |
| **å¼¹æ€§** | MatFormer | Meta AI | âœ… |
| **æŒç»­å­¦ä¹ ** | DyTox | CVPR 2022 | âœ… |
| **è¯¾ç¨‹å­¦ä¹ ** | CAMPUS | Li et al. 2025 | âœ… |
| **ç¡¬ä»¶** | å¤šå‚å•†NPU | ç»Ÿä¸€æ¥å£ | âœ… |
| **äº‘ç«¯** | äº‘ç«¯NPU | åä¸ºäº‘ | âœ… |

### æ€§èƒ½ä¼˜åŠ¿æ±‡æ€»

| ç»´åº¦ | æå‡å¹…åº¦ | å…³é”®æŠ€æœ¯ |
|-----|---------|---------|
| **è®­ç»ƒé€Ÿåº¦** | 5-10Ã— | GPU Flash + DBC |
| **æ¨ç†é€Ÿåº¦** | 2-4Ã— | MXFP4 + Triton Kernel |
| **æ˜¾å­˜å ç”¨** | â†“87.5% | MXFP4é‡åŒ– |
| **è™šæ‹Ÿæ˜¾å­˜** | â†‘21Ã— | VGPU Stack |
| **ä¸Šä¸‹æ–‡é•¿åº¦** | 4K â†’ 10M | iRoPE |
| **NaNç‡** | â†“5Ã— | è®°å¿†å¢å¼ºå·¦æ—‹å¹³æ»‘ |
| **ç»†èŠ‚ä¿ç•™** | +38% | åˆ†å±‚è®°å¿†ç³»ç»Ÿ |
| **å®šä¹‰æ¼‚ç§»** | â†“7.5Ã— | ç‰ˆæœ¬åŒ– + é˜²æ¼‚ç§» |
| **æˆæœ¬** | â†“80% | è™šæ‹ŸBlackwell |
| **FLOPs** | â†“87.5% | MatFormeråµŒå¥— |
| **æ£€ç´¢æˆæœ¬** | â†“70-90% | AIM-Memory æƒ¯æ€§è·¯ç”± |
| **å¬å›æˆæœ¬** | â†“40-60% | AIM-NC N-gramè¿‡æ»¤ |
| **æ•°å­¦å‡†ç¡®ç‡** | +38% | Agent Pythonæ²™ç›’ |
| **å¤šæ­¥æ¨ç†** | +45% | Agent ReActå¾ªç¯ |

---

## ğŸ‰ æ€»ç»“

**APT-Transformer æ˜¯ä¸€ä¸ªå…¨æ ˆ AI è®­ç»ƒå¹³å°**ï¼Œå…·å¤‡ï¼š

### âœ… ä¸–ç•Œçº§æŠ€æœ¯æ ˆ
- Meta Llama 4 çš„ iRoPEï¼ˆ10M tokensï¼‰
- OpenAI GPT-OSS çš„ MXFP4 é‡åŒ–
- Meta MatFormer çš„å¼¹æ€§æ¶æ„
- åŸåˆ›çš„å·¦æ—‹å¹³æ»‘ + åˆ†å±‚è®°å¿†

### âœ… ç”Ÿäº§å°±ç»ª
- å®Œæ•´çš„è®­ç»ƒ/æ¨ç†/è¯„ä¼°æµç¨‹
- 26+ ç”Ÿäº§çº§æ’ä»¶
- WebUI + REST API
- Checkpoint ä¿æŠ¤ + ä¾èµ–å®¹é”™

### âœ… æè‡´æ€§èƒ½
- æˆæœ¬é™ä½ 80%
- æ˜¾å­˜å ç”¨é™ä½ 87.5%
- è®­ç»ƒé€Ÿåº¦æå‡ 5-10Ã—
- æ”¯æŒ 10M tokens é•¿ä¸Šä¸‹æ–‡

### âœ… å¤šå‚å•†æ”¯æŒ
- NVIDIA / Intel / Huawei / AMD
- GPU / HPU / NPU / XPU / CPU
- æœ¬åœ° + äº‘ç«¯æ··åˆéƒ¨ç½²

---

**ç«‹å³å¼€å§‹ä½¿ç”¨ APT-Transformerï¼** ğŸš€

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/chen0430tw/APT-Transformer.git
cd APT-Transformer

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# ä¸€è¡Œå¯ç”¨æ‰€æœ‰ä¼˜åŒ–
python -c "import apt_model.optimization.vb_global as vb; vb.enable()"

# å¼€å§‹è®­ç»ƒ
python -m apt_model train --data data.txt --epochs 10
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2026-01-21
**ç»´æŠ¤è€…**: APT-Transformer Team
**è®¸å¯è¯**: MIT
