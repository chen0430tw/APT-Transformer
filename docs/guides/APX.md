# APX - APT Package Exchange Format

## ğŸ“¦ æ¦‚è¿°

**APX (APT Package Exchange)** æ˜¯APT-Transformeré¡¹ç›®çš„æ ‡å‡†åŒ–æ¨¡å‹æ‰“åŒ…æ ¼å¼ã€‚å®ƒå…è®¸ä½ å°†ä»»ä½•HuggingFaceã€LLaMAã€DeepSeekç­‰ä¸»æµæ¡†æ¶çš„æ¨¡å‹æ‰“åŒ…æˆç»Ÿä¸€çš„`.apx`æ–‡ä»¶ï¼Œå®ç°ï¼š

- âœ… **è·¨æ¡†æ¶å…¼å®¹**ï¼šç»Ÿä¸€çš„æ¥å£è®¿é—®ä¸åŒæ¡†æ¶æ¨¡å‹
- âœ… **å®Œæ•´å°è£…**ï¼šåŒ…å«æ¨¡å‹æƒé‡ã€é…ç½®ã€åˆ†è¯å™¨ã€é€‚é…å™¨ä»£ç 
- âœ… **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ”¯æŒæ’ä»¶å¼æ‰©å±•å’Œèƒ½åŠ›å£°æ˜
- âœ… **è½»é‡éƒ¨ç½²**ï¼šæ”¯æŒthinæ¨¡å¼ï¼ˆä»…æ‰“åŒ…å…ƒæ•°æ®ï¼Œä¸å«æƒé‡ï¼‰
- âœ… **æ ‡å‡†åŒ–ç®¡ç†**ï¼šç‰ˆæœ¬æ§åˆ¶ã€ä¾èµ–ç®¡ç†ã€èƒ½åŠ›æ£€æµ‹

## ğŸ—ï¸ APXåŒ…ç»“æ„

ä¸€ä¸ªæ ‡å‡†çš„`.apx`æ–‡ä»¶æ˜¯ä¸€ä¸ªZIPå‹ç¼©åŒ…ï¼ŒåŒ…å«ä»¥ä¸‹ç»“æ„ï¼š

```
my_model.apx (ZIP)
â”œâ”€â”€ apx.yaml                    # APXæ¸…å•æ–‡ä»¶ï¼ˆå¿…éœ€ï¼‰
â”œâ”€â”€ model/
â”‚   â””â”€â”€ adapters/
â”‚       â”œâ”€â”€ hf_adapter.py       # HuggingFaceé€‚é…å™¨
â”‚       â””â”€â”€ tokenizer_adapter.py # åˆ†è¯å™¨é€‚é…å™¨
â”œâ”€â”€ artifacts/                  # æ¨¡å‹å·¥ä»¶
â”‚   â”œâ”€â”€ config.json            # æ¨¡å‹é…ç½®
â”‚   â”œâ”€â”€ tokenizer.json         # åˆ†è¯å™¨æ–‡ä»¶
â”‚   â”œâ”€â”€ tokenizer.model        # SentencePieceæ¨¡å‹ï¼ˆå¯é€‰ï¼‰
â”‚   â”œâ”€â”€ vocab.json             # è¯æ±‡è¡¨ï¼ˆå¯é€‰ï¼‰
â”‚   â”œâ”€â”€ merges.txt             # BPEåˆå¹¶è§„åˆ™ï¼ˆå¯é€‰ï¼‰
â”‚   â””â”€â”€ model.safetensors      # æ¨¡å‹æƒé‡ï¼ˆfullæ¨¡å¼ï¼‰
â””â”€â”€ tests/                      # æµ‹è¯•æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    â””â”€â”€ smoke.py               # å†’çƒŸæµ‹è¯•
```

## ğŸ“„ apx.yaml æ¸…å•æ ¼å¼

```yaml
apx_version: 1                    # APXæ ¼å¼ç‰ˆæœ¬
name: my-awesome-model            # æ¨¡å‹åç§°
version: 1.0.0                    # æ¨¡å‹ç‰ˆæœ¬
type: model                       # åŒ…ç±»å‹

entrypoints:
  model_adapter: model/adapters/hf_adapter.py:HFAdapter
  tokenizer_adapter: model/adapters/tokenizer_adapter.py:HFTokenizerAdapter

artifacts:                        # å·¥ä»¶æ˜ å°„
  config: artifacts/config.json
  tokenizer: artifacts/tokenizer.json
  weights: artifacts/model.safetensors

capabilities:                     # æ¨¡å‹èƒ½åŠ›å£°æ˜
  provides:
    - text-generation
    - multilingual
    - moe                         # Mixture of Expertsï¼ˆå¯é€‰ï¼‰
    - rag                         # Retrieval-Augmented Generationï¼ˆå¯é€‰ï¼‰
  prefers:
    - builtin                     # ä¼˜å…ˆä½¿ç”¨å†…å»ºåŠŸèƒ½

compose:                          # ç»„åˆé…ç½®ï¼ˆå¯é€‰ï¼‰
  router: observe_only            # è·¯ç”±å™¨æ¨¡å¼
  checkpoint_format: safetensors  # æ£€æŸ¥ç‚¹æ ¼å¼
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

APXè½¬æ¢å™¨ä»…ä¾èµ–Pythonæ ‡å‡†åº“ï¼Œæ— éœ€é¢å¤–å®‰è£…ã€‚ä½†å¦‚æœè¦ä½¿ç”¨HuggingFaceé€‚é…å™¨ï¼Œéœ€è¦ï¼š

```bash
pip install transformers torch
```

### 2. æ‰“åŒ…æ¨¡å‹

#### åŸºç¡€ç”¨æ³•ï¼šæ‰“åŒ…HuggingFaceæ¨¡å‹

```bash
python scripts/apx_converter.py \
  --src /path/to/huggingface/model \
  --out my_model.apx \
  --name my-awesome-model \
  --version 1.0.0
```

#### Fullæ¨¡å¼ï¼ˆåŒ…å«æƒé‡ï¼‰

```bash
python scripts/apx_converter.py \
  --src ./bert-base-chinese \
  --out bert-base-chinese.apx \
  --name bert-base-chinese \
  --version 1.0.0 \
  --mode full
```

#### Thinæ¨¡å¼ï¼ˆä»…å…ƒæ•°æ®ï¼‰

é€‚åˆå·²æœ‰æ¨¡å‹æ–‡ä»¶ï¼Œåªéœ€æ‰“åŒ…é…ç½®å’Œé€‚é…å™¨çš„åœºæ™¯ï¼š

```bash
python scripts/apx_converter.py \
  --src ./llama-7b \
  --out llama-7b-thin.apx \
  --name llama-7b \
  --version 1.0.0 \
  --mode thin
```

Thinæ¨¡å¼ä¼šåœ¨`artifacts/`ä¸­ç”Ÿæˆå ä½æ–‡ä»¶ï¼ŒæŒ‡å‘åŸå§‹æ¨¡å‹è·¯å¾„ï¼š

```json
{
  "__thin__": true,
  "source_weight": "/path/to/original/model.safetensors"
}
```

### 3. é«˜çº§é€‰é¡¹

#### æŒ‡å®šæƒé‡å’Œåˆ†è¯å™¨æ–‡ä»¶

```bash
python scripts/apx_converter.py \
  --src ./deepseek-model \
  --out deepseek.apx \
  --name deepseek \
  --version 2.0.0 \
  --weights-glob "*.safetensors" \
  --tokenizer-glob "tokenizer*" \
  --config-file ./deepseek-model/config.json
```

#### æ·»åŠ èƒ½åŠ›å£°æ˜

```bash
python scripts/apx_converter.py \
  --src ./moe-model \
  --out moe-model.apx \
  --name moe-model \
  --version 1.0.0 \
  --capability text-generation \
  --capability moe \
  --capability multilingual
```

#### æ·»åŠ Composeé…ç½®

```bash
python scripts/apx_converter.py \
  --src ./model \
  --out model.apx \
  --name my-model \
  --version 1.0.0 \
  --compose router=observe_only \
  --compose checkpoint_format=safetensors
```

#### æ·»åŠ å†’çƒŸæµ‹è¯•

```bash
python scripts/apx_converter.py \
  --src ./model \
  --out model.apx \
  --name my-model \
  --version 1.0.0 \
  --add-test
```

## ğŸ”§ CLIå‘½ä»¤

APT-Transformeræä¾›äº†å®Œæ•´çš„APXå‘½ä»¤è¡Œå·¥å…·ï¼š

### æ‰“åŒ…æ¨¡å‹

```bash
# ä½¿ç”¨CLIå‘½ä»¤ï¼ˆæ¨èï¼‰
python -m apt_model pack-apx \
  --src /path/to/model \
  --out model.apx \
  --name my-model \
  --version 1.0.0
```

### æ£€æµ‹æ¨¡å‹æ¡†æ¶

```bash
python -m apt_model detect-framework --src /path/to/model
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
[info] Detected framework: huggingface
```

### è‡ªåŠ¨æ£€æµ‹æ¨¡å‹èƒ½åŠ›

```bash
python -m apt_model detect-capabilities --src /path/to/model
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
[info] Detected capabilities:
  - text-generation
  - multilingual
  - moe
```

### æŸ¥çœ‹APXåŒ…ä¿¡æ¯

```bash
python -m apt_model apx-info --apx model.apx
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
[APX Manifest]
apx_version: 1
name: my-model
version: 1.0.0
type: model
entrypoints:
  model_adapter: model/adapters/hf_adapter.py:HFAdapter
  tokenizer_adapter: model/adapters/tokenizer_adapter.py:HFTokenizerAdapter
...
```

## ğŸ¯ é€‚é…å™¨ç³»ç»Ÿ

### HuggingFaceé€‚é…å™¨

APXå†…ç½®çš„HuggingFaceé€‚é…å™¨æä¾›æ ‡å‡†æ¥å£ï¼š

```python
from apt_model.tools.apx import load_apx

# åŠ è½½APXåŒ…
model_adapter = load_apx("my_model.apx")

# ç”Ÿæˆæ–‡æœ¬
texts = ["Hello, how are you?", "What is AI?"]
outputs = model_adapter.generate(texts, max_new_tokens=64)

for text, output in zip(texts, outputs):
    print(f"è¾“å…¥: {text}")
    print(f"è¾“å‡º: {output}\n")
```

### è‡ªå®šä¹‰é€‚é…å™¨

ä½ ä¹Ÿå¯ä»¥åˆ›å»ºè‡ªå®šä¹‰é€‚é…å™¨æ¥æ”¯æŒç‰¹æ®Šæ¨¡å‹ï¼š

```python
# custom_adapter.py
class CustomAdapter:
    def __init__(self, model, tokenizer):
        self.model = model
        self.tokenizer = tokenizer

    @classmethod
    def from_artifacts(cls, artifacts_dir: str):
        # ä»artifacts/åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
        model = load_custom_model(artifacts_dir)
        tokenizer = load_custom_tokenizer(artifacts_dir)
        return cls(model, tokenizer)

    def generate(self, texts, max_new_tokens=64):
        # å®ç°ç”Ÿæˆé€»è¾‘
        ...
```

ç„¶åä½¿ç”¨`--adapter stub`å‚æ•°å¹¶æ‰‹åŠ¨æ›¿æ¢é€‚é…å™¨æ–‡ä»¶ã€‚

## ğŸ“Š èƒ½åŠ›æ£€æµ‹ç³»ç»Ÿ

APXæ”¯æŒè‡ªåŠ¨æ£€æµ‹æ¨¡å‹çš„ä»¥ä¸‹èƒ½åŠ›ï¼š

| èƒ½åŠ›æ ‡è¯† | è¯´æ˜ | æ£€æµ‹ä¾æ® |
|---------|------|---------|
| `moe` | Mixture of Experts | é…ç½®ä¸­æœ‰`num_experts`æˆ–`moe`å…³é”®è¯ |
| `rag` | æ£€ç´¢å¢å¼ºç”Ÿæˆ | å­˜åœ¨`retriever`ã€`knowledge_base`ç­‰å…³é”®è¯ |
| `rlhf` | äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹  | å­˜åœ¨`reward_model`ã€`rlhf`ç­‰å…³é”®è¯ |
| `multimodal` | å¤šæ¨¡æ€ï¼ˆè§†è§‰+æ–‡æœ¬ï¼‰ | å­˜åœ¨`vision`ã€`image_processor`ç­‰ |
| `multilingual` | å¤šè¯­è¨€ | è¯æ±‡è¡¨å¤§å°>50000æˆ–é…ç½®æ ‡æ³¨multilingual |
| `code-generation` | ä»£ç ç”Ÿæˆ | æ¨¡å‹åç§°åŒ…å«`code`ã€`codex`ç­‰ |
| `long-context` | é•¿ä¸Šä¸‹æ–‡ | `max_position_embeddings` > 4096 |

### èƒ½åŠ›æ£€æµ‹ç¤ºä¾‹

```python
from apt_model.tools.apx import detect_capabilities
from pathlib import Path

capabilities = detect_capabilities(Path("/path/to/model"))
print("Detected capabilities:", capabilities)
# è¾“å‡º: ['text-generation', 'multilingual', 'long-context']
```

## ğŸ” æ¡†æ¶æ£€æµ‹

APXèƒ½è‡ªåŠ¨è¯†åˆ«æ¨¡å‹æ¥è‡ªå“ªä¸ªæ¡†æ¶ï¼š

| æ¡†æ¶ç±»å‹ | è¯†åˆ«æ ‡å¿— |
|---------|---------|
| `huggingface` | å­˜åœ¨`config.json`ä¸”åŒ…å«`architectures`æˆ–`model_type` |
| `structured` | å­˜åœ¨`params.json`ã€`lit_config.json`ã€`config.yml`ç­‰ |
| `unknown` | æ— æ³•è¯†åˆ« |

```python
from apt_model.tools.apx import detect_framework
from pathlib import Path

framework = detect_framework(Path("/path/to/model"))
print(f"Framework: {framework}")
# è¾“å‡º: huggingface
```

## ğŸ“¦ å®Œæ•´ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šæ‰“åŒ…å¹¶åŠ è½½BERTæ¨¡å‹

```bash
# 1. æ‰“åŒ…BERT
python scripts/apx_converter.py \
  --src ./bert-base-chinese \
  --out bert.apx \
  --name bert-base-chinese \
  --version 1.0.0 \
  --capability text-classification \
  --capability multilingual \
  --add-test

# 2. æŸ¥çœ‹åŒ…ä¿¡æ¯
python -m apt_model apx-info --apx bert.apx

# 3. ä½¿ç”¨æ¨¡å‹
python -c "
from apt_model.tools.apx import load_apx

model = load_apx('bert.apx')
texts = ['æˆ‘çˆ±ä¸­å›½', 'äººå·¥æ™ºèƒ½å¾ˆå¼ºå¤§']
outputs = model.generate(texts, max_new_tokens=20)
print(outputs)
"
```

### ç¤ºä¾‹2ï¼šæ‰“åŒ…LLaMAæ¨¡å‹ï¼ˆThinæ¨¡å¼ï¼‰

```bash
# 1. ä»…æ‰“åŒ…å…ƒæ•°æ®ï¼ˆæ¨¡å‹æƒé‡ä¿ç•™åœ¨åŸä½ç½®ï¼‰
python scripts/apx_converter.py \
  --src /mnt/models/llama-7b \
  --out llama-7b-thin.apx \
  --name llama-7b \
  --version 1.0.0 \
  --mode thin \
  --capability text-generation \
  --capability long-context

# 2. éƒ¨ç½²æ—¶ç›´æ¥ä½¿ç”¨ï¼ˆæ¨¡å‹ä»åŸè·¯å¾„åŠ è½½ï¼‰
```

### ç¤ºä¾‹3ï¼šæ‰“åŒ…è‡ªå®šä¹‰æ¨¡å‹

```bash
# 1. æ‰“åŒ…è‡ªå®šä¹‰ç»“æ„æ¨¡å‹
python scripts/apx_converter.py \
  --src ./my_custom_model \
  --out custom.apx \
  --name my-custom-model \
  --version 2.0.0 \
  --config-file ./my_custom_model/model_config.json \
  --weights-glob "*.pth" \
  --tokenizer-glob "tokenizer/*" \
  --adapter stub \
  --capability custom-task

# 2. æ‰‹åŠ¨ä¿®æ”¹é€‚é…å™¨ï¼ˆè§£å‹APXï¼Œç¼–è¾‘adapters/ï¼Œé‡æ–°æ‰“åŒ…ï¼‰
```

## ğŸ› ï¸ é«˜çº§åŠŸèƒ½

### 1. å¤šæ¨¡å‹ç»„åˆï¼ˆComposeï¼‰

é€šè¿‡`compose`é…ç½®å®ç°æ¨¡å‹ç»„åˆå’Œè·¯ç”±ï¼š

```yaml
compose:
  router: observe_only          # ä»…è§‚å¯Ÿï¼Œä¸å¹²é¢„
  ensemble_strategy: voting     # æŠ•ç¥¨ç­–ç•¥
  checkpoint_format: safetensors
```

### 2. æ’ä»¶ç³»ç»Ÿé›†æˆ

APXæ”¯æŒä¸APTæ’ä»¶ç³»ç»Ÿé›†æˆï¼š

```yaml
capabilities:
  provides:
    - custom-capability
  prefers:
    - plugin                    # ä¼˜å…ˆä½¿ç”¨æ’ä»¶å®ç°
```

### 3. ç‰ˆæœ¬ç®¡ç†

APXåŒ…æ”¯æŒè¯­ä¹‰åŒ–ç‰ˆæœ¬æ§åˆ¶ï¼š

```bash
# æ‰“åŒ…ä¸åŒç‰ˆæœ¬
python scripts/apx_converter.py --src ./model --out model-v1.0.0.apx --name model --version 1.0.0
python scripts/apx_converter.py --src ./model --out model-v1.1.0.apx --name model --version 1.1.0
python scripts/apx_converter.py --src ./model --out model-v2.0.0.apx --name model --version 2.0.0
```

## ğŸ“ å‘½ä»¤è¡Œå‚æ•°å®Œæ•´åˆ—è¡¨

### apx_converter.py å‚æ•°

```bash
--src PATH                # æºæ¨¡å‹ç›®å½•ï¼ˆå¿…éœ€ï¼‰
--out PATH                # è¾“å‡º.apxæ–‡ä»¶è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
--name NAME               # APXåŒ…åç§°ï¼ˆå¿…éœ€ï¼‰
--version VERSION         # APXåŒ…ç‰ˆæœ¬ï¼ˆå¿…éœ€ï¼‰
--adapter {hf,stub}       # é€‚é…å™¨ç±»å‹ï¼ˆé»˜è®¤ï¼šhfï¼‰
--mode {full,thin}        # æ‰“åŒ…æ¨¡å¼ï¼ˆé»˜è®¤ï¼šfullï¼‰
--weights-glob PATTERN    # æƒé‡æ–‡ä»¶globæ¨¡å¼ï¼ˆå¯é€‰ï¼‰
--tokenizer-glob PATTERN  # åˆ†è¯å™¨æ–‡ä»¶globæ¨¡å¼ï¼ˆå¯é€‰ï¼‰
--config-file PATH        # æ˜¾å¼æŒ‡å®šconfig.jsonï¼ˆå¯é€‰ï¼‰
--prefers {builtin,plugin} # ä¼˜å…ˆçº§ï¼ˆé»˜è®¤ï¼šbuiltinï¼‰
--capability CAP          # èƒ½åŠ›å£°æ˜ï¼ˆå¯å¤šæ¬¡æŒ‡å®šï¼‰
--compose KEY=VALUE       # Composeé…ç½®ï¼ˆå¯å¤šæ¬¡æŒ‡å®šï¼‰
--thin                    # ç­‰ä»·äº--mode thin
--add-test                # æ·»åŠ å†’çƒŸæµ‹è¯•
```

### CLIå‘½ä»¤å‚æ•°

```bash
# pack-apxå‘½ä»¤
python -m apt_model pack-apx \
  --src PATH              # æºæ¨¡å‹ç›®å½•
  --out PATH              # è¾“å‡º.apxè·¯å¾„
  --name NAME             # æ¨¡å‹åç§°
  --version VERSION       # æ¨¡å‹ç‰ˆæœ¬
  [å…¶ä»–å‚æ•°åŒapx_converter.py]

# detect-capabilitieså‘½ä»¤
python -m apt_model detect-capabilities \
  --src PATH              # æºæ¨¡å‹ç›®å½•

# detect-frameworkå‘½ä»¤
python -m apt_model detect-framework \
  --src PATH              # æºæ¨¡å‹ç›®å½•

# apx-infoå‘½ä»¤
python -m apt_model apx-info \
  --apx PATH              # APXæ–‡ä»¶è·¯å¾„
```

## ğŸ­ ä½¿ç”¨åœºæ™¯

### 1. æ¨¡å‹åˆ†å‘
æ‰“åŒ…æ¨¡å‹ä¸ºAPXæ ¼å¼ï¼Œæ–¹ä¾¿åˆ†äº«å’Œéƒ¨ç½²ã€‚

### 2. ç‰ˆæœ¬æ§åˆ¶
å¯¹åŒä¸€æ¨¡å‹çš„ä¸åŒç‰ˆæœ¬è¿›è¡Œæ ‡å‡†åŒ–ç®¡ç†ã€‚

### 3. è·¨æ¡†æ¶è¿ç§»
ç»Ÿä¸€æ¥å£è®¿é—®ä¸åŒæ¡†æ¶çš„æ¨¡å‹ã€‚

### 4. è½»é‡éƒ¨ç½²
ä½¿ç”¨thinæ¨¡å¼åœ¨å¤šä¸ªç¯å¢ƒä¸­å…±äº«åŒä¸€æ¨¡å‹æ–‡ä»¶ã€‚

### 5. èƒ½åŠ›å£°æ˜
é€šè¿‡æ ‡å‡†åŒ–å…ƒæ•°æ®å£°æ˜æ¨¡å‹èƒ½åŠ›ï¼Œä¾¿äºè‡ªåŠ¨åŒ–é€‰æ‹©å’Œè·¯ç”±ã€‚

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### å·¥ä»¶æ–‡ä»¶å€™é€‰åˆ—è¡¨

APXè½¬æ¢å™¨ä¼šè‡ªåŠ¨æœç´¢ä»¥ä¸‹æ–‡ä»¶ï¼š

**åˆ†è¯å™¨æ–‡ä»¶**ï¼š
- `tokenizer.json`
- `tokenizer.model`
- `sentencepiece.bpe.model`
- `sp.model`
- `tokenizer_config.json`
- `vocab.json`
- `merges.txt`

**æƒé‡æ–‡ä»¶**ï¼ˆé»˜è®¤globï¼‰ï¼š
- `*.safetensors`
- `pytorch_model*.bin`
- `consolidated*.pth`

### é€‚é…å™¨æ¥å£è§„èŒƒ

è‡ªå®šä¹‰é€‚é…å™¨å¿…é¡»å®ç°ä»¥ä¸‹æ¥å£ï¼š

```python
class CustomAdapter:
    @classmethod
    def from_artifacts(cls, artifacts_dir: str):
        """ä»artifactsç›®å½•åŠ è½½æ¨¡å‹"""
        ...

    def encode(self, texts, max_new_tokens=0):
        """ç¼–ç æ–‡æœ¬"""
        ...

    def generate(self, texts, max_new_tokens=64):
        """ç”Ÿæˆæ–‡æœ¬"""
        ...

    def forward(self, batch):
        """å‰å‘ä¼ æ’­"""
        ...

    def save_pretrained(self, out_dir: str):
        """ä¿å­˜æ¨¡å‹"""
        ...
```

## ğŸ†˜ å¸¸è§é—®é¢˜

### Q1: æ‰“åŒ…åAPXæ–‡ä»¶è¿‡å¤§ï¼Ÿ
**A**: ä½¿ç”¨`--mode thin`ä»…æ‰“åŒ…å…ƒæ•°æ®ï¼Œæƒé‡ä¿ç•™åœ¨åŸä½ç½®ã€‚

### Q2: å¦‚ä½•æ‰“åŒ…éHuggingFaceæ¨¡å‹ï¼Ÿ
**A**: ä½¿ç”¨`--adapter stub`ï¼Œç„¶åæ‰‹åŠ¨ç¼–è¾‘é€‚é…å™¨ä»£ç ã€‚

### Q3: èƒ½åŠ›æ£€æµ‹ä¸å‡†ç¡®ï¼Ÿ
**A**: ä½¿ç”¨`--capability`å‚æ•°æ‰‹åŠ¨æŒ‡å®šèƒ½åŠ›ï¼š
```bash
--capability moe --capability rag --capability multilingual
```

### Q4: APXåŒ…å¦‚ä½•è§£å‹æŸ¥çœ‹ï¼Ÿ
**A**: APXæœ¬è´¨æ˜¯ZIPæ–‡ä»¶ï¼Œå¯ä»¥ç›´æ¥è§£å‹ï¼š
```bash
unzip model.apx -d model_extracted/
```

### Q5: å¦‚ä½•åœ¨APTé¡¹ç›®ä¸­ä½¿ç”¨APXåŒ…ï¼Ÿ
**A**: ä½¿ç”¨`load_apx()`å‡½æ•°ï¼š
```python
from apt_model.tools.apx import load_apx
model = load_apx("model.apx")
```

## ğŸ“ ç›¸å…³æ–‡ä»¶ä½ç½®

- **è½¬æ¢å™¨è„šæœ¬**: `scripts/apx_converter.py`
- **CLIå‘½ä»¤**: `apt_model/cli/apx_commands.py`
- **APXåŠ è½½å™¨**: `apt_model/console/apx_loader.py`
- **å·¥å…·æ¨¡å—**: `apt_model/tools/apx.py`ï¼ˆå¦‚æœå­˜åœ¨ï¼‰

## ğŸ“š å‚è€ƒèµ„æ–™

- **æ¨¡å‹é€‚é…å™¨å¼€å‘**: æŸ¥çœ‹`apt_model/modeling/`ç›®å½•ä¸‹çš„é€‚é…å™¨ç¤ºä¾‹
- **æ’ä»¶ç³»ç»Ÿ**: å‚è€ƒ`apt_model/plugins/README.md`
- **æ£€æŸ¥ç‚¹ç®¡ç†**: `apt_model/training/checkpoint.py`

## ğŸ¤ è´¡çŒ®æŒ‡å—

å¦‚æœä½ æƒ³ä¸ºAPXæ ¼å¼æ·»åŠ æ–°åŠŸèƒ½ï¼š

1. æ‰©å±•`apx.yaml`æ ¼å¼å®šä¹‰
2. æ›´æ–°`scripts/apx_converter.py`ä¸­çš„æ‰“åŒ…é€»è¾‘
3. æ·»åŠ ç›¸åº”çš„èƒ½åŠ›æ£€æµ‹è§„åˆ™
4. æ›´æ–°æœ¬æ–‡æ¡£

---

**è´¡çŒ®è€…**: APT-Transformerå›¢é˜Ÿ
**æœ€åæ›´æ–°**: 2025-12-04
**è®¸å¯**: ä¸APT-Transformeré¡¹ç›®ç›¸åŒ
