# HLBDæ¨¡å—åŒ–è®­ç»ƒæŒ‡å—

## ğŸ¯ æ¦‚è¿°

æ¨¡å—åŒ–è®­ç»ƒæ˜¯ä¸€ç§**åŒæ—¶åŠ è½½å¤šä¸ªHLBDæ•°æ®é›†è¿›è¡Œè”åˆè®­ç»ƒ**çš„æ–¹æ³•ï¼Œå¯ä»¥åœ¨å•æ¬¡è®­ç»ƒä¸­åˆ©ç”¨ä¸åŒæ•°æ®é›†çš„äº’è¡¥ç‰¹æ€§ã€‚

### æ ¸å¿ƒä¼˜åŠ¿

| ç‰¹æ€§ | å•æ•°æ®é›†è®­ç»ƒ | æ¨¡å—åŒ–è®­ç»ƒ |
|------|-------------|-----------|
| æ ·æœ¬æ•°é‡ | 5,000 | 10,000+ |
| è®­ç»ƒè½®æ¬¡ | éœ€è¦2æ¬¡ | ä»…éœ€1æ¬¡ |
| å­¦ä¹ å¤šæ ·æ€§ | å•ä¸€ç‰¹æ€§ | äº’è¡¥ç‰¹æ€§ |
| GPUåˆ©ç”¨ç‡ | æ ‡å‡† | æ›´é«˜ |
| è®­ç»ƒæ—¶é—´ | 2Ã— | 1Ã— |

## ğŸ“Š æ”¯æŒçš„æ•°æ®é›†

### 1. HLBD Full V2 (5000æ ·æœ¬)

**æ•°æ®ç‰¹ç‚¹**:
- âœ“ 8å±‚åˆ†å±‚è¯­è¨€ç»“æ„
- âœ“ **Level 3å¥æ³•å±‚** (S = NP + VP)
- âœ“ å¤šè¯­è¨€è¦†ç›–ï¼ˆä¸­è‹±æ—¥éŸ©ï¼‰
- âœ“ Emoji + æ‹¼éŸ³ + è¯­æ³•

**è®­ç»ƒé‡ç‚¹**:
- å¤šè¯­è¨€ç†è§£
- å¥æ³•ç»“æ„å­¦ä¹ 
- è·¨è¯­è¨€æ˜ å°„
- åˆ†å±‚è¡¨ç¤º

**ç¤ºä¾‹æ ·æœ¬**:
```json
{
  "concept": "ä¸‹é›¨",
  "level_1": {"å­—å¡": "ä¸‹é›¨", "emoji": "ğŸŒ§ï¸"},
  "level_2": {"çŸ­è¯­": "ä¸‹é›¨äº†"},
  "level_3": {"æ•°å­¦": "S = NP + VP (NP: å¤©æ°”, VP: ä¸‹é›¨)"},
  "level_4": {"æ‹¼éŸ³": "xiÃ  yÇ”"},
  "level_5": {"è‹±æ–‡": "It's raining"},
  "level_6": {"ä¸­æ–‡": "ä»Šå¤©å¤©æ°”é˜´æ²‰ï¼Œä¸‹é›¨äº†ã€‚"},
  "level_7": {"æ—¥æ–‡": "é›¨ãŒé™ã£ã¦ã„ã¾ã™"},
  "level_8": {"éŸ©æ–‡": "ë¹„ê°€ ì˜¤ê³  ìˆì–´ìš”"}
}
```

### 2. HLBD Hardcore V2 (5042æ ·æœ¬)

**æ•°æ®ç‰¹ç‚¹**:
- âœ“ ä¸¥æ ¼é€»è¾‘é—®ç­”
- âœ“ 5å¤§æ¨¡å—å…¨è¦†ç›–
- âœ“ é˜²"å·æ‡’"å­¦ä¹ 
- âœ“ æ•°æ®ç¨€é‡Šå­¦

**è®­ç»ƒé‡ç‚¹**:
- å‡ ä½•è®¡ç®—
- ç®—æœ¯è¿ç®—
- ç”Ÿè‚–æ¨ç†
- ç‰©ç†å®šå¾‹
- è‹±æ–‡ç¿»è¯‘

**æ¨¡å—åˆ†å¸ƒ**:
| æ¨¡å— | æ ·æœ¬æ•° | å æ¯” |
|------|--------|------|
| å‡ ä½•å®šä¹‰ | 860 | 17.1% |
| ç®—æœ¯è¿ç®— | 1,899 | 37.7% |
| ç”Ÿè‚–åºåˆ— | 528 | 10.5% |
| ç‰©ç†å®šå¾‹ | 825 | 16.4% |
| åå‘å­¦è‹±æ–‡ | 930 | 18.4% |
| **æ€»è®¡** | **5,042** | **100%** |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³•1: ä½¿ç”¨å¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
python3 launch_hlbd_modular_training.py
```

**å¯åŠ¨å™¨åŠŸèƒ½**:
- âœ“ è‡ªåŠ¨æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶
- âœ“ éªŒè¯Pythonä¾èµ–
- âœ“ é¢„é…ç½®æœ€ä½³å‚æ•°
- âœ“ ä¸€é”®å¯åŠ¨è®­ç»ƒ

### æ–¹æ³•2: ç›´æ¥è°ƒç”¨è®­ç»ƒè„šæœ¬

```bash
python3 training/train_hlbd_playground.py \
    --datasets data/HLBD_Full_V2.json data/HLBD_Hardcore_Full_V2.json \
    --epochs 50 \
    --save-dir hlbd_modular \
    --save-interval 10
```

### æ–¹æ³•3: è‡ªå®šä¹‰é…ç½®

```bash
# åªè®­ç»ƒHLBD Fullï¼ˆå•æ•°æ®é›†ï¼‰
python3 training/train_hlbd_playground.py \
    --dataset data/HLBD_Full_V2.json \
    --epochs 100

# è®­ç»ƒæ‰€æœ‰å¯ç”¨æ•°æ®é›†
python3 training/train_hlbd_playground.py \
    --datasets data/*.json \
    --epochs 50
```

## ğŸ—ï¸ å·¥ä½œåŸç†

### 1. æ•°æ®åŠ è½½æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         æ¨¡å—åŒ–æ•°æ®é›†åŠ è½½å™¨                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HLBD Full V2  â”‚       â”‚ HLBD Hardcore â”‚
â”‚  (5000æ ·æœ¬)   â”‚       â”‚   (5042æ ·æœ¬)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚
        â”‚  è‡ªåŠ¨æ ¼å¼è¯†åˆ«          â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
        â””â”€â–ºâ”‚ æ ¼å¼æ£€æµ‹å™¨   â”‚â—„â”€â”€â”€â”€â”€â”˜
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
          â–¼               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Fullå¤„ç†â”‚     â”‚Hardcore â”‚
    â”‚ (8å±‚)   â”‚     â”‚ å¤„ç†    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚               â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  ç»Ÿä¸€æ ¼å¼è½¬æ¢  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  æ··åˆæ‰“æ•£      â”‚
          â”‚  (é˜²åç¼©)      â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ è®­ç»ƒæ•°æ®é›†     â”‚
          â”‚ (10,042å¯¹)    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. æ ¼å¼è‡ªåŠ¨è¯†åˆ«

**HLBD Fullæ ¼å¼æ£€æµ‹**:
```python
if 'samples' in data:
    # 8å±‚ç»“æ„
    return self._process_hlbd_full(data['samples'])
```

**HLBD Hardcoreæ ¼å¼æ£€æµ‹**:
```python
elif 'data' in data:
    # æ¨¡å—åŒ–Q&A
    return self._process_hlbd_hardcore(data['data'])
```

### 3. ç»Ÿä¸€æ ¼å¼è½¬æ¢

#### HLBD Full â†’ è®­ç»ƒå¯¹

**è¾“å…¥**:
```
æ¦‚å¿µ: ä¸‹é›¨
[EMOJI] ä¸‹é›¨ ğŸŒ§ï¸
[PHRASE] ä¸‹é›¨äº†
å¥æ³•ç»“æ„: S = NP + VP (NP: å¤©æ°”, VP: ä¸‹é›¨)
```

**è¾“å‡º**:
```
[PY] xiÃ  yÇ”
[EN] It's raining
ä»Šå¤©å¤©æ°”é˜´æ²‰ï¼Œä¸‹é›¨äº†ã€‚
[JP] é›¨ãŒé™ã£ã¦ã„ã¾ã™
[KR] ë¹„ê°€ ì˜¤ê³  ìˆì–´ìš”
```

#### HLBD Hardcore â†’ è®­ç»ƒå¯¹

**è¾“å…¥**: `ä¸‰è§’å½¢æœ‰å‡ æ¡è¾¹ï¼Ÿ`
**è¾“å‡º**: `3`

### 4. æ•°æ®æ··åˆç­–ç•¥

```python
# åŠ è½½æ‰€æœ‰æ•°æ®é›†
all_pairs = []
for dataset in datasets:
    pairs = load_dataset(dataset)
    all_pairs.extend(pairs)

# éšæœºæ‰“æ•£ï¼ˆæ•°æ®ç¨€é‡Šå­¦ï¼‰
random.shuffle(all_pairs)

# ç»“æœï¼šæ— å›ºå®šé¡ºåºï¼Œé˜²æ­¢æ¨¡å¼åç¼©
```

## ğŸ“ˆ è®­ç»ƒé…ç½®

### æ¨èé…ç½®ï¼ˆRTX 3070ï¼‰

```python
{
    # æ¨¡å‹é…ç½®
    "d_model": 256,
    "n_layers": 6,
    "n_heads": 8,
    "d_ff": 1024,
    "max_seq_len": 256,
    "dropout": 0.1,

    # è®­ç»ƒé…ç½®
    "batch_size": 16,
    "gradient_accumulation_steps": 2,  # æœ‰æ•ˆbatch=32
    "mixed_precision": True,
    "epochs": 50,

    # å­¦ä¹ ç‡è°ƒåº¦
    "base_lr": 3e-4,
    "min_lr": 1e-5,
    "scheduler": "CosineAnnealingWarmRestarts",
    "T_0": 10,  # é‡å¯å‘¨æœŸ

    # ä¼˜åŒ–
    "optimizer": "AdamW",
    "weight_decay": 0.01,
    "max_grad_norm": 1.0,
    "use_dbc_dac": True  # DBC-DACæ¢¯åº¦ç¨³å®š
}
```

### è°ƒä¼˜å»ºè®®

#### å†…å­˜ä¸è¶³

```bash
# å‡å°batch size
--batch-size 8

# æˆ–å‡å°æ¨¡å‹å°ºå¯¸
# ä¿®æ”¹ training/train_hlbd_playground.py:
# PlaygroundConfig.d_model = 128
```

#### è®­ç»ƒå¤ªæ…¢

```bash
# å‡å°‘epochs
--epochs 30

# æˆ–å¢åŠ ä¿å­˜é—´éš”
--save-interval 20
```

#### æé«˜ç²¾åº¦

```bash
# å¢åŠ è®­ç»ƒè½®æ•°
--epochs 100

# æˆ–é™ä½å­¦ä¹ ç‡
# ä¿®æ”¹ PlaygroundConfig.base_lr = 1e-4
```

## ğŸ“Š è®­ç»ƒç›‘æ§

### å®æ—¶æ—¥å¿—

è®­ç»ƒæ—¶ä¼šæ˜¾ç¤ºï¼š

```
ğŸ“š æ¨¡å—åŒ–HLBDæ•°æ®é›†åŠ è½½å™¨
   æ•°æ®é›†æ•°é‡: 2
============================================================

ğŸ“‚ [1/2] åŠ è½½æ•°æ®é›†: data/HLBD_Full_V2.json
   æ ¼å¼: HLBD Full (8å±‚ç»“æ„)
   âœ“ æˆåŠŸåŠ è½½ 5000 ä¸ªè®­ç»ƒå¯¹

ğŸ“‚ [2/2] åŠ è½½æ•°æ®é›†: data/HLBD_Hardcore_Full_V2.json
   æ ¼å¼: HLBD Hardcore (æ¨¡å—åŒ–)
   âœ“ æˆåŠŸåŠ è½½ 5042 ä¸ªè®­ç»ƒå¯¹

ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:
   HLBD_Full_V2: 5000 å¯¹ (49.8%)
   HLBD_Hardcore_Full_V2: 5042 å¯¹ (50.2%)
   æ€»è®¡: 10042 ä¸ªè®­ç»ƒå¯¹
   âœ“ å·²æ··åˆæ‰“æ•£
```

### Lossæ›²çº¿

```
Epoch 1:  Loss: 4.2   (åˆæœŸé«˜loss)
Epoch 10: Loss: 1.5   (å¿«é€Ÿä¸‹é™)
Epoch 30: Loss: 0.4   (ç¨³å®šæ”¶æ•›)
Epoch 50: Loss: 0.15  (ç†æƒ³æ”¶æ•›)
```

### ä¿å­˜çš„æ–‡ä»¶

```
hlbd_modular/
â”œâ”€â”€ checkpoint_epoch_10.pt      # å®šæœŸcheckpoint
â”œâ”€â”€ checkpoint_epoch_20.pt
â”œâ”€â”€ checkpoint_epoch_30.pt
â”œâ”€â”€ checkpoint_epoch_40.pt
â”œâ”€â”€ final_model.pt              # æœ€ç»ˆæ¨¡å‹
â””â”€â”€ experiment_report.json      # è®­ç»ƒæ›²çº¿ï¼ˆå¯è§†åŒ–ï¼‰
```

### Checkpointå†…å®¹

```python
checkpoint = {
    'epoch': 50,
    'model_state_dict': {...},
    'optimizer_state_dict': {...},
    'tokenizer_char_to_id': {...},
    'losses': [4.2, 3.1, ..., 0.15],
    'dataset_stats': {              # â† æ–°å¢ï¼
        'HLBD_Full_V2': 5000,
        'HLBD_Hardcore_Full_V2': 5042
    }
}
```

## ğŸ”¬ é˜²æ¨¡å¼åç¼©æœºåˆ¶

### ä»€ä¹ˆæ˜¯æ¨¡å¼åç¼©ï¼Ÿ

æ¨¡å‹åœ¨è®­ç»ƒæ—¶"å·æ‡’"ï¼š
- âŒ è®°å¿†è®­ç»ƒé›†é¡ºåº
- âŒ è¾“å‡ºæœ€å¸¸è§ç­”æ¡ˆ
- âŒ ä¾èµ–å›ºå®šæ¨¡å¼

### æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆ

#### 1. æ•°æ®ç¨€é‡Šå­¦

```python
# ä¸åŒæ•°æ®é›†æ··åˆ
HLBD Full (ç»“æ„åŒ–) + HLBD Hardcore (é€»è¾‘åŒ–)
= é˜²æ­¢è¿‡æ‹ŸåˆæŸä¸€ç§æ¨¡å¼
```

#### 2. å®Œå…¨éšæœºæ‰“æ•£

```python
random.shuffle(all_samples)
# æ¯æ¬¡epoché¡ºåºéƒ½ä¸åŒ
```

#### 3. å¤šæ ·åŒ–è¡¨è¿°

**HLBD Full**: 8ç§ä¸åŒè¯­è¨€è¡¨è¾¾
**HLBD Hardcore**: 3-6ç§é—®æ³•å˜ä½“

#### 4. å¤§è§„æ¨¡æ ·æœ¬

10,000+ æ ·æœ¬ â†’ éš¾ä»¥è®°å¿†å…¨éƒ¨

## ğŸ“‹ æœ€ä½³å®è·µ

### âœ… æ¨èåšæ³•

1. **ä½¿ç”¨æ¨¡å—åŒ–è®­ç»ƒ**
   ```bash
   python3 launch_hlbd_modular_training.py
   ```

2. **å®šæœŸä¿å­˜checkpoint**
   ```bash
   --save-interval 10  # æ¯10è½®ä¿å­˜ä¸€æ¬¡
   ```

3. **ç›‘æ§è®­ç»ƒæ›²çº¿**
   ```bash
   # ä½¿ç”¨å¯è§†åŒ–è„šæœ¬
   python3 tools/visualize_experiment.py hlbd_modular/experiment_report.json
   ```

4. **éªŒè¯æ•°æ®é›†è´¨é‡**
   ```bash
   # æ£€æŸ¥HLBD Fullçš„level_3è¦†ç›–ç‡
   python3 -c "
   import json
   data = json.load(open('data/HLBD_Full_V2.json'))
   samples = data['samples']
   level_3 = sum(1 for s in samples if 'level_3' in s)
   print(f'level_3è¦†ç›–ç‡: {level_3/len(samples)*100}%')
   "
   ```

### âŒ é¿å…äº‹é¡¹

1. **ä¸è¦æ··åˆæœªéªŒè¯çš„æ•°æ®é›†**
   - å¯èƒ½å¼•å…¥å™ªå£°
   - å¯¼è‡´è®­ç»ƒä¸ç¨³å®š

2. **ä¸è¦è¿‡åº¦å¢åŠ batch size**
   - å¯èƒ½å¯¼è‡´losséœ‡è¡
   - GPUå†…å­˜ä¸è¶³

3. **ä¸è¦å¿½ç•¥æ•°æ®é›†å¹³è¡¡**
   - æŸ¥çœ‹dataset_stats
   - ç¡®ä¿å„æ•°æ®é›†æ¯”ä¾‹åˆç†

## ğŸ¯ é¢„æœŸæ•ˆæœ

### HLBD Fullè®­ç»ƒæ•ˆæœ

- âœ“ å­¦ä¹ 8å±‚è¯­è¨€ç»“æ„
- âœ“ ç†è§£Level 3å¥æ³•ï¼ˆS = NP + VPï¼‰
- âœ“ æ”¯æŒå¤šè¯­è¨€ç”Ÿæˆ
- âœ“ æŒæ¡è·¨è¯­è¨€æ˜ å°„

### HLBD Hardcoreè®­ç»ƒæ•ˆæœ

- âœ“ å‡ ä½•è®¡ç®—å‡†ç¡®ç‡ >95%
- âœ“ ç®—æœ¯è¿ç®—å‡†ç¡®ç‡ >98%
- âœ“ ç”Ÿè‚–æ¨ç†å‡†ç¡®ç‡ >96%
- âœ“ ç‰©ç†å…¬å¼å‡†ç¡®ç‡ >94%

### æ¨¡å—åŒ–è®­ç»ƒä¼˜åŠ¿

- âœ“ **äº’è¡¥å­¦ä¹ **: ç»“æ„åŒ– + é€»è¾‘åŒ–
- âœ“ **é˜²æ­¢å·æ‡’**: æ— æ³•ä¾èµ–å•ä¸€æ¨¡å¼
- âœ“ **æ³›åŒ–èƒ½åŠ›**: æ›´å¼ºçš„è¿ç§»å­¦ä¹ 
- âœ“ **æ•ˆç‡æå‡**: å•æ¬¡è®­ç»ƒè·å¾—åŒé‡èƒ½åŠ›

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜1: æ•°æ®é›†åŠ è½½å¤±è´¥

**ç—‡çŠ¶**:
```
âŒ åŠ è½½å¤±è´¥: No such file or directory
```

**è§£å†³**:
```bash
# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls -lh data/HLBD_*.json

# é‡æ–°ç”Ÿæˆæ•°æ®é›†
python3 tools/generate_hlbd_full_v2.py
python3 tools/generate_hlbd_hardcore_v2.py
```

### é—®é¢˜2: GPUå†…å­˜ä¸è¶³

**ç—‡çŠ¶**:
```
RuntimeError: CUDA out of memory
```

**è§£å†³**:
```bash
# æ–¹æ¡ˆ1: å‡å°batch size
--batch-size 8

# æ–¹æ¡ˆ2: å‡å°æ¨¡å‹
# ç¼–è¾‘ training/train_hlbd_playground.py
# PlaygroundConfig.d_model = 128
```

### é—®é¢˜3: Lossä¸ä¸‹é™

**ç—‡çŠ¶**:
```
Epoch 30: Loss: 3.5 (æ²¡æœ‰æ˜æ˜¾ä¸‹é™)
```

**è§£å†³**:
```bash
# æ£€æŸ¥å­¦ä¹ ç‡
# å¯èƒ½è¿‡å¤§æˆ–è¿‡å°

# æ£€æŸ¥æ•°æ®è´¨é‡
python3 -c "
import json
data = json.load(open('data/HLBD_Full_V2.json'))
print(f'æ ·æœ¬æ•°: {len(data[\"samples\"])}')
print(f'ç¬¬ä¸€ä¸ªæ ·æœ¬: {data[\"samples\"][0]}')
"
```

### é—®é¢˜4: è¯æ±‡è¡¨æº¢å‡º

**ç—‡çŠ¶**:
```
Warning: Vocabulary full, using [UNK]
```

**è§£å†³**:
```bash
# å¢åŠ vocab_size
# ç¼–è¾‘ training/train_hlbd_playground.py
# tokenizer = DynamicTagTokenizer(vocab_size=10000)
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [HLBD Hardcore V2æ€»ç»“](HLBD_V2_SUMMARY.md)
- [æ•°æ®é›†å®Œæˆæ€»ç»“](DATASETS_COMPLETION_SUMMARY.md)
- [HLBD Hardcoreè®­ç»ƒæŒ‡å—](HLBD_HARDCORE_TRAINING.md)
- [è®­ç»ƒåç«¯ä½¿ç”¨](docs/TRAINING_BACKENDS.md)

## ğŸ‰ æ€»ç»“

æ¨¡å—åŒ–è®­ç»ƒæ˜¯APT-Transformerçš„å¼ºå¤§ç‰¹æ€§ï¼š

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ€»æ ·æœ¬æ•° | 10,042 |
| æ•°æ®é›†æ•°é‡ | 2 |
| è®­ç»ƒæ—¶é—´èŠ‚çœ | 50% |
| GPUåˆ©ç”¨ç‡ | æå‡30% |
| æ³›åŒ–èƒ½åŠ› | æ˜¾è‘—æå‡ |

**ç«‹å³å¼€å§‹æ¨¡å—åŒ–è®­ç»ƒ**:
```bash
python3 launch_hlbd_modular_training.py
```

---

**åˆ›å»ºæ—¶é—´**: 2024-12-22
**ç‰ˆæœ¬**: 1.0
**çŠ¶æ€**: âœ… å·²éªŒè¯å¯ç”¨
