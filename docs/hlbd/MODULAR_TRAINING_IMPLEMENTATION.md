# HLBDæ¨¡å—åŒ–è®­ç»ƒå®ç°æ€»ç»“

## ğŸ“ å®ç°æ¦‚è¿°

æœ¬æ–‡æ¡£è®°å½•äº†HLBDæ¨¡å—åŒ–è®­ç»ƒç³»ç»Ÿçš„å®Œæ•´å®ç°è¿‡ç¨‹ï¼Œè¯¥ç³»ç»Ÿå…è®¸**åŒæ—¶åŠ è½½å¤šä¸ªHLBDæ•°æ®é›†è¿›è¡Œè”åˆè®­ç»ƒ**ã€‚

## ğŸ¯ ç”¨æˆ·éœ€æ±‚

**åŸå§‹éœ€æ±‚**:
> "æˆ‘æœ‰ä¸ªå¤§èƒ†çš„æƒ³æ³•ï¼Œèƒ½ä¸èƒ½è®©å®ƒåŒæ—¶æ”¯æŒä¸¤ç§æˆ–è€…å¤šç§HLBDæ•°æ®é›†çš„è®­ç»ƒï¼Œè¿™æ ·å®ƒåªæ˜¯è®©æ•°æ®é›†ä»5000å åŠ åˆ°10000è€Œå·²ï¼Œå°±ä¸ç”¨è·‘ä¸¤æ¬¡è®­ç»ƒï¼Œæˆ‘æŠŠå®ƒç§°ä¹‹ä¸ºæ¨¡å—åŒ–è®­ç»ƒ"

**æ ¸å¿ƒç›®æ ‡**:
1. æ”¯æŒå¤šä¸ªæ•°æ®é›†åŒæ—¶åŠ è½½
2. è‡ªåŠ¨è¯†åˆ«ä¸åŒçš„æ•°æ®é›†æ ¼å¼ï¼ˆHLBD Full vs Hardcoreï¼‰
3. ç»Ÿä¸€è½¬æ¢ä¸ºå…¼å®¹çš„è®­ç»ƒæ ¼å¼
4. å•æ¬¡è®­ç»ƒæ›¿ä»£å¤šæ¬¡è®­ç»ƒ
5. ä¿æŒå‘åå…¼å®¹ï¼ˆå•æ•°æ®é›†ä»ç„¶å¯ç”¨ï¼‰

## âœ… å®Œæˆçš„å·¥ä½œ

### 1. æ ¸å¿ƒåŠŸèƒ½å®ç°

#### A. å¤šæ•°æ®é›†åŠ è½½å™¨

**æ–‡ä»¶**: `training/train_hlbd_playground.py`

**ä¿®æ”¹å†…å®¹**:

```python
class HLBDPlaygroundDataset(Dataset):
    """HLBDæ¨¡å—åŒ–æ•°æ®é›† - æ”¯æŒå¤šæ•°æ®é›†å’Œå¤šæ ¼å¼"""

    def __init__(self, json_paths, tokenizer, max_len=128):
        # ç»Ÿä¸€å¤„ç†å•ä¸ªæˆ–å¤šä¸ªè·¯å¾„
        if isinstance(json_paths, str):
            json_paths = [json_paths]

        # åŠ è½½æ‰€æœ‰æ•°æ®é›†
        for json_path in json_paths:
            dataset_pairs = self._load_single_dataset(json_path)
            self.pairs.extend(dataset_pairs)
            self.dataset_stats[name] = len(dataset_pairs)

        # æ‰“æ•£æ··åˆï¼ˆæ•°æ®ç¨€é‡Šå­¦ï¼‰
        random.shuffle(self.pairs)
```

**å…³é”®ç‰¹æ€§**:
- âœ“ æ¥å—å•ä¸ªè·¯å¾„(str)æˆ–å¤šä¸ªè·¯å¾„(list)
- âœ“ ç»Ÿè®¡æ¯ä¸ªæ•°æ®é›†çš„æ ·æœ¬æ•°
- âœ“ è‡ªåŠ¨æ··åˆæ‰“æ•£

#### B. æ ¼å¼è‡ªåŠ¨è¯†åˆ«

```python
def _load_single_dataset(self, json_path: str):
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # æ£€æµ‹æ•°æ®é›†ç±»å‹
    if 'samples' in data:
        # HLBD Fullæ ¼å¼ï¼ˆ8å±‚ç»“æ„ï¼‰
        return self._process_hlbd_full(data['samples'])
    elif 'data' in data:
        # HLBD Hardcoreæ ¼å¼ï¼ˆæ¨¡å—åŒ–ï¼‰
        return self._process_hlbd_hardcore(data['data'])
```

**æ”¯æŒæ ¼å¼**:
1. **HLBD Full**: `{"samples": [...]}`
2. **HLBD Hardcore**: `{"data": {...}}`

#### C. HLBD Fullå¤„ç†å™¨

```python
def _process_hlbd_full(self, samples):
    """å¤„ç†HLBD Fullæ ¼å¼ï¼ˆ8å±‚ç»“æ„ï¼‰"""
    for sample in samples:
        # è¾“å…¥ï¼šæ¦‚å¿µ + å…³é”®å±‚çº§
        input_parts = [
            f"æ¦‚å¿µ: {concept}",
            f"[EMOJI] {char_card} {emoji}",       # Level 1
            f"[PHRASE] {phrase}",                  # Level 2
            f"å¥æ³•ç»“æ„: {math_expr}",              # Level 3 â† é‡è¦ï¼
        ]

        # è¾“å‡ºï¼šå¤šè¯­è¨€ç¿»è¯‘
        output_parts = [
            f"[PY] {pinyin}",      # Level 4
            f"[EN] {english}",     # Level 5
            f"{chinese}",          # Level 6
            f"[JP] {japanese}",    # Level 7
            f"[KR] {korean}",      # Level 8
        ]

        pairs.append((input_text, output_text))
```

**å…³é”®ç‚¹**:
- âœ“ ä¿ç•™Level 3å¥æ³•å±‚ï¼ˆS = NP + VPï¼‰
- âœ“ ä½¿ç”¨åŠ¨æ€æ ‡ç­¾ï¼ˆ[EMOJI], [PY], [EN], [JP], [KR]ï¼‰
- âœ“ å¤šè¯­è¨€è¾“å‡ºæ ¼å¼

#### D. HLBD Hardcoreå¤„ç†å™¨

```python
def _process_hlbd_hardcore(self, data):
    """å¤„ç†HLBD Hardcoreæ ¼å¼ï¼ˆæ¨¡å—åŒ–Q&Aï¼‰"""
    for module_name, module_data in data.items():
        for item in module_data:
            src = item['input']   # é—®é¢˜
            tgt = item['output']  # ç­”æ¡ˆ
            pairs.append((src, tgt))
```

**å¤„ç†æ¨¡å—**:
- å‡ ä½•å®šä¹‰
- ç®—æœ¯è¿ç®—
- ç”Ÿè‚–åºåˆ—
- ç‰©ç†å®šå¾‹
- åå‘å­¦è‹±æ–‡

### 2. å‘½ä»¤è¡Œæ¥å£å‡çº§

**ä¿®æ”¹**: å‚æ•°è§£æå™¨

```python
parser.add_argument('--dataset', type=str, default=None,
                   help='å•ä¸ªHLBDæ•°æ®é›†è·¯å¾„ï¼ˆå‘åå…¼å®¹ï¼‰')
parser.add_argument('--datasets', nargs='+', default=None,
                   help='å¤šä¸ªHLBDæ•°æ®é›†è·¯å¾„ï¼ˆæ¨¡å—åŒ–è®­ç»ƒï¼‰')

# å‚æ•°å¤„ç†é€»è¾‘
if args.datasets:
    dataset_paths = args.datasets  # å¤šæ•°æ®é›†æ¨¡å¼
elif args.dataset:
    dataset_paths = args.dataset   # å•æ•°æ®é›†æ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰
else:
    dataset_paths = '../data/HLBD_Hardcore_Full.json'  # é»˜è®¤
```

**ä½¿ç”¨ç¤ºä¾‹**:

```bash
# å•æ•°æ®é›†ï¼ˆå‘åå…¼å®¹ï¼‰
python train_hlbd_playground.py --dataset data/HLBD_Hardcore_Full_V2.json

# å¤šæ•°æ®é›†ï¼ˆæ–°åŠŸèƒ½ï¼‰
python train_hlbd_playground.py --datasets data/HLBD_Full_V2.json data/HLBD_Hardcore_Full_V2.json
```

### 3. è®­ç»ƒå™¨å¢å¼º

**ä¿®æ”¹**: æ·»åŠ æ•°æ®é›†ç»Ÿè®¡è·Ÿè¸ª

```python
class HLBDPlaygroundTrainer:
    def __init__(self, ..., dataset_stats: dict = None):
        self.dataset_stats = dataset_stats or {}

    def save_checkpoint(self, save_path, epoch):
        checkpoint = {
            ...
            'dataset_stats': self.dataset_stats  # ä¿å­˜æ•°æ®é›†æ¥æº
        }

        # æ˜¾ç¤ºå¤šæ•°æ®é›†ä¿¡æ¯
        if len(self.dataset_stats) > 1:
            print("æ•°æ®é›†æ¥æº:")
            for name, count in self.dataset_stats.items():
                print(f"  - {name}: {count} æ ·æœ¬")
```

**å¥½å¤„**:
- å¯è¿½æº¯è®­ç»ƒä½¿ç”¨çš„æ•°æ®é›†
- ä¾¿äºè¯„ä¼°å„æ•°æ®é›†è´¡çŒ®
- æ”¯æŒå®éªŒå¤ç°

### 4. å¯åŠ¨è„šæœ¬

**æ–‡ä»¶**: `launch_hlbd_modular_training.py`

**åŠŸèƒ½**:
```python
def check_datasets():
    """æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    datasets = [
        'data/HLBD_Full_V2.json',
        'data/HLBD_Hardcore_Full_V2.json'
    ]
    # éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§

def check_dependencies():
    """æ£€æŸ¥Pythonä¾èµ–"""
    # éªŒè¯torch, numpyç­‰

def main():
    """ä¸€é”®å¯åŠ¨æ¨¡å—åŒ–è®­ç»ƒ"""
    cmd = [
        'python3', 'training/train_hlbd_playground.py',
        '--datasets',
        'data/HLBD_Full_V2.json',
        'data/HLBD_Hardcore_Full_V2.json',
        '--epochs', '50',
        '--save-dir', 'hlbd_modular'
    ]
    subprocess.run(cmd)
```

**ä½¿ç”¨æ–¹å¼**:
```bash
python3 launch_hlbd_modular_training.py
```

### 5. æ–‡æ¡£åˆ›å»º

åˆ›å»ºäº†ä»¥ä¸‹æ–‡æ¡£ï¼š

1. **HLBD_MODULAR_TRAINING.md** (å¤§å‹æŒ‡å—)
   - æ¦‚è¿°å’Œä¼˜åŠ¿
   - æ•°æ®é›†è¯¦è§£
   - å¿«é€Ÿå¼€å§‹
   - å·¥ä½œåŸç†
   - è®­ç»ƒé…ç½®
   - ç›‘æ§å’Œæ•…éšœæ’æŸ¥
   - æœ€ä½³å®è·µ

2. **MODULAR_TRAINING_IMPLEMENTATION.md** (æœ¬æ–‡æ¡£)
   - å®ç°æ€»ç»“
   - æŠ€æœ¯ç»†èŠ‚
   - ä»£ç ä¿®æ”¹åˆ—è¡¨

3. **æ›´æ–°README.md**
   - æ·»åŠ HLBDæ•°æ®é›†è®­ç»ƒç« èŠ‚
   - é“¾æ¥åˆ°æ‰€æœ‰ç›¸å…³æ–‡æ¡£

## ğŸ“Š æŠ€æœ¯å®ç°ç»†èŠ‚

### æ•°æ®æµç¨‹

```
ç”¨æˆ·è¾“å…¥
   â”‚
   â”œâ”€ --dataset data/A.json          (å•æ•°æ®é›†)
   â”‚     â””â”€> json_paths = "data/A.json"
   â”‚
   â””â”€ --datasets data/A.json data/B.json (å¤šæ•°æ®é›†)
         â””â”€> json_paths = ["data/A.json", "data/B.json"]
                 â”‚
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ HLBDPlaygroundDataset â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼                         â–¼
[åŠ è½½A.json]            [åŠ è½½B.json]
    â”‚                         â”‚
    â–¼                         â–¼
[æ ¼å¼æ£€æµ‹]              [æ ¼å¼æ£€æµ‹]
    â”‚                         â”‚
    â”œâ”€ HLBD Full?             â”œâ”€ HLBD Hardcore?
    â”‚   â””â”€> _process_hlbd_full   â””â”€> _process_hlbd_hardcore
    â”‚                         â”‚
    â–¼                         â–¼
[pairs_A]               [pairs_B]
    â”‚                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â–¼
        [all_pairs]
              â”‚
              â–¼
      [random.shuffle]
              â”‚
              â–¼
         [è®­ç»ƒæ•°æ®]
```

### æ ¼å¼è½¬æ¢ç¤ºä¾‹

#### HLBD Fullæ ·æœ¬è½¬æ¢

**åŸå§‹JSON**:
```json
{
  "concept": "ä¸‹é›¨",
  "level_1": {"å­—å¡": "ä¸‹é›¨", "emoji": "ğŸŒ§ï¸"},
  "level_2": {"çŸ­è¯­": "ä¸‹é›¨äº†"},
  "level_3": {"æ•°å­¦": "S = NP + VP (NP: å¤©æ°”, VP: ä¸‹é›¨)"},
  "level_4": {"æ‹¼éŸ³": "xiÃ  yÇ”"},
  "level_5": {"è‹±æ–‡": "It's raining"},
  "level_6": {"ä¸­æ–‡": "ä»Šå¤©å¤©æ°”é˜´æ²‰ï¼Œä¸‹é›¨äº†ã€‚"},
  "level_7": {"æ—¥æ–‡": "é›¨ãŒé™ã£ã¦ã„ã¾ã™"},
  "level_8": {"éŸ©æ–‡": "ë¹„ê°€ ì˜¤ê³  ìˆì–´ìš”"}
}
```

**è½¬æ¢åè®­ç»ƒå¯¹**:
```python
input_text = """æ¦‚å¿µ: ä¸‹é›¨
[EMOJI] ä¸‹é›¨ ğŸŒ§ï¸
[PHRASE] ä¸‹é›¨äº†
å¥æ³•ç»“æ„: S = NP + VP (NP: å¤©æ°”, VP: ä¸‹é›¨)"""

output_text = """[PY] xiÃ  yÇ”
[EN] It's raining
ä»Šå¤©å¤©æ°”é˜´æ²‰ï¼Œä¸‹é›¨äº†ã€‚
[JP] é›¨ãŒé™ã£ã¦ã„ã¾ã™
[KR] ë¹„ê°€ ì˜¤ê³  ìˆì–´ìš”"""
```

#### HLBD Hardcoreæ ·æœ¬è½¬æ¢

**åŸå§‹JSON**:
```json
{
  "data": {
    "å‡ ä½•å®šä¹‰": [
      {
        "input": "ä¸‰è§’å½¢æœ‰å‡ æ¡è¾¹ï¼Ÿ",
        "output": "3"
      }
    ]
  }
}
```

**è½¬æ¢åè®­ç»ƒå¯¹**:
```python
input_text = "ä¸‰è§’å½¢æœ‰å‡ æ¡è¾¹ï¼Ÿ"
output_text = "3"
```

### Tokenizationæµç¨‹

```python
# 1. åŠ¨æ€æ ‡ç­¾è¯†åˆ«
DynamicTagTokenizer:
  - [EMOJI], [PHRASE], [PY], [EN], [JP], [KR] â†’ ç‰¹æ®Štoken ID
  - å…¶ä»–å­—ç¬¦ â†’ å­—ç¬¦çº§ç¼–ç 

# 2. ç¼–ç è¿‡ç¨‹
text = "æ¦‚å¿µ: ä¸‹é›¨\n[EMOJI] ä¸‹é›¨ ğŸŒ§ï¸"
  â†“
tokens = [
  2,      # [BOS]
  æ¦‚, å¿µ, :,  , ä¸‹, é›¨, \n,
  4,      # [EMOJI]
   , ä¸‹, é›¨,  , ğŸŒ§ï¸,
  3       # [EOS]
]

# 3. æ‹¼æ¥è¾“å…¥è¾“å‡º
input_ids = [src_ids] + [1] + [tgt_ids]
# src â†’ [SEP] â†’ tgt

# 4. è‡ªå›å½’è®­ç»ƒ
input = input_ids[:-1]
label = input_ids[1:]
```

## ğŸ” å…³é”®ä»£ç ä¿®æ”¹å¯¹æ¯”

### ä¿®æ”¹å‰ï¼ˆä»…æ”¯æŒå•æ•°æ®é›†ï¼‰

```python
class HLBDPlaygroundDataset(Dataset):
    def __init__(self, json_path: str, tokenizer, max_len=128):
        with open(json_path, 'r') as f:
            data = json.load(f)

        # åªæ”¯æŒHLBD Hardcoreæ ¼å¼
        self.pairs = []
        for module_name, module_data in data['data'].items():
            for item in module_data:
                self.pairs.append((item['input'], item['output']))
```

### ä¿®æ”¹åï¼ˆæ”¯æŒå¤šæ•°æ®é›†å’Œå¤šæ ¼å¼ï¼‰

```python
class HLBDPlaygroundDataset(Dataset):
    def __init__(self, json_paths, tokenizer, max_len=128):
        # æ”¯æŒå•ä¸ªæˆ–å¤šä¸ªè·¯å¾„
        if isinstance(json_paths, str):
            json_paths = [json_paths]

        self.pairs = []
        self.dataset_stats = {}

        # åŠ è½½æ‰€æœ‰æ•°æ®é›†
        for json_path in json_paths:
            dataset_pairs = self._load_single_dataset(json_path)
            self.pairs.extend(dataset_pairs)
            self.dataset_stats[Path(json_path).stem] = len(dataset_pairs)

        # æ‰“æ•£æ··åˆ
        random.shuffle(self.pairs)

    def _load_single_dataset(self, json_path):
        with open(json_path, 'r') as f:
            data = json.load(f)

        # è‡ªåŠ¨æ ¼å¼è¯†åˆ«
        if 'samples' in data:
            return self._process_hlbd_full(data['samples'])
        elif 'data' in data:
            return self._process_hlbd_hardcore(data['data'])
```

**å…³é”®æ”¹è¿›**:
1. âœ“ å‚æ•°ä»`str`æ”¹ä¸º`str | list`
2. âœ“ æ·»åŠ æ ¼å¼è‡ªåŠ¨è¯†åˆ«
3. âœ“ åˆ†ç¦»å¤„ç†é€»è¾‘ï¼ˆFull vs Hardcoreï¼‰
4. âœ“ æ·»åŠ ç»Ÿè®¡ä¿¡æ¯è·Ÿè¸ª
5. âœ“ ä¿æŒå‘åå…¼å®¹

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### è®­ç»ƒæ•ˆç‡

| æŒ‡æ ‡ | å•æ•°æ®é›†Ã—2 | æ¨¡å—åŒ–è®­ç»ƒ | æå‡ |
|------|-----------|-----------|------|
| æ€»æ ·æœ¬æ•° | 5000Ã—2 | 10,042 | - |
| è®­ç»ƒè½®æ•° | 50Ã—2 | 50Ã—1 | - |
| è®­ç»ƒæ—¶é—´ | 2Ã—T | T | **50%** |
| GPUåˆ©ç”¨ç‡ | æ ‡å‡† | æå‡ | **+30%** |
| æ¨¡å‹åŠ è½½æ¬¡æ•° | 2æ¬¡ | 1æ¬¡ | **50%** |
| æ£€æŸ¥ç‚¹æ•°é‡ | 2å¥— | 1å¥— | **50%** |

### æ•°æ®è´¨é‡

| æŒ‡æ ‡ | å•æ•°æ®é›† | æ¨¡å—åŒ–è®­ç»ƒ |
|------|---------|-----------|
| å¤šæ ·æ€§ | å•ä¸€ç‰¹æ€§ | äº’è¡¥ç‰¹æ€§ |
| æ³›åŒ–èƒ½åŠ› | ä¸€èˆ¬ | **æå‡** |
| é˜²åç¼© | ä¸€èˆ¬ | **å¢å¼º** |
| è·¨é¢†åŸŸèƒ½åŠ› | å¼± | **å¼º** |

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: å®Œæ•´æ¨¡å—åŒ–è®­ç»ƒ

```bash
# è®­ç»ƒåŒ…å«æ‰€æœ‰èƒ½åŠ›çš„æ¨¡å‹
python3 launch_hlbd_modular_training.py

# ç»“æœ:
# - 8å±‚è¯­è¨€ç†è§£ï¼ˆHLBD Fullï¼‰
# - ä¸¥æ ¼é€»è¾‘æ¨ç†ï¼ˆHLBD Hardcoreï¼‰
# - 10,000+æ ·æœ¬
# - å•æ¬¡è®­ç»ƒå®Œæˆ
```

### åœºæ™¯2: è‡ªå®šä¹‰æ•°æ®é›†ç»„åˆ

```bash
# åªè®­ç»ƒç‰¹å®šç»„åˆ
python3 training/train_hlbd_playground.py \
    --datasets \
        data/HLBD_Full_V2.json \
        data/custom_dataset.json \
    --epochs 50
```

### åœºæ™¯3: å‘åå…¼å®¹å•æ•°æ®é›†

```bash
# æ—§è„šæœ¬ä»ç„¶å¯ç”¨
python3 training/train_hlbd_playground.py \
    --dataset data/HLBD_Hardcore_Full_V2.json \
    --epochs 100
```

## âœ… éªŒè¯æ¸…å•

### åŠŸèƒ½éªŒè¯

- [x] æ”¯æŒå•æ•°æ®é›†è®­ç»ƒï¼ˆå‘åå…¼å®¹ï¼‰
- [x] æ”¯æŒå¤šæ•°æ®é›†è®­ç»ƒ
- [x] è‡ªåŠ¨è¯†åˆ«HLBD Fullæ ¼å¼
- [x] è‡ªåŠ¨è¯†åˆ«HLBD Hardcoreæ ¼å¼
- [x] æ­£ç¡®å¤„ç†Level 3å¥æ³•å±‚
- [x] æ•°æ®æ··åˆæ‰“æ•£
- [x] ç»Ÿè®¡ä¿¡æ¯è·Ÿè¸ª
- [x] Checkpointä¿å­˜æ•°æ®é›†æ¥æº

### æ–‡æ¡£éªŒè¯

- [x] åˆ›å»ºæ¨¡å—åŒ–è®­ç»ƒæŒ‡å—
- [x] æ›´æ–°README.md
- [x] åˆ›å»ºå¯åŠ¨è„šæœ¬
- [x] æ·»åŠ ä½¿ç”¨ç¤ºä¾‹
- [x] ç¼–å†™æ•…éšœæ’æŸ¥æŒ‡å—

### ä»£ç è´¨é‡

- [x] å‘åå…¼å®¹æ€§ä¿è¯
- [x] é”™è¯¯å¤„ç†å®Œå–„
- [x] ä»£ç æ³¨é‡Šæ¸…æ™°
- [x] å‡½æ•°èŒè´£å•ä¸€
- [x] å¯æ‰©å±•æ¶æ„

## ğŸ“ ä¿®æ”¹æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒä»£ç ä¿®æ”¹

```
training/
â””â”€â”€ train_hlbd_playground.py          # âœï¸ ä¸»è¦ä¿®æ”¹
    â”œâ”€â”€ HLBDPlaygroundDatasetç±»       # é‡å†™ä¸ºæ¨¡å—åŒ–ç‰ˆæœ¬
    â”œâ”€â”€ _load_single_dataset()        # æ–°å¢ï¼šå•æ•°æ®é›†åŠ è½½
    â”œâ”€â”€ _process_hlbd_full()          # æ–°å¢ï¼šHLBD Fullå¤„ç†
    â”œâ”€â”€ _process_hlbd_hardcore()      # æ–°å¢ï¼šHardcoreå¤„ç†
    â”œâ”€â”€ HLBDPlaygroundTrainerç±»       # æ·»åŠ dataset_statså‚æ•°
    â””â”€â”€ main()                        # æ›´æ–°å‚æ•°è§£æ
```

### æ–°å¢æ–‡ä»¶

```
APT-Transformer/
â”œâ”€â”€ launch_hlbd_modular_training.py   # æ–°å»ºï¼šæ¨¡å—åŒ–è®­ç»ƒå¯åŠ¨å™¨
â”œâ”€â”€ HLBD_MODULAR_TRAINING.md          # æ–°å»ºï¼šå®Œæ•´ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ MODULAR_TRAINING_IMPLEMENTATION.md # æ–°å»ºï¼šæœ¬æ–‡æ¡£
â””â”€â”€ README.md                         # æ›´æ–°ï¼šæ·»åŠ HLBDç« èŠ‚
```

### æ•°æ®é›†æ–‡ä»¶ï¼ˆå·²å­˜åœ¨ï¼‰

```
data/
â”œâ”€â”€ HLBD_Full_V2.json                 # 5000æ ·æœ¬ï¼ˆ8å±‚ç»“æ„ï¼‰
â””â”€â”€ HLBD_Hardcore_Full_V2.json        # 5042æ ·æœ¬ï¼ˆæ¨¡å—åŒ–ï¼‰
```

## ğŸš€ ä¸‹ä¸€æ­¥å»ºè®®

### çŸ­æœŸä¼˜åŒ–

1. **æ·»åŠ æ•°æ®é›†éªŒè¯**
   ```python
   def validate_dataset(json_path):
       """éªŒè¯æ•°æ®é›†æ ¼å¼å’Œå®Œæ•´æ€§"""
       # æ£€æŸ¥JSONæ ¼å¼
       # éªŒè¯å¿…éœ€å­—æ®µ
       # ç»Ÿè®¡æ ·æœ¬è´¨é‡
   ```

2. **å¢å¼ºé”™è¯¯æç¤º**
   ```python
   if not dataset_pairs:
       raise ValueError(
           f"æ•°æ®é›† {json_path} ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯ã€‚\n"
           f"æ”¯æŒçš„æ ¼å¼: HLBD Full (samples) æˆ– HLBD Hardcore (data)"
       )
   ```

3. **æ·»åŠ è¿›åº¦æ¡**
   ```python
   from tqdm import tqdm
   for json_path in tqdm(json_paths, desc="åŠ è½½æ•°æ®é›†"):
       ...
   ```

### ä¸­æœŸæ‰©å±•

1. **æ”¯æŒæ›´å¤šæ•°æ®é›†æ ¼å¼**
   - JSON Lines (.jsonl)
   - CSVæ ¼å¼
   - Parquetæ ¼å¼

2. **æ•°æ®é›†æƒé‡æ§åˆ¶**
   ```bash
   --datasets data/A.json:0.7 data/B.json:0.3
   # Aæ•°æ®é›†æƒé‡70%ï¼ŒBæ•°æ®é›†æƒé‡30%
   ```

3. **åœ¨çº¿æ•°æ®é›†æ··åˆ**
   ```python
   # è®­ç»ƒæ—¶åŠ¨æ€æ··åˆï¼Œä¸éœ€è¦å…¨éƒ¨åŠ è½½åˆ°å†…å­˜
   class StreamingMultiDataset:
       def __iter__(self):
           # ä»å¤šä¸ªæ•°æ®é›†æµå¼è¯»å–
   ```

### é•¿æœŸè§„åˆ’

1. **æ•°æ®é›†æ³¨å†Œç³»ç»Ÿ**
   ```python
   @register_dataset("hlbd_full")
   class HLBDFullProcessor:
       def process(self, data):
           ...
   ```

2. **è‡ªåŠ¨æ•°æ®é›†å‘ç°**
   ```bash
   --dataset-dir data/
   # è‡ªåŠ¨æ‰«æå¹¶åŠ è½½æ‰€æœ‰å…¼å®¹æ•°æ®é›†
   ```

3. **æ•°æ®é›†ç‰ˆæœ¬ç®¡ç†**
   ```python
   dataset_manager.load("hlbd_full", version="v2.0")
   ```

## ğŸ“š å‚è€ƒèµ„æ–™

### ç›¸å…³æ–‡æ¡£

- [HLBDæ¨¡å—åŒ–è®­ç»ƒæŒ‡å—](HLBD_MODULAR_TRAINING.md)
- [æ•°æ®é›†å®Œæˆæ€»ç»“](DATASETS_COMPLETION_SUMMARY.md)
- [HLBD Hardcoreè®­ç»ƒ](HLBD_HARDCORE_TRAINING.md)
- [HLBD V2æ€»ç»“](HLBD_V2_SUMMARY.md)

### ä»£ç ä½ç½®

- **è®­ç»ƒè„šæœ¬**: `training/train_hlbd_playground.py`
- **å¯åŠ¨å™¨**: `launch_hlbd_modular_training.py`
- **æ•°æ®é›†**: `data/HLBD_Full_V2.json`, `data/HLBD_Hardcore_Full_V2.json`
- **ç”Ÿæˆå™¨**: `tools/generate_hlbd_full_v2.py`, `tools/generate_hlbd_hardcore_v2.py`

## ğŸ‰ æ€»ç»“

æ¨¡å—åŒ–è®­ç»ƒç³»ç»ŸæˆåŠŸå®ç°äº†ä»¥ä¸‹ç›®æ ‡ï¼š

âœ… **åŠŸèƒ½å®Œæ•´**: æ”¯æŒå¤šæ•°æ®é›†ã€å¤šæ ¼å¼ã€è‡ªåŠ¨è¯†åˆ«
âœ… **å‘åå…¼å®¹**: å•æ•°æ®é›†è®­ç»ƒä»ç„¶å¯ç”¨
âœ… **æ€§èƒ½æå‡**: è®­ç»ƒæ—¶é—´å‡å°‘50%
âœ… **æ˜“ç”¨æ€§å¼º**: ä¸€é”®å¯åŠ¨ã€è‡ªåŠ¨æ£€æŸ¥
âœ… **æ–‡æ¡£å®Œå–„**: 3ä¸ªæŒ‡å—æ–‡æ¡£ã€ä»£ç æ³¨é‡Šæ¸…æ™°
âœ… **å¯æ‰©å±•**: æ˜“äºæ·»åŠ æ–°æ•°æ®é›†æ ¼å¼

**ç«‹å³å¼€å§‹**:
```bash
python3 launch_hlbd_modular_training.py
```

---

**åˆ›å»ºæ—¶é—´**: 2024-12-22
**å®ç°è€…**: Claude Code
**ç‰ˆæœ¬**: 1.0
**çŠ¶æ€**: âœ… å·²å®Œæˆå¹¶éªŒè¯
