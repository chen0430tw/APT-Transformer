"""
è™šæ‹ŸBlackwellè®­ç»ƒå¯åŠ¨è„šæœ¬

å®Œæ•´çš„APTå¤§æ¨¡å‹è®­ç»ƒæµç¨‹ï¼Œé›†æˆæ‰€æœ‰è™šæ‹ŸBlackwellä¼˜åŒ–ï¼š
- VGPUå †å ï¼ˆå¤šçº§å†…å­˜ç®¡ç†ï¼‰
- FP4é‡åŒ–ï¼ˆå‚æ•°å‹ç¼©ï¼‰
- Flash Attentionï¼ˆæ³¨æ„åŠ›ä¼˜åŒ–ï¼‰
- è‡ªåŠ¨èµ„æºè¯„ä¼°å’Œé…ç½®

ä½¿ç”¨ç¤ºä¾‹ï¼š
    # å°æ¨¡å‹å¿«é€Ÿæµ‹è¯•
    python train_vb_apt.py --config small --epochs 10

    # ä¸­å‹æ¨¡å‹è®­ç»ƒ
    python train_vb_apt.py --config medium --batch-size 16

    # å¤§æ¨¡å‹è®­ç»ƒï¼ˆè‡ªåŠ¨VGPUé…ç½®ï¼‰
    python train_vb_apt.py --config large --vgpu-auto

    # è‡ªå®šä¹‰é…ç½®
    python train_vb_apt.py --hidden-size 1024 --num-layers 24 --batch-size 8
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import argparse
import json
import time
from datetime import datetime
from typing import Dict, Optional
import os

# APTæ¨¡å‹
from apt.core.modeling.apt_model import (
    APTLargeModel,
    APTModelConfiguration
)

# è™šæ‹ŸBlackwell
from apt_model.optimization import (
    VGPUStack,
    create_vgpu_stack,
    VGPUResourceEstimator,
    ModelConfig,
)

# é›†æˆæ¨¡å—
from test_vb_apt_integration import VBOptimizedAPTModel


# ============================================================================
# é…ç½®é¢„è®¾
# ============================================================================

PRESETS = {
    'tiny': {
        'vocab_size': 5000,
        'hidden_size': 128,
        'num_layers': 2,
        'num_heads': 4,
        'max_position_embeddings': 256,
        'batch_size': 32,
    },
    'small': {
        'vocab_size': 10000,
        'hidden_size': 256,
        'num_layers': 4,
        'num_heads': 4,
        'max_position_embeddings': 512,
        'batch_size': 16,
    },
    'medium': {
        'vocab_size': 30000,
        'hidden_size': 768,
        'num_layers': 12,
        'num_heads': 12,
        'max_position_embeddings': 1024,
        'batch_size': 8,
    },
    'large': {
        'vocab_size': 50000,
        'hidden_size': 1024,
        'num_layers': 24,
        'num_heads': 16,
        'max_position_embeddings': 2048,
        'batch_size': 4,
    },
}


# ============================================================================
# ç®€å•æ•°æ®é›†ï¼ˆç”¨äºæ¼”ç¤ºï¼‰
# ============================================================================

class DummyTextDataset(Dataset):
    """è™šæ‹Ÿæ–‡æœ¬æ•°æ®é›†ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""

    def __init__(self, vocab_size: int, seq_len: int, num_samples: int = 1000):
        self.vocab_size = vocab_size
        self.seq_len = seq_len
        self.num_samples = num_samples

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        # ç”Ÿæˆéšæœºåºåˆ—
        input_ids = torch.randint(0, self.vocab_size, (self.seq_len,))
        # æ ‡ç­¾æ˜¯è¾“å…¥å³ç§»ä¸€ä½
        labels = torch.roll(input_ids, -1)
        labels[-1] = 0  # æœ€åä¸€ä¸ªtokenç”¨padding

        return {
            'input_ids': input_ids,
            'labels': labels
        }


# ============================================================================
# è®­ç»ƒå™¨
# ============================================================================

class VBTrainer:
    """è™šæ‹ŸBlackwellè®­ç»ƒå™¨"""

    def __init__(self, args):
        self.args = args
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'

        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path(args.output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # æ—¥å¿—æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_file = self.output_dir / f"training_{timestamp}.log"

        # åˆå§‹åŒ–
        self.model = None
        self.vgpu_stack = None
        self.optimizer = None
        self.train_loader = None

        self.log(f"è™šæ‹ŸBlackwellè®­ç»ƒå™¨åˆå§‹åŒ–")
        self.log(f"è®¾å¤‡: {self.device}")
        self.log(f"è¾“å‡ºç›®å½•: {self.output_dir}")

    def log(self, message: str):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_msg = f"[{timestamp}] {message}"
        print(log_msg)
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_msg + '\n')

    def setup_model(self):
        """è®¾ç½®æ¨¡å‹"""
        self.log("\n" + "="*70)
        self.log("æ­¥éª¤1: æ¨¡å‹é…ç½®")
        self.log("="*70)

        # è·å–é…ç½®
        if self.args.config:
            preset = PRESETS[self.args.config]
            self.log(f"ä½¿ç”¨é¢„è®¾é…ç½®: {self.args.config}")
        else:
            preset = {}
            self.log("ä½¿ç”¨è‡ªå®šä¹‰é…ç½®")

        # è¦†ç›–é…ç½®
        config_dict = {
            'vocab_size': self.args.vocab_size or preset.get('vocab_size', 10000),
            'hidden_size': self.args.hidden_size or preset.get('hidden_size', 256),
            'num_layers': self.args.num_layers or preset.get('num_layers', 4),
            'num_heads': self.args.num_heads or preset.get('num_heads', 4),
            'max_position_embeddings': self.args.seq_length or preset.get('max_position_embeddings', 512),
            'dropout': self.args.dropout,
        }

        self.batch_size = self.args.batch_size or preset.get('batch_size', 16)

        # æ‰“å°é…ç½®
        self.log("\næ¨¡å‹é…ç½®:")
        for key, value in config_dict.items():
            self.log(f"  {key}: {value}")
        self.log(f"  batch_size: {self.batch_size}")

        # åˆ›å»ºAPTé…ç½®
        apt_config = APTModelConfiguration(**config_dict)

        # èµ„æºè¯„ä¼°
        if self.args.estimate_resources:
            self.log("\nè¿›è¡Œèµ„æºè¯„ä¼°...")
            self._estimate_resources(config_dict)

        # åˆ›å»ºVGPU Stack
        self.log("\nåˆ›å»ºVGPUå †å ...")
        if self.args.vgpu_auto:
            self.vgpu_stack = self._create_auto_vgpu_stack(config_dict)
        else:
            self.vgpu_stack = create_vgpu_stack()

        # åˆ›å»ºæ¨¡å‹
        self.log("\nåˆ›å»ºè™šæ‹ŸBlackwellä¼˜åŒ–æ¨¡å‹...")
        self.model = VBOptimizedAPTModel(
            apt_config,
            self.vgpu_stack,
            use_fp4=self.args.use_fp4,
            use_flash_attn=self.args.use_flash_attn
        ).to(self.device)

        # ç»Ÿè®¡å‚æ•°
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        self.log(f"\næ¨¡å‹å‚æ•°:")
        self.log(f"  æ€»å‚æ•°: {total_params:,} ({total_params/1e6:.1f}M)")
        self.log(f"  å¯è®­ç»ƒ: {trainable_params:,} ({trainable_params/1e6:.1f}M)")

    def _estimate_resources(self, config_dict: Dict):
        """ä¼°ç®—èµ„æºéœ€æ±‚"""
        model_config = ModelConfig(
            vocab_size=config_dict['vocab_size'],
            hidden_size=config_dict['hidden_size'],
            num_layers=config_dict['num_layers'],
            num_heads=config_dict['num_heads'],
            seq_length=config_dict['max_position_embeddings'],
            batch_size=self.batch_size,
            mixed_precision=self.args.mixed_precision,
            gradient_checkpointing=self.args.gradient_checkpointing
        )

        estimator = VGPUResourceEstimator()
        estimator.estimate_transformer(model_config)

        # è·å–å¯ç”¨GPU
        available_gpus = []
        if torch.cuda.is_available():
            for i in range(torch.cuda.device_count()):
                props = torch.cuda.get_device_properties(i)
                available_gpus.append({
                    'device': f'cuda:{i}',
                    'vram_gb': props.total_memory / (1024**3),
                    'speed_gbps': 900  # å‡è®¾å€¼
                })

        estimator.generate_vgpu_config(available_gpus or [{'device': 'cpu', 'vram_gb': 16, 'speed_gbps': 50}])
        estimator.print_report()

    def _create_auto_vgpu_stack(self, config_dict: Dict) -> VGPUStack:
        """è‡ªåŠ¨åˆ›å»ºVGPUå †å é…ç½®"""
        # ç®€å•ä¼°ç®—æ‰€éœ€å®¹é‡
        param_count = (config_dict['vocab_size'] * config_dict['hidden_size'] +
                      config_dict['num_layers'] * config_dict['hidden_size'] * config_dict['hidden_size'] * 4)
        param_gb = param_count * 4 / (1024**3)  # float32

        self.log(f"  ä¼°ç®—å‚æ•°å†…å­˜: {param_gb:.2f} GB")

        # è·å–GPUå®¹é‡
        if torch.cuda.is_available():
            gpu_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            self.log(f"  GPUæ˜¾å­˜: {gpu_gb:.1f} GB")

            config = {
                'levels': [
                    {'capacity_mb': int(gpu_gb * 0.7 * 1024), 'device': 'cuda:0', 'speed_gbps': 900},
                    {'capacity_mb': int(param_gb * 2 * 1024), 'device': 'cpu', 'speed_gbps': 50},
                    {'capacity_mb': int(param_gb * 4 * 1024), 'device': 'ssd', 'speed_gbps': 7},
                ]
            }
        else:
            config = None

        from apt_model.optimization.vgpu_stack import VGPUStack
        return VGPUStack(config)

    def setup_data(self):
        """è®¾ç½®æ•°æ®"""
        self.log("\n" + "="*70)
        self.log("æ­¥éª¤2: æ•°æ®åŠ è½½")
        self.log("="*70)

        # åˆ›å»ºæ•°æ®é›†
        train_dataset = DummyTextDataset(
            vocab_size=self.model.config.vocab_size,
            seq_len=self.model.config.max_position_embeddings,
            num_samples=self.args.num_samples
        )

        # åˆ›å»ºDataLoader
        self.train_loader = DataLoader(
            train_dataset,
            batch_size=self.batch_size,
            shuffle=True,
            num_workers=0  # Windowsä¸Šè®¾ä¸º0
        )

        self.log(f"æ•°æ®é›†å¤§å°: {len(train_dataset)}")
        self.log(f"æ‰¹æ¬¡æ•°: {len(self.train_loader)}")
        self.log(f"æ‰¹æ¬¡å¤§å°: {self.batch_size}")

    def setup_optimizer(self):
        """è®¾ç½®ä¼˜åŒ–å™¨"""
        self.log("\n" + "="*70)
        self.log("æ­¥éª¤3: ä¼˜åŒ–å™¨é…ç½®")
        self.log("="*70)

        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=self.args.learning_rate,
            weight_decay=self.args.weight_decay
        )

        self.log(f"ä¼˜åŒ–å™¨: AdamW")
        self.log(f"å­¦ä¹ ç‡: {self.args.learning_rate}")
        self.log(f"æƒé‡è¡°å‡: {self.args.weight_decay}")

    def train(self):
        """è®­ç»ƒå¾ªç¯"""
        self.log("\n" + "="*70)
        self.log("æ­¥éª¤4: å¼€å§‹è®­ç»ƒ")
        self.log("="*70)

        best_loss = float('inf')
        global_step = 0

        for epoch in range(self.args.epochs):
            epoch_start = time.time()
            epoch_loss = 0.0
            epoch_batches = 0

            self.model.train()

            for batch_idx, batch in enumerate(self.train_loader):
                step_start = time.time()

                # æ•°æ®ç§»åˆ°è®¾å¤‡
                input_ids = batch['input_ids'].to(self.device)
                labels = batch['labels'].to(self.device)

                # å‰å‘ä¼ æ’­
                self.optimizer.zero_grad()
                output = self.model(input_ids)

                # è®¡ç®—æŸå¤±
                loss = nn.functional.cross_entropy(
                    output.view(-1, self.model.config.vocab_size),
                    labels.view(-1)
                )

                # åå‘ä¼ æ’­
                loss.backward()
                if self.args.max_grad_norm > 0:
                    torch.nn.utils.clip_grad_norm_(
                        self.model.parameters(),
                        self.args.max_grad_norm
                    )
                self.optimizer.step()

                # ç»Ÿè®¡
                step_time = time.time() - step_start
                epoch_loss += loss.item()
                epoch_batches += 1
                global_step += 1

                # æ—¥å¿—
                if (batch_idx + 1) % self.args.log_interval == 0:
                    avg_loss = epoch_loss / epoch_batches
                    self.log(f"Epoch {epoch+1}/{self.args.epochs} | "
                           f"Batch {batch_idx+1}/{len(self.train_loader)} | "
                           f"Loss: {loss.item():.4f} | "
                           f"Avg Loss: {avg_loss:.4f} | "
                           f"Time: {step_time*1000:.0f}ms")

                # ä¿å­˜æ£€æŸ¥ç‚¹
                if self.args.save_steps > 0 and global_step % self.args.save_steps == 0:
                    self._save_checkpoint(epoch, global_step, loss.item())

            # Epochç»“æŸ
            epoch_time = time.time() - epoch_start
            avg_loss = epoch_loss / epoch_batches

            self.log(f"\n{'='*70}")
            self.log(f"Epoch {epoch+1} å®Œæˆ")
            self.log(f"  å¹³å‡æŸå¤±: {avg_loss:.4f}")
            self.log(f"  è€—æ—¶: {epoch_time:.2f}s")
            self.log(f"  ååé‡: {len(self.train_loader)/epoch_time:.2f} batch/s")
            self.log(f"{'='*70}\n")

            # VGPUç»Ÿè®¡
            if (epoch + 1) % self.args.stat_interval == 0:
                self.log("\nVGPUå †å ç»Ÿè®¡:")
                self.vgpu_stack.print_stats()

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if avg_loss < best_loss:
                best_loss = avg_loss
                self._save_checkpoint(epoch, global_step, avg_loss, is_best=True)

        self.log("\n" + "="*70)
        self.log("è®­ç»ƒå®Œæˆï¼")
        self.log("="*70)
        self.log(f"æœ€ä½³æŸå¤±: {best_loss:.4f}")

    def _save_checkpoint(self, epoch: int, step: int, loss: float, is_best: bool = False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'global_step': step,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'loss': loss,
            'config': vars(self.args),
        }

        if is_best:
            filename = self.output_dir / 'best_model.pt'
            self.log(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: {filename}")
        else:
            filename = self.output_dir / f'checkpoint_step_{step}.pt'
            self.log(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {filename}")

        torch.save(checkpoint, filename)


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def parse_args():
    parser = argparse.ArgumentParser(description='è™šæ‹ŸBlackwell APTè®­ç»ƒ')

    # æ¨¡å‹é…ç½®
    parser.add_argument('--config', type=str, choices=list(PRESETS.keys()),
                       help='ä½¿ç”¨é¢„è®¾é…ç½® (tiny/small/medium/large)')
    parser.add_argument('--vocab-size', type=int, help='è¯è¡¨å¤§å°')
    parser.add_argument('--hidden-size', type=int, help='éšè—å±‚å¤§å°')
    parser.add_argument('--num-layers', type=int, help='å±‚æ•°')
    parser.add_argument('--num-heads', type=int, help='æ³¨æ„åŠ›å¤´æ•°')
    parser.add_argument('--seq-length', type=int, help='åºåˆ—é•¿åº¦')
    parser.add_argument('--dropout', type=float, default=0.1, help='Dropoutç‡')

    # è®­ç»ƒé…ç½®
    parser.add_argument('--batch-size', type=int, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--epochs', type=int, default=10, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--learning-rate', type=float, default=1e-4, help='å­¦ä¹ ç‡')
    parser.add_argument('--weight-decay', type=float, default=0.01, help='æƒé‡è¡°å‡')
    parser.add_argument('--max-grad-norm', type=float, default=1.0, help='æ¢¯åº¦è£å‰ª')
    parser.add_argument('--num-samples', type=int, default=1000, help='è®­ç»ƒæ ·æœ¬æ•°')

    # VGPUé…ç½®
    parser.add_argument('--vgpu-auto', action='store_true',
                       help='è‡ªåŠ¨é…ç½®VGPUå †å ')
    parser.add_argument('--use-fp4', action='store_true',
                       help='å¯ç”¨FP4é‡åŒ–')
    parser.add_argument('--use-flash-attn', action='store_true',
                       help='å¯ç”¨Flash Attention')
    parser.add_argument('--mixed-precision', action='store_true',
                       help='å¯ç”¨æ··åˆç²¾åº¦')
    parser.add_argument('--gradient-checkpointing', action='store_true',
                       help='å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹')

    # å…¶ä»–
    parser.add_argument('--output-dir', type=str, default='./output',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--log-interval', type=int, default=10,
                       help='æ—¥å¿—é—´éš”ï¼ˆæ‰¹æ¬¡ï¼‰')
    parser.add_argument('--stat-interval', type=int, default=5,
                       help='ç»Ÿè®¡é—´éš”ï¼ˆè½®æ•°ï¼‰')
    parser.add_argument('--save-steps', type=int, default=0,
                       help='ä¿å­˜é—´éš”ï¼ˆæ­¥æ•°ï¼Œ0=ä¸ä¿å­˜ï¼‰')
    parser.add_argument('--estimate-resources', action='store_true',
                       help='è®­ç»ƒå‰ä¼°ç®—èµ„æºéœ€æ±‚')

    return parser.parse_args()


def main():
    print("\n")
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘              è™šæ‹ŸBlackwell APTè®­ç»ƒç³»ç»Ÿ                              â•‘")
    print("â•‘              VGPU Stack + Flash Optimization                       â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print("\n")

    # è§£æå‚æ•°
    args = parse_args()

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = VBTrainer(args)

    # è®¾ç½®
    trainer.setup_model()
    trainer.setup_data()
    trainer.setup_optimizer()

    # è®­ç»ƒ
    trainer.train()

    print("\nâœ… è®­ç»ƒå®Œæˆï¼")
    print(f"è¾“å‡ºç›®å½•: {trainer.output_dir}")


if __name__ == "__main__":
    main()
