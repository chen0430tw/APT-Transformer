#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é”™è¯¯æŒä¹…åŒ–ç³»ç»Ÿæµ‹è¯•

æµ‹è¯•ErrorPersistenceç±»çš„æ‰€æœ‰åŠŸèƒ½ï¼ŒåŒ…æ‹¬:
- é”™è¯¯æ—¥å¿—è®°å½•
- é”™è¯¯æ¨¡å¼è¯†åˆ«
- ç»Ÿè®¡åˆ†æ
- æ•°æ®å¯¼å‡º
"""

import os
import json
import pytest
import tempfile
import sqlite3
from pathlib import Path
from datetime import datetime, timedelta

from apt.apt_model.utils.error_persistence import (
    ErrorPersistence,
    log_training_error,
    get_global_error_persistence
)


@pytest.fixture
def temp_db():
    """ä¸´æ—¶æ•°æ®åº“fixture"""
    with tempfile.TemporaryDirectory() as temp_dir:
        db_path = Path(temp_dir) / "test_errors.db"
        yield db_path


@pytest.fixture
def error_persistence(temp_db):
    """ErrorPersistenceå®ä¾‹fixture"""
    ep = ErrorPersistence(db_path=str(temp_db))
    yield ep
    ep.close()


class TestBasicErrorLogging:
    """æµ‹è¯•åŸºç¡€é”™è¯¯æ—¥å¿—åŠŸèƒ½"""

    def test_database_initialization(self, temp_db):
        """æµ‹è¯•æ•°æ®åº“åˆå§‹åŒ–"""
        ep = ErrorPersistence(db_path=str(temp_db))

        # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦åˆ›å»º
        assert temp_db.exists()

        # æ£€æŸ¥è¡¨æ˜¯å¦åˆ›å»º
        conn = sqlite3.connect(str(temp_db))
        cursor = conn.cursor()

        cursor.execute("""
            SELECT name FROM sqlite_master
            WHERE type='table' AND name IN ('error_logs', 'error_patterns')
        """)
        tables = [row[0] for row in cursor.fetchall()]

        assert 'error_logs' in tables
        assert 'error_patterns' in tables

        conn.close()
        ep.close()

    def test_log_simple_error(self, error_persistence):
        """æµ‹è¯•è®°å½•ç®€å•é”™è¯¯"""
        try:
            raise ValueError("Test error message")
        except ValueError as e:
            error_id = error_persistence.log_error(
                error=e,
                severity=ErrorPersistence.SEVERITY_ERROR,
                module="test_module",
                function="test_function"
            )

        # éªŒè¯è¿”å›çš„error_id
        assert error_id > 0

        # éªŒè¯é”™è¯¯å·²è®°å½•åˆ°æ•°æ®åº“
        error_persistence.cursor.execute("""
            SELECT error_type, error_message, module, function
            FROM error_logs WHERE id = ?
        """, (error_id,))

        row = error_persistence.cursor.fetchone()
        assert row[0] == "ValueError"
        assert row[1] == "Test error message"
        assert row[2] == "test_module"
        assert row[3] == "test_function"

    def test_log_error_with_context(self, error_persistence):
        """æµ‹è¯•è®°å½•å¸¦ä¸Šä¸‹æ–‡çš„é”™è¯¯"""
        context = {
            'batch_size': 8,
            'learning_rate': 0.001,
            'gpu_memory': '4GB'
        }

        try:
            raise RuntimeError("Out of memory")
        except RuntimeError as e:
            error_id = error_persistence.log_error(
                error=e,
                severity=ErrorPersistence.SEVERITY_CRITICAL,
                context=context,
                epoch=5,
                global_step=1200
            )

        # éªŒè¯ä¸Šä¸‹æ–‡ä¿¡æ¯
        error_persistence.cursor.execute("""
            SELECT context, epoch, global_step FROM error_logs WHERE id = ?
        """, (error_id,))

        row = error_persistence.cursor.fetchone()
        stored_context = json.loads(row[0])

        assert stored_context == context
        assert row[1] == 5
        assert row[2] == 1200

    def test_severity_levels(self, error_persistence):
        """æµ‹è¯•ä¸åŒä¸¥é‡æ€§çº§åˆ«"""
        severities = [
            (ErrorPersistence.SEVERITY_DEBUG, "Debug error"),
            (ErrorPersistence.SEVERITY_INFO, "Info error"),
            (ErrorPersistence.SEVERITY_WARNING, "Warning error"),
            (ErrorPersistence.SEVERITY_ERROR, "Error error"),
            (ErrorPersistence.SEVERITY_CRITICAL, "Critical error"),
        ]

        for severity, message in severities:
            try:
                raise Exception(message)
            except Exception as e:
                error_persistence.log_error(e, severity=severity)

        # éªŒè¯æ‰€æœ‰ä¸¥é‡æ€§çº§åˆ«éƒ½å·²è®°å½•
        error_persistence.cursor.execute("""
            SELECT DISTINCT severity FROM error_logs ORDER BY severity
        """)

        stored_severities = [row[0] for row in error_persistence.cursor.fetchall()]
        assert stored_severities == [0, 1, 2, 3, 4]


class TestErrorPatternRecognition:
    """æµ‹è¯•é”™è¯¯æ¨¡å¼è¯†åˆ«"""

    def test_identical_errors_create_pattern(self, error_persistence):
        """æµ‹è¯•ç›¸åŒé”™è¯¯åˆ›å»ºæ¨¡å¼"""
        # è®°å½•3æ¬¡ç›¸åŒçš„é”™è¯¯
        for i in range(3):
            try:
                x = 1 / 0
            except ZeroDivisionError as e:
                error_persistence.log_error(e)

        # æ£€æŸ¥é”™è¯¯æ¨¡å¼è¡¨
        error_persistence.cursor.execute("""
            SELECT error_type, occurrence_count FROM error_patterns
        """)

        patterns = error_persistence.cursor.fetchall()
        assert len(patterns) == 1
        assert patterns[0][0] == "ZeroDivisionError"
        assert patterns[0][1] == 3

    def test_similar_errors_share_pattern(self, error_persistence):
        """æµ‹è¯•ç›¸ä¼¼é”™è¯¯å…±äº«æ¨¡å¼"""
        # è®°å½•æ•°å­—ä¸åŒä½†æ¨¡å¼ç›¸åŒçš„é”™è¯¯
        for i in range(5):
            try:
                raise ValueError(f"Invalid value: {i}")
            except ValueError as e:
                error_persistence.log_error(e)

        # åº”è¯¥è¯†åˆ«ä¸ºåŒä¸€ä¸ªæ¨¡å¼
        error_persistence.cursor.execute("""
            SELECT occurrence_count FROM error_patterns WHERE error_type = 'ValueError'
        """)

        count = error_persistence.cursor.fetchone()[0]
        assert count == 5

    def test_get_error_patterns(self, error_persistence):
        """æµ‹è¯•è·å–é”™è¯¯æ¨¡å¼åˆ—è¡¨"""
        # åˆ›å»ºå¤šä¸ªä¸åŒé¢‘ç‡çš„é”™è¯¯
        for i in range(10):
            try:
                raise ValueError("Frequent error")
            except ValueError as e:
                error_persistence.log_error(e)

        for i in range(3):
            try:
                raise TypeError("Less frequent error")
            except TypeError as e:
                error_persistence.log_error(e)

        # è·å–é”™è¯¯æ¨¡å¼ï¼ˆè‡³å°‘å‡ºç°2æ¬¡ï¼‰
        patterns = error_persistence.get_error_patterns(min_occurrences=2)

        assert len(patterns) == 2
        # ValueErroråº”è¯¥æ’åœ¨å‰é¢ï¼ˆå‡ºç°æ¬¡æ•°æ›´å¤šï¼‰
        assert patterns[0]['error_type'] == 'ValueError'
        assert patterns[0]['occurrence_count'] == 10
        assert patterns[1]['error_type'] == 'TypeError'
        assert patterns[1]['occurrence_count'] == 3

    def test_mark_pattern_resolved(self, error_persistence):
        """æµ‹è¯•æ ‡è®°é”™è¯¯æ¨¡å¼ä¸ºå·²è§£å†³"""
        # åˆ›å»ºé”™è¯¯
        try:
            raise ValueError("Test error")
        except ValueError as e:
            error_persistence.log_error(e)

        # è·å–é”™è¯¯å“ˆå¸Œ
        patterns = error_persistence.get_error_patterns(min_occurrences=1, unresolved_only=False)
        error_hash = patterns[0]['error_hash']

        # æ ‡è®°ä¸ºå·²è§£å†³
        error_persistence.mark_pattern_resolved(error_hash)

        # éªŒè¯å·²è§£å†³
        patterns_unresolved = error_persistence.get_error_patterns(min_occurrences=1, unresolved_only=True)
        assert len(patterns_unresolved) == 0

        patterns_all = error_persistence.get_error_patterns(min_occurrences=1, unresolved_only=False)
        assert patterns_all[0]['resolved'] == True


class TestErrorStatistics:
    """æµ‹è¯•é”™è¯¯ç»Ÿè®¡åˆ†æ"""

    def test_error_statistics_basic(self, error_persistence):
        """æµ‹è¯•åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯"""
        # åˆ›å»ºä¸åŒä¸¥é‡æ€§çš„é”™è¯¯
        errors = [
            (ErrorPersistence.SEVERITY_WARNING, ValueError("Warning 1")),
            (ErrorPersistence.SEVERITY_WARNING, ValueError("Warning 2")),
            (ErrorPersistence.SEVERITY_ERROR, RuntimeError("Error 1")),
            (ErrorPersistence.SEVERITY_CRITICAL, MemoryError("Critical 1")),
        ]

        for severity, error in errors:
            error_persistence.log_error(error, severity=severity)

        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = error_persistence.get_error_statistics(hours=24)

        assert stats['total_errors'] == 4
        assert stats['severity_breakdown']['WARNING'] == 2
        assert stats['severity_breakdown']['ERROR'] == 1
        assert stats['severity_breakdown']['CRITICAL'] == 1

    def test_error_type_distribution(self, error_persistence):
        """æµ‹è¯•é”™è¯¯ç±»å‹åˆ†å¸ƒ"""
        # åˆ›å»ºä¸åŒç±»å‹çš„é”™è¯¯
        for i in range(5):
            error_persistence.log_error(ValueError(f"Value error {i}"))

        for i in range(3):
            error_persistence.log_error(TypeError(f"Type error {i}"))

        for i in range(7):
            error_persistence.log_error(RuntimeError(f"Runtime error {i}"))

        stats = error_persistence.get_error_statistics(hours=24)

        assert stats['error_types']['ValueError'] == 5
        assert stats['error_types']['TypeError'] == 3
        assert stats['error_types']['RuntimeError'] == 7

    def test_top_patterns_in_statistics(self, error_persistence):
        """æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯ä¸­çš„é«˜é¢‘æ¨¡å¼"""
        # åˆ›å»ºé«˜é¢‘é”™è¯¯
        for i in range(15):
            error_persistence.log_error(ValueError("Most frequent error"))

        for i in range(8):
            error_persistence.log_error(TypeError("Second frequent error"))

        stats = error_persistence.get_error_statistics(hours=24)

        assert len(stats['top_patterns']) == 2
        assert stats['top_patterns'][0]['count'] == 15
        assert stats['top_patterns'][1]['count'] == 8


class TestErrorSearch:
    """æµ‹è¯•é”™è¯¯æœç´¢åŠŸèƒ½"""

    def test_search_by_keyword(self, error_persistence):
        """æµ‹è¯•æŒ‰å…³é”®è¯æœç´¢"""
        # åˆ›å»ºä¸åŒæ¶ˆæ¯çš„é”™è¯¯
        error_persistence.log_error(ValueError("CUDA out of memory"))
        error_persistence.log_error(RuntimeError("Invalid CUDA device"))
        error_persistence.log_error(TypeError("String expected"))

        # æœç´¢åŒ…å«"CUDA"çš„é”™è¯¯
        results = error_persistence.search_errors(keyword="CUDA")

        assert len(results) == 2
        assert all('CUDA' in r['error_message'] for r in results)

    def test_search_by_severity(self, error_persistence):
        """æµ‹è¯•æŒ‰ä¸¥é‡æ€§æœç´¢"""
        error_persistence.log_error(ValueError("Warning"), severity=ErrorPersistence.SEVERITY_WARNING)
        error_persistence.log_error(RuntimeError("Error"), severity=ErrorPersistence.SEVERITY_ERROR)
        error_persistence.log_error(MemoryError("Critical"), severity=ErrorPersistence.SEVERITY_CRITICAL)

        # æœç´¢ERRORçº§åˆ«
        results = error_persistence.search_errors(severity=ErrorPersistence.SEVERITY_ERROR)

        assert len(results) == 1
        assert results[0]['severity'] == 'ERROR'

    def test_search_by_error_type(self, error_persistence):
        """æµ‹è¯•æŒ‰é”™è¯¯ç±»å‹æœç´¢"""
        error_persistence.log_error(ValueError("Value error 1"))
        error_persistence.log_error(ValueError("Value error 2"))
        error_persistence.log_error(TypeError("Type error 1"))

        # æœç´¢ValueErrorç±»å‹
        results = error_persistence.search_errors(error_type="ValueError")

        assert len(results) == 2
        assert all(r['error_type'] == 'ValueError' for r in results)

    def test_search_limit(self, error_persistence):
        """æµ‹è¯•æœç´¢æ•°é‡é™åˆ¶"""
        # åˆ›å»º100ä¸ªé”™è¯¯
        for i in range(100):
            error_persistence.log_error(ValueError(f"Error {i}"))

        # é™åˆ¶è¿”å›10ä¸ª
        results = error_persistence.search_errors(limit=10)

        assert len(results) == 10


class TestWebUIExport:
    """æµ‹è¯•WebUI/APIæ•°æ®å¯¼å‡º"""

    def test_export_for_webui_structure(self, error_persistence):
        """æµ‹è¯•WebUIå¯¼å‡ºæ•°æ®ç»“æ„"""
        # åˆ›å»ºä¸€äº›æµ‹è¯•æ•°æ®
        for i in range(10):
            error_persistence.log_error(ValueError(f"Test error {i}"))

        # å¯¼å‡ºæ•°æ®
        data = error_persistence.export_for_webui()

        # éªŒè¯æ•°æ®ç»“æ„
        assert 'statistics' in data
        assert 'patterns' in data
        assert 'recent_errors' in data
        assert 'timeline' in data
        assert 'generated_at' in data

        # éªŒè¯ç»Ÿè®¡ä¿¡æ¯
        assert 'last_24h' in data['statistics']
        assert 'last_7d' in data['statistics']

        # éªŒè¯åŒ…å«æ•°æ®
        assert data['statistics']['last_24h']['total_errors'] == 10

    def test_export_to_json_file(self, error_persistence, temp_db):
        """æµ‹è¯•å¯¼å‡ºåˆ°JSONæ–‡ä»¶"""
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        error_persistence.log_error(ValueError("Test export"))

        # å¯¼å‡ºåˆ°æ–‡ä»¶
        export_path = temp_db.parent / "export.json"
        data = error_persistence.export_for_webui(export_path=str(export_path))

        # éªŒè¯æ–‡ä»¶å·²åˆ›å»º
        assert export_path.exists()

        # éªŒè¯æ–‡ä»¶å†…å®¹
        with open(export_path, 'r', encoding='utf-8') as f:
            file_data = json.load(f)

        assert file_data == data
        assert file_data['statistics']['last_24h']['total_errors'] > 0

    def test_timeline_aggregation(self, error_persistence):
        """æµ‹è¯•æ—¶é—´çº¿èšåˆ"""
        # åˆ›å»ºé”™è¯¯
        for i in range(5):
            error_persistence.log_error(ValueError(f"Error {i}"))

        # å¯¼å‡ºæ•°æ®
        data = error_persistence.export_for_webui()

        # éªŒè¯æ—¶é—´çº¿
        assert 'timeline' in data
        assert isinstance(data['timeline'], list)

        # æ—¶é—´çº¿åº”è¯¥åŒ…å«æŒ‰å°æ—¶èšåˆçš„æ•°æ®
        if len(data['timeline']) > 0:
            timeline_entry = data['timeline'][0]
            assert 'hour' in timeline_entry
            assert 'total' in timeline_entry
            assert 'by_severity' in timeline_entry


class TestErrorReport:
    """æµ‹è¯•é”™è¯¯æŠ¥å‘Šç”Ÿæˆ"""

    def test_generate_error_report(self, error_persistence):
        """æµ‹è¯•ç”ŸæˆMarkdownæŠ¥å‘Š"""
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        for i in range(5):
            error_persistence.log_error(ValueError("Frequent error"))

        for i in range(2):
            error_persistence.log_error(TypeError("Less frequent error"))

        # ç”ŸæˆæŠ¥å‘Š
        report = error_persistence.generate_error_report()

        # éªŒè¯æŠ¥å‘Šå†…å®¹
        assert "# é”™è¯¯åˆ†ææŠ¥å‘Š" in report
        assert "é”™è¯¯ç»Ÿè®¡æ¦‚è§ˆ" in report
        assert "é«˜é¢‘é”™è¯¯æ¨¡å¼" in report
        assert "æ”¹è¿›å»ºè®®" in report

        # éªŒè¯åŒ…å«é”™è¯¯ä¿¡æ¯
        assert "ValueError" in report
        assert "TypeError" in report

    def test_save_report_to_file(self, error_persistence, temp_db):
        """æµ‹è¯•ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        error_persistence.log_error(ValueError("Test error"))

        # ç”Ÿæˆå¹¶ä¿å­˜æŠ¥å‘Š
        report_path = temp_db.parent / "error_report.md"
        report = error_persistence.generate_error_report(output_path=str(report_path))

        # éªŒè¯æ–‡ä»¶å·²åˆ›å»º
        assert report_path.exists()

        # éªŒè¯æ–‡ä»¶å†…å®¹
        with open(report_path, 'r', encoding='utf-8') as f:
            file_content = f.read()

        assert file_content == report
        assert "# é”™è¯¯åˆ†ææŠ¥å‘Š" in file_content


class TestConvenienceFunctions:
    """æµ‹è¯•ä¾¿æ·å‡½æ•°"""

    def test_log_training_error(self, temp_db):
        """æµ‹è¯•log_training_errorä¾¿æ·å‡½æ•°"""
        # ä½¿ç”¨å…¨å±€å•ä¾‹éœ€è¦è¦†ç›–æ•°æ®åº“è·¯å¾„
        import apt.apt_model.utils.error_persistence as ep_module
        ep_module._global_error_persistence = ErrorPersistence(db_path=str(temp_db))

        try:
            raise ValueError("Training error")
        except ValueError as e:
            error_id = log_training_error(
                error=e,
                severity=ErrorPersistence.SEVERITY_ERROR,
                epoch=10,
                global_step=500,
                context={'batch_size': 16}
            )

        # éªŒè¯é”™è¯¯å·²è®°å½•
        assert error_id > 0

        # éªŒè¯ä¸Šä¸‹æ–‡ä¿¡æ¯
        ep = get_global_error_persistence()
        errors = ep.search_errors(limit=1)

        assert len(errors) == 1
        assert errors[0]['epoch'] == 10
        assert errors[0]['global_step'] == 500
        assert errors[0]['context']['batch_size'] == 16

        ep.close()

    def test_global_error_persistence_singleton(self, temp_db):
        """æµ‹è¯•å…¨å±€å•ä¾‹æ¨¡å¼"""
        import apt.apt_model.utils.error_persistence as ep_module

        # é‡ç½®å…¨å±€å®ä¾‹
        if hasattr(ep_module, '_global_error_persistence'):
            delattr(ep_module, '_global_error_persistence')

        # è¦†ç›–å…¨å±€å®ä¾‹
        ep_module._global_error_persistence = ErrorPersistence(db_path=str(temp_db))

        # è·å–ä¸¤æ¬¡åº”è¯¥æ˜¯åŒä¸€ä¸ªå®ä¾‹
        ep1 = get_global_error_persistence()
        ep2 = get_global_error_persistence()

        assert ep1 is ep2

        ep1.close()


class TestContextManager:
    """æµ‹è¯•ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""

    def test_context_manager_usage(self, temp_db):
        """æµ‹è¯•ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ­£ç¡®å…³é—­è¿æ¥"""
        with ErrorPersistence(db_path=str(temp_db)) as ep:
            ep.log_error(ValueError("Test error"))

            # è¿æ¥åº”è¯¥ä»ç„¶æ‰“å¼€
            assert ep.conn is not None

        # é€€å‡ºä¸Šä¸‹æ–‡åï¼Œè¿æ¥åº”è¯¥å·²å…³é—­
        # æ³¨æ„: sqlite3çš„Connectionå¯¹è±¡æ²¡æœ‰ç®€å•çš„æ–¹æ³•æ£€æŸ¥æ˜¯å¦å…³é—­
        # ä½†æˆ‘ä»¬å¯ä»¥å°è¯•æ“ä½œï¼Œåº”è¯¥ä¼šå¤±è´¥
        with pytest.raises(sqlite3.ProgrammingError):
            ep.cursor.execute("SELECT 1")


# ============================================================================
# ğŸ”® API Readiness Tests (æœªæ¥APIç«¯ç‚¹æµ‹è¯•)
# ============================================================================

class TestAPIReadiness:
    """æµ‹è¯•æœªæ¥APIç«¯ç‚¹çš„æ•°æ®æ¥å£"""

    def test_api_endpoint_statistics(self, error_persistence):
        """
        æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯APIç«¯ç‚¹

        æœªæ¥API: GET /api/errors/statistics
        """
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        for i in range(10):
            error_persistence.log_error(ValueError(f"Error {i}"))

        # æ¨¡æ‹ŸAPIå“åº”
        stats = error_persistence.get_error_statistics(hours=24)

        # éªŒè¯APIå“åº”æ ¼å¼
        assert 'total_errors' in stats
        assert 'severity_breakdown' in stats
        assert 'error_types' in stats
        assert 'top_patterns' in stats
        assert stats['total_errors'] == 10

    def test_api_endpoint_patterns(self, error_persistence):
        """
        æµ‹è¯•é”™è¯¯æ¨¡å¼APIç«¯ç‚¹

        æœªæ¥API: GET /api/errors/patterns
        """
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        for i in range(5):
            error_persistence.log_error(ValueError("Repeated error"))

        # æ¨¡æ‹ŸAPIå“åº”
        patterns = error_persistence.get_error_patterns(min_occurrences=1)

        # éªŒè¯APIå“åº”æ ¼å¼
        assert isinstance(patterns, list)
        assert len(patterns) > 0
        assert 'error_hash' in patterns[0]
        assert 'error_type' in patterns[0]
        assert 'occurrence_count' in patterns[0]

    def test_api_endpoint_resolve(self, error_persistence):
        """
        æµ‹è¯•è§£å†³é”™è¯¯APIç«¯ç‚¹

        æœªæ¥API: POST /api/errors/resolve/{hash}
        """
        # åˆ›å»ºé”™è¯¯
        error_persistence.log_error(ValueError("Test error"))

        # è·å–é”™è¯¯å“ˆå¸Œ
        patterns = error_persistence.get_error_patterns(min_occurrences=1, unresolved_only=False)
        error_hash = patterns[0]['error_hash']

        # æ¨¡æ‹ŸAPIè°ƒç”¨
        error_persistence.mark_pattern_resolved(error_hash)

        # éªŒè¯å·²è§£å†³
        patterns_updated = error_persistence.get_error_patterns(min_occurrences=1, unresolved_only=False)
        assert patterns_updated[0]['resolved'] == True

    def test_api_endpoint_search(self, error_persistence):
        """
        æµ‹è¯•æœç´¢APIç«¯ç‚¹

        æœªæ¥API: GET /api/errors/search?keyword=xxx
        """
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        error_persistence.log_error(ValueError("CUDA memory error"))
        error_persistence.log_error(RuntimeError("File not found"))

        # æ¨¡æ‹ŸAPIè°ƒç”¨
        results = error_persistence.search_errors(keyword="CUDA", limit=10)

        # éªŒè¯APIå“åº”
        assert isinstance(results, list)
        assert len(results) == 1
        assert 'error_message' in results[0]
        assert 'CUDA' in results[0]['error_message']


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
