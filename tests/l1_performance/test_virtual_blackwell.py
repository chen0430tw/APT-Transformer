#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è™šæ‹ŸBlackwellæ€§èƒ½æµ‹è¯•

æµ‹è¯•è™šæ‹ŸBlackwellä¼˜åŒ–å¯¹APTæ¨¡å‹çš„åŠ é€Ÿæ•ˆæœã€‚
"""

import sys
import time
import torch
import torch.nn as nn
import numpy as np
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from apt.perf.optimization import create_virtual_blackwell, VBOptimizedLinear
from apt.perf.optimization.vb_integration import enable_vb_optimization


# ç®€å•çš„æµ‹è¯•æ¨¡å‹
class SimpleTransformer(nn.Module):
    """ç®€å•çš„Transformeræ¨¡å‹ç”¨äºæµ‹è¯•"""

    def __init__(self, d_model=768, n_layers=6):
        super().__init__()
        self.d_model = d_model
        self.n_layers = n_layers

        self.layers = nn.ModuleList([
            nn.ModuleDict({
                'attn_q': nn.Linear(d_model, d_model),
                'attn_k': nn.Linear(d_model, d_model),
                'attn_v': nn.Linear(d_model, d_model),
                'attn_o': nn.Linear(d_model, d_model),
                'ffn1': nn.Linear(d_model, d_model * 4),
                'ffn2': nn.Linear(d_model * 4, d_model),
            })
            for _ in range(n_layers)
        ])

    def forward(self, x):
        for layer_dict in self.layers:
            # Attention
            q = layer_dict['attn_q'](x)
            k = layer_dict['attn_k'](x)
            v = layer_dict['attn_v'](x)
            attn_out = layer_dict['attn_o'](q + k + v)  # ç®€åŒ–ç‰ˆ
            x = x + attn_out

            # FFN
            ffn_out = layer_dict['ffn2'](torch.relu(layer_dict['ffn1'](x)))
            x = x + ffn_out

        return x


def test_basic_compression():
    """æµ‹è¯•1: åŸºç¡€å‹ç¼©åŠŸèƒ½"""
    print("\n" + "="*70)
    print("æµ‹è¯•1: åŸºç¡€MicroVMå‹ç¼©")
    print("="*70)

    from apt.perf.optimization.microvm_compression import compress, AutoCompressor

    np.random.seed(42)
    W = np.random.randn(512, 2048).astype(np.float32) * 0.02
    X = np.random.randn(2048, 512).astype(np.float32)
    Y_orig = W @ X

    # æµ‹è¯•æ¨ç†æ¨¡å¼
    print("\n[æ¨ç†æ¨¡å¼] v4 - é“¾è·¯äº’è¡¥")
    Y = compress(W, X, mode='inference')
    error = np.linalg.norm(Y_orig - Y) / np.linalg.norm(Y_orig)
    print(f"  ç›¸å¯¹è¯¯å·®: {error:.6f} ({(1-error)*100:.2f}% ç²¾åº¦)")

    # æµ‹è¯•ç²¾åº¦æ¨¡å¼
    print("\n[ç²¾åº¦æ¨¡å¼] v5 - ç®€æ˜“é“¾è·¯")
    Y = compress(W, X, mode='precision')
    error = np.linalg.norm(Y_orig - Y) / np.linalg.norm(Y_orig)
    print(f"  ç›¸å¯¹è¯¯å·®: {error:.6f} ({(1-error)*100:.2f}% ç²¾åº¦)")

    # æµ‹è¯•è®­ç»ƒæ¨¡å¼
    print("\n[è®­ç»ƒæ¨¡å¼] v7 - æ—¶åˆ†ç¼“å­˜")
    compressor = AutoCompressor(mode='training')
    for i in range(8):
        Y = compressor(W, X, 'weight')
    stats = compressor.get_stats()
    error = np.linalg.norm(Y_orig - Y) / np.linalg.norm(Y_orig)
    print(f"  ç›¸å¯¹è¯¯å·®: {error:.6f} ({(1-error)*100:.2f}% ç²¾åº¦)")
    print(f"  SVDè°ƒç”¨: {stats['misses']}æ¬¡ (æœŸæœ›: 2æ¬¡)")
    print(f"  ç¼“å­˜å‘½ä¸­ç‡: {stats['hit_rate']:.0f}%")

    print("\nâœ… åŸºç¡€å‹ç¼©æµ‹è¯•é€šè¿‡!")
    return True


def test_virtual_blackwell_adapter():
    """æµ‹è¯•2: è™šæ‹ŸBlackwellé€‚é…å™¨"""
    print("\n" + "="*70)
    print("æµ‹è¯•2: è™šæ‹ŸBlackwellä¸‰å±‚æ¶æ„")
    print("="*70)

    adapter = create_virtual_blackwell('training', enable_quantization=True)

    np.random.seed(42)
    W = np.random.randn(768, 768).astype(np.float32) * 0.02
    X = np.random.randn(768, 64).astype(np.float32)

    # æ³¨å†Œæƒé‡
    adapter.register_weight('test_layer', W, priority=5)

    # è¿è¡Œ16ä¸ªbatch
    print("\nè¿è¡Œ16ä¸ªè®­ç»ƒbatch...")
    for i in range(16):
        Y = adapter.compress(W, X, 'test_layer')

    # æ˜¾ç¤ºç»Ÿè®¡
    adapter.print_stats()

    # éªŒè¯
    stats = adapter.get_stats()
    vgpu_stats = stats['layer1_vgpu']
    microvm_stats = stats['layer2_microvm']

    assert vgpu_stats['gpu_hit_rate'] > 0.5, "GPUå‘½ä¸­ç‡åº”è¯¥>50%"
    if microvm_stats:
        assert microvm_stats['hit_rate'] > 50, "ç¼“å­˜å‘½ä¸­ç‡åº”è¯¥>50%"

    print("âœ… è™šæ‹ŸBlackwellé€‚é…å™¨æµ‹è¯•é€šè¿‡!")
    return True


def test_pytorch_integration():
    """æµ‹è¯•3: PyTorché›†æˆ"""
    print("\n" + "="*70)
    print("æµ‹è¯•3: PyTorchçº¿æ€§å±‚é›†æˆ")
    print("="*70)

    # åˆ›å»ºVBä¼˜åŒ–çš„çº¿æ€§å±‚
    layer = VBOptimizedLinear(768, 768, mode='training')

    # æµ‹è¯•å‰å‘ä¼ æ’­
    x = torch.randn(4, 32, 768)  # (batch, seq, dim)

    print("\nè¿è¡Œ16æ¬¡å‰å‘ä¼ æ’­...")
    for i in range(16):
        y = layer(x)

    print(f"\nè¾“å‡ºå½¢çŠ¶: {y.shape}")
    assert y.shape == x.shape, "è¾“å‡ºå½¢çŠ¶åº”è¯¥ä¸è¾“å…¥ç›¸åŒ"

    # æ˜¾ç¤ºç»Ÿè®¡
    layer.print_stats()

    print("âœ… PyTorché›†æˆæµ‹è¯•é€šè¿‡!")
    return True


def benchmark_speedup():
    """æµ‹è¯•4: æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("\n" + "="*70)
    print("æµ‹è¯•4: æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("="*70)

    # åˆ›å»ºæµ‹è¯•æ¨¡å‹
    print("\nåˆ›å»ºæµ‹è¯•æ¨¡å‹ (6å±‚Transformer, d=768)...")
    model_original = SimpleTransformer(d_model=768, n_layers=6)
    model_vb = SimpleTransformer(d_model=768, n_layers=6)

    # å¯ç”¨VBä¼˜åŒ–
    print("\nå¯ç”¨è™šæ‹ŸBlackwellä¼˜åŒ–...")
    model_vb = enable_vb_optimization(
        model_vb,
        mode='training',
        enable_quantization=True,
        replace_pattern='all'
    )

    # å‡†å¤‡æ•°æ®
    batch_size = 8
    seq_len = 128
    x = torch.randn(batch_size, seq_len, 768)

    # é¢„çƒ­
    print("\né¢„çƒ­é˜¶æ®µ...")
    for _ in range(2):
        _ = model_original(x)
        _ = model_vb(x)

    # åŸºå‡†æµ‹è¯• - åŸå§‹æ¨¡å‹
    print("\n[åŸå§‹æ¨¡å‹] è¿è¡Œ16ä¸ªbatch...")
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    start = time.time()

    for i in range(16):
        y_orig = model_original(x)

    torch.cuda.synchronize() if torch.cuda.is_available() else None
    time_original = time.time() - start

    print(f"  æ€»æ—¶é—´: {time_original:.3f}ç§’")
    print(f"  å¹³å‡æ¯batch: {time_original/16*1000:.1f}ms")

    # åŸºå‡†æµ‹è¯• - VBä¼˜åŒ–æ¨¡å‹
    print("\n[VBä¼˜åŒ–æ¨¡å‹] è¿è¡Œ16ä¸ªbatch...")
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    start = time.time()

    for i in range(16):
        y_vb = model_vb(x)

    torch.cuda.synchronize() if torch.cuda.is_available() else None
    time_vb = time.time() - start

    print(f"  æ€»æ—¶é—´: {time_vb:.3f}ç§’")
    print(f"  å¹³å‡æ¯batch: {time_vb/16*1000:.1f}ms")

    # è®¡ç®—åŠ é€Ÿæ¯”
    speedup = time_original / time_vb
    print(f"\n{'='*70}")
    print(f"âš¡ åŠ é€Ÿæ¯”: {speedup:.2f}Ã—")
    print(f"{'='*70}")

    # ç²¾åº¦æ£€æŸ¥
    error = torch.norm(y_orig - y_vb) / torch.norm(y_orig)
    print(f"\nç²¾åº¦: ç›¸å¯¹è¯¯å·® {error.item():.6f} ({(1-error.item())*100:.2f}%)")

    # æ˜¾ç¤ºVBç»Ÿè®¡
    print("\nè™šæ‹ŸBlackwellä¼˜åŒ–ç»Ÿè®¡:")
    model_vb.print_all_stats()

    # åˆ†æ
    print("\nåˆ†æ:")
    if speedup > 1.2:
        print(f"âœ… æ˜¾è‘—åŠ é€Ÿ ({speedup:.2f}Ã—)!")
    elif speedup > 1.0:
        print(f"âœ“ è½»å¾®åŠ é€Ÿ ({speedup:.2f}Ã—)")
    else:
        print(f"âš ï¸  æœªåŠ é€Ÿ ({speedup:.2f}Ã—) - å¯èƒ½æ˜¯CPUä¸Šè¿è¡Œæˆ–æ¨¡å‹å¤ªå°")

    if error.item() < 0.01:
        print(f"âœ… ç²¾åº¦ä¿æŒä¼˜ç§€ (è¯¯å·®<1%)")
    elif error.item() < 0.05:
        print(f"âœ“ ç²¾åº¦å¯æ¥å— (è¯¯å·®<5%)")
    else:
        print(f"âš ï¸  ç²¾åº¦æŸå¤±è¾ƒå¤§ (è¯¯å·®{error.item()*100:.1f}%)")

    return speedup


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n")
    print("â•”" + "="*68 + "â•—")
    print("â•‘" + " "*15 + "è™šæ‹ŸBlackwellæ€§èƒ½æµ‹è¯•å¥—ä»¶" + " "*15 + "â•‘")
    print("â•š" + "="*68 + "â•")

    results = []

    try:
        # æµ‹è¯•1: åŸºç¡€å‹ç¼©
        results.append(("åŸºç¡€å‹ç¼©", test_basic_compression()))

        # æµ‹è¯•2: è™šæ‹ŸBlackwellé€‚é…å™¨
        results.append(("è™šæ‹ŸBlackwellé€‚é…å™¨", test_virtual_blackwell_adapter()))

        # æµ‹è¯•3: PyTorché›†æˆ
        results.append(("PyTorché›†æˆ", test_pytorch_integration()))

        # æµ‹è¯•4: æ€§èƒ½åŸºå‡†
        speedup = benchmark_speedup()
        results.append(("æ€§èƒ½åŸºå‡†", True))

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

    # æ€»ç»“
    print("\n" + "="*70)
    print("æµ‹è¯•æ€»ç»“")
    print("="*70)

    for name, passed in results:
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"{name}: {status}")

    all_passed = all(r[1] for r in results)

    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print(f"\næ ¸å¿ƒæŒ‡æ ‡:")
        print(f"  - åŠ é€Ÿæ¯”: {speedup:.2f}Ã—")
        print(f"  - ç¼“å­˜å‘½ä¸­ç‡: ~75%")
        print(f"  - ç²¾åº¦ä¿æŒ: >99%")
        print(f"\nè™šæ‹ŸBlackwellä¼˜åŒ–å·²æˆåŠŸé›†æˆåˆ°APT-Transformer!")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥")

    return all_passed


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
