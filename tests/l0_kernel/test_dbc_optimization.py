#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
DBC-DACä¼˜åŒ–æ–¹æ³•è¯¯å·®å¯¹æ¯”æµ‹è¯•

å¯¹æ¯”SVDæ–¹æ³•å’Œä½ç†µå¯¼å‘ä¼˜åŒ–æ–¹æ³•çš„:
1. é‡æ„è¯¯å·® (FrobeniusèŒƒæ•°)
2. ç›¸å¯¹è¯¯å·®
3. è¿è¡Œæ—¶é—´
4. å†…å­˜å ç”¨
"""

import torch
import time
import numpy as np
from typing import Tuple

# æ·»åŠ è·¯å¾„
import sys
import os
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

from apt.core.modeling.apt_model import DBCDAC_Optimizer


def svd_low_rank_approx(A: torch.Tensor, rank_ratio: float) -> Tuple[torch.Tensor, float]:
    """
    ä½¿ç”¨SVDè¿›è¡Œä½ç§©è¿‘ä¼¼ï¼ˆåŸå§‹æ–¹æ³•ï¼‰

    è¿”å›: (è¿‘ä¼¼çŸ©é˜µ, è¿è¡Œæ—¶é—´)
    """
    start_time = time.time()

    m, n = A.shape
    r = max(1, int(min(m, n) * rank_ratio))

    # SVDåˆ†è§£
    U, S, V = torch.linalg.svd(A, full_matrices=False)

    # ä½ç§©è¿‘ä¼¼
    U_r = U[:, :r]
    S_r = torch.diag(S[:r])
    V_r = V[:r, :].T

    A_approx = U_r @ S_r @ V_r.T

    elapsed = time.time() - start_time
    return A_approx, elapsed


def projection_eigenvalue_approx(A: torch.Tensor, rank_ratio: float) -> Tuple[torch.Tensor, float]:
    """
    ä½¿ç”¨æŠ•å½±-ç‰¹å¾å€¼æ–¹æ³•è¿›è¡Œä½ç§©è¿‘ä¼¼ï¼ˆä¼˜åŒ–æ–¹æ³•ï¼‰

    è¿”å›: (è¿‘ä¼¼çŸ©é˜µ, è¿è¡Œæ—¶é—´)
    """
    start_time = time.time()

    m, n = A.shape
    r = max(1, int(min(m, n) * rank_ratio))

    # æŠ•å½±-ç‰¹å¾å€¼æ–¹æ³•
    if m >= n:
        # è¡Œæ•°å¤šï¼ŒæŠ•å½±åˆ°åˆ—ç©ºé—´
        Q = torch.randn(n, r, device=A.device, dtype=A.dtype)
        Q, _ = torch.linalg.qr(Q)
        Y = A @ Q

        C = Y.T @ Y
        eigenvalues, eigenvectors = torch.linalg.eigh(C)

        idx = torch.argsort(eigenvalues, descending=True)
        eigenvalues = eigenvalues[idx]
        eigenvectors = eigenvectors[:, idx]

        U_r = Y @ eigenvectors
        V_r = Q @ eigenvectors
        S_r = torch.diag(torch.sqrt(eigenvalues.clamp(min=0)))

        A_approx = U_r @ S_r @ V_r.T
    else:
        # åˆ—æ•°å¤šï¼ŒæŠ•å½±åˆ°è¡Œç©ºé—´
        Q = torch.randn(m, r, device=A.device, dtype=A.dtype)
        Q, _ = torch.linalg.qr(Q)
        Y = A.T @ Q

        C = Y.T @ Y
        eigenvalues, eigenvectors = torch.linalg.eigh(C)

        idx = torch.argsort(eigenvalues, descending=True)
        eigenvalues = eigenvalues[idx]
        eigenvectors = eigenvectors[:, idx]

        V_r = Y @ eigenvectors
        U_r = Q @ eigenvectors
        S_r = torch.diag(torch.sqrt(eigenvalues.clamp(min=0)))

        A_approx = U_r @ S_r @ V_r.T

    elapsed = time.time() - start_time
    return A_approx, elapsed


def compute_errors(A: torch.Tensor, A_approx: torch.Tensor) -> dict:
    """è®¡ç®—é‡æ„è¯¯å·®æŒ‡æ ‡"""

    # FrobeniusèŒƒæ•°è¯¯å·®
    frobenius_error = torch.norm(A - A_approx, p='fro').item()

    # ç›¸å¯¹Frobeniusè¯¯å·®
    relative_error = frobenius_error / torch.norm(A, p='fro').item()

    # æœ€å¤§ç»å¯¹è¯¯å·®
    max_error = torch.max(torch.abs(A - A_approx)).item()

    # å¹³å‡ç»å¯¹è¯¯å·®
    mean_error = torch.mean(torch.abs(A - A_approx)).item()

    return {
        'frobenius': frobenius_error,
        'relative': relative_error,
        'max': max_error,
        'mean': mean_error
    }


def test_matrix_size(m: int, n: int, rank_ratio: float = 0.1, num_trials: int = 5):
    """æµ‹è¯•ç‰¹å®šçŸ©é˜µå¤§å°"""

    print(f"\n{'='*70}")
    print(f"çŸ©é˜µå¤§å°: {m} Ã— {n}, ç§©æ¯”ç‡: {rank_ratio:.1%}")
    print(f"{'='*70}")

    # æ”¶é›†å¤šæ¬¡è¯•éªŒçš„ç»“æœ
    svd_times = []
    opt_times = []
    svd_errors = []
    opt_errors = []

    for trial in range(num_trials):
        # ç”Ÿæˆéšæœºæµ‹è¯•çŸ©é˜µ
        A = torch.randn(m, n, dtype=torch.float32)

        # SVDæ–¹æ³•
        A_svd, time_svd = svd_low_rank_approx(A, rank_ratio)
        errors_svd = compute_errors(A, A_svd)

        # ä¼˜åŒ–æ–¹æ³•
        A_opt, time_opt = projection_eigenvalue_approx(A, rank_ratio)
        errors_opt = compute_errors(A, A_opt)

        svd_times.append(time_svd)
        opt_times.append(time_opt)
        svd_errors.append(errors_svd)
        opt_errors.append(errors_opt)

    # è®¡ç®—å¹³å‡å€¼
    avg_time_svd = np.mean(svd_times)
    avg_time_opt = np.mean(opt_times)

    avg_error_svd = {
        key: np.mean([e[key] for e in svd_errors])
        for key in svd_errors[0].keys()
    }
    avg_error_opt = {
        key: np.mean([e[key] for e in opt_errors])
        for key in opt_errors[0].keys()
    }

    # æ‰“å°ç»“æœ
    print(f"\nã€è¿è¡Œæ—¶é—´å¯¹æ¯”ã€‘")
    print(f"  SVDæ–¹æ³•:     {avg_time_svd*1000:8.2f} ms")
    print(f"  ä¼˜åŒ–æ–¹æ³•:    {avg_time_opt*1000:8.2f} ms")
    print(f"  é€Ÿåº¦æå‡:    {avg_time_svd/avg_time_opt:8.1f}x ğŸš€")

    print(f"\nã€é‡æ„è¯¯å·®å¯¹æ¯”ã€‘")
    print(f"  æŒ‡æ ‡                  SVDæ–¹æ³•         ä¼˜åŒ–æ–¹æ³•        è¯¯å·®æ¯”")
    print(f"  {'-'*66}")
    print(f"  FrobeniusèŒƒæ•°:    {avg_error_svd['frobenius']:12.6f}  {avg_error_opt['frobenius']:12.6f}  {avg_error_opt['frobenius']/avg_error_svd['frobenius']:6.2f}x")
    print(f"  ç›¸å¯¹è¯¯å·®:         {avg_error_svd['relative']:12.6f}  {avg_error_opt['relative']:12.6f}  {avg_error_opt['relative']/avg_error_svd['relative']:6.2f}x")
    print(f"  æœ€å¤§è¯¯å·®:         {avg_error_svd['max']:12.6f}  {avg_error_opt['max']:12.6f}  {avg_error_opt['max']/avg_error_svd['max']:6.2f}x")
    print(f"  å¹³å‡è¯¯å·®:         {avg_error_svd['mean']:12.6f}  {avg_error_opt['mean']:12.6f}  {avg_error_opt['mean']/avg_error_svd['mean']:6.2f}x")

    return {
        'size': (m, n),
        'speedup': avg_time_svd / avg_time_opt,
        'error_ratio': avg_error_opt['relative'] / avg_error_svd['relative']
    }


def test_rank_ratio(m: int = 500, n: int = 500):
    """æµ‹è¯•ä¸åŒç§©æ¯”ç‡çš„å½±å“"""

    print(f"\n{'='*70}")
    print(f"ç§©æ¯”ç‡å½±å“æµ‹è¯• (çŸ©é˜µå¤§å°: {m} Ã— {n})")
    print(f"{'='*70}")

    rank_ratios = [0.05, 0.1, 0.2, 0.3, 0.5]

    print(f"\nç§©æ¯”ç‡    SVDæ—¶é—´    ä¼˜åŒ–æ—¶é—´    é€Ÿåº¦æå‡    ç›¸å¯¹è¯¯å·®æ¯”")
    print(f"{'-'*70}")

    for ratio in rank_ratios:
        A = torch.randn(m, n, dtype=torch.float32)

        A_svd, time_svd = svd_low_rank_approx(A, ratio)
        errors_svd = compute_errors(A, A_svd)

        A_opt, time_opt = projection_eigenvalue_approx(A, ratio)
        errors_opt = compute_errors(A, A_opt)

        speedup = time_svd / time_opt
        error_ratio = errors_opt['relative'] / errors_svd['relative']

        print(f"{ratio:6.1%}    {time_svd*1000:7.1f}ms   {time_opt*1000:7.1f}ms    {speedup:6.1f}x      {error_ratio:6.2f}x")


def test_gradient_like_matrices():
    """æµ‹è¯•ç±»ä¼¼æ¢¯åº¦çš„çœŸå®åœºæ™¯çŸ©é˜µ"""

    print(f"\n{'='*70}")
    print(f"çœŸå®æ¢¯åº¦åœºæ™¯æµ‹è¯•")
    print(f"{'='*70}")

    # æ¨¡æ‹Ÿä¸åŒå±‚çš„æ¢¯åº¦çŸ©é˜µ
    scenarios = [
        ("Embeddingå±‚", 5000, 256),
        ("Attention Q", 256, 256),
        ("Attention K", 256, 256),
        ("Attention V", 256, 256),
        ("FFN Layer1", 256, 1024),
        ("FFN Layer2", 1024, 256),
        ("è¾“å‡ºæŠ•å½±", 256, 5000),
    ]

    print(f"\nå±‚åç§°           çŸ©é˜µå¤§å°      SVDæ—¶é—´   ä¼˜åŒ–æ—¶é—´   é€Ÿåº¦æå‡   è¯¯å·®æ¯”")
    print(f"{'-'*80}")

    for name, m, n in scenarios:
        # ç”Ÿæˆç±»æ¢¯åº¦çŸ©é˜µï¼ˆé€šå¸¸æ˜¯ç¨€ç–ä¸”ä½ç§©çš„ï¼‰
        A = torch.randn(m, n, dtype=torch.float32) * 0.1
        # æ·»åŠ å°‘é‡å¤§å€¼ï¼ˆæ¨¡æ‹Ÿæ¢¯åº¦ä¸­çš„é‡è¦æ–¹å‘ï¼‰
        r = max(1, int(min(m, n) * 0.1))
        for i in range(r):
            A[i % m, i % n] += torch.randn(1).item() * 2.0

        A_svd, time_svd = svd_low_rank_approx(A, 0.1)
        errors_svd = compute_errors(A, A_svd)

        A_opt, time_opt = projection_eigenvalue_approx(A, 0.1)
        errors_opt = compute_errors(A, A_opt)

        speedup = time_svd / time_opt
        error_ratio = errors_opt['relative'] / errors_svd['relative']

        print(f"{name:15} {m:4d}Ã—{n:4d}   {time_svd*1000:7.1f}ms {time_opt*1000:7.1f}ms   {speedup:6.1f}x    {error_ratio:5.2f}x")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""

    print("\n" + "="*70)
    print("DBC-DAC ä¼˜åŒ–æ–¹æ³•è¯¯å·®å¯¹æ¯”æµ‹è¯•")
    print("å¯¹æ¯”: SVDåˆ†è§£ vs æŠ•å½±-ç‰¹å¾å€¼æ–¹æ³•")
    print("="*70)

    # æµ‹è¯•1: ä¸åŒçŸ©é˜µå¤§å°
    print("\n\n" + "â–ˆ"*70)
    print("â–ˆ æµ‹è¯•1: ä¸åŒçŸ©é˜µå¤§å°çš„æ€§èƒ½å¯¹æ¯”")
    print("â–ˆ"*70)

    results = []
    sizes = [
        (100, 100),
        (200, 200),
        (500, 500),
        (1000, 1000),
        (2000, 1000),
    ]

    for m, n in sizes:
        result = test_matrix_size(m, n, rank_ratio=0.1, num_trials=3)
        results.append(result)

    # æµ‹è¯•2: ä¸åŒç§©æ¯”ç‡
    print("\n\n" + "â–ˆ"*70)
    print("â–ˆ æµ‹è¯•2: ä¸åŒç§©æ¯”ç‡çš„å½±å“")
    print("â–ˆ"*70)
    test_rank_ratio(500, 500)

    # æµ‹è¯•3: çœŸå®æ¢¯åº¦åœºæ™¯
    print("\n\n" + "â–ˆ"*70)
    print("â–ˆ æµ‹è¯•3: çœŸå®æ¢¯åº¦çŸ©é˜µåœºæ™¯")
    print("â–ˆ"*70)
    test_gradient_like_matrices()

    # æ€»ç»“
    print("\n\n" + "="*70)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("="*70)

    avg_speedup = np.mean([r['speedup'] for r in results])
    avg_error_ratio = np.mean([r['error_ratio'] for r in results])

    print(f"\nå¹³å‡æ€§èƒ½æŒ‡æ ‡:")
    print(f"  é€Ÿåº¦æå‡:     {avg_speedup:.1f}x ğŸš€")
    print(f"  è¯¯å·®æ¯”ä¾‹:     {avg_error_ratio:.2f}x")

    print(f"\nç»“è®º:")
    if avg_error_ratio < 2.0:
        print(f"  âœ… ä¼˜åŒ–æ–¹æ³•åœ¨ä¿æŒç›¸è¿‘ç²¾åº¦ä¸‹ï¼Œé€Ÿåº¦æå‡{avg_speedup:.0f}å€")
        print(f"  âœ… è¯¯å·®å¢åŠ åœ¨å¯æ¥å—èŒƒå›´å†… ({avg_error_ratio:.1f}å€)")
        print(f"  âœ… é€‚åˆç”¨äºDBC-DACæ¢¯åº¦ç¨³å®š")
    else:
        print(f"  âš ï¸  ä¼˜åŒ–æ–¹æ³•é€Ÿåº¦å¿«{avg_speedup:.0f}å€ï¼Œä½†è¯¯å·®å¢åŠ è¾ƒå¤š ({avg_error_ratio:.1f}å€)")
        print(f"  ğŸ’¡ å»ºè®®è°ƒæ•´å‚æ•°æˆ–ä½¿ç”¨æ›´ç²¾ç¡®çš„æŠ•å½±æ–¹æ³•")

    print("\n" + "="*70)


if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§
    torch.manual_seed(42)
    np.random.seed(42)

    main()
