#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""ç®€å•æµ‹è¯•bert-base-chinese tokenizeræ˜¯å¦èƒ½åŠ è½½"""

from transformers import BertTokenizer

print("ğŸ”§ æµ‹è¯•åŠ è½½bert-base-chinese tokenizer...")

try:
    tokenizer = BertTokenizer.from_pretrained('./bert/bert-base-chinese')
    print(f"âœ… TokenizeråŠ è½½æˆåŠŸ!")
    print(f"   è¯æ±‡è¡¨å¤§å°: {tokenizer.vocab_size}")

    # æµ‹è¯•ç¼–ç 
    test_text = "ä½ å¥½ï¼Œä¸–ç•Œï¼"
    encoded = tokenizer.encode(test_text)
    print(f"\nğŸ“ æµ‹è¯•ç¼–ç :")
    print(f"   è¾“å…¥: {test_text}")
    print(f"   ç¼–ç : {encoded}")
    print(f"   è§£ç : {tokenizer.decode(encoded)}")

    print("\nâœ… Tokenizeræµ‹è¯•é€šè¿‡ï¼")

except Exception as e:
    print(f"âŒ é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()
