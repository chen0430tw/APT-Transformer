#!/usr/bin/env python3
"""
ä¸ºè®­ç»ƒè„šæœ¬æ·»åŠ æ¢å¤åŠŸèƒ½çš„è¡¥ä¸

ç”¨æ³•:
1. åœ¨train_control_experiment.pyä¸­æ·»åŠ --resumeå‚æ•°
2. åœ¨test_hlbd_quick_learning.pyä¸­æ·»åŠ --resumeå‚æ•°
"""

# ============================================================================
# å¯¹ç…§å®éªŒè®­ç»ƒæ¢å¤åŠŸèƒ½
# ============================================================================

def add_resume_to_control_experiment():
    """
    ä¸ºtrain_control_experiment.pyæ·»åŠ æ¢å¤åŠŸèƒ½

    ä½¿ç”¨æ–¹æ³•:
    1. è®­ç»ƒä¸­æ–­åï¼Œæ‰¾åˆ°æœ€æ–°çš„checkpoint
       ls -lt control_experiments/*.pt | head -1

    2. æ¢å¤è®­ç»ƒ
       python train_control_experiment.py --resume control_experiments/control_epoch_25.pt
    """

    example_code = """
# åœ¨ControlExperimentTrainerç±»ä¸­æ·»åŠ :

def load_checkpoint(self, checkpoint_path: str):
    \"\"\"ä»checkpointæ¢å¤è®­ç»ƒ\"\"\"
    print(f"\\nğŸ“¦ ä»checkpointæ¢å¤è®­ç»ƒ: {checkpoint_path}")

    # åˆ¤æ–­æ˜¯å¯¹ç…§ç»„è¿˜æ˜¯å®éªŒç»„
    is_control = 'control' in checkpoint_path

    ckpt = torch.load(checkpoint_path)

    if is_control:
        self.control_model.load_state_dict(ckpt['model_state_dict'])
        self.control_optimizer.load_state_dict(ckpt['optimizer_state_dict'])
        self.control_losses = ckpt['losses']
        start_epoch = ckpt['epoch']
        print(f"   âœ“ å¯¹ç…§ç»„æ¨¡å‹å·²æ¢å¤åˆ°epoch {start_epoch}")
    else:
        self.autopoietic_model.load_state_dict(ckpt['model_state_dict'])
        self.autopoietic_optimizer.load_state_dict(ckpt['optimizer_state_dict'])
        self.autopoietic_losses = ckpt['losses']
        start_epoch = ckpt['epoch']
        print(f"   âœ“ å®éªŒç»„æ¨¡å‹å·²æ¢å¤åˆ°epoch {start_epoch}")

    return start_epoch


# åœ¨main()å‡½æ•°ä¸­æ·»åŠ å‚æ•°:

parser.add_argument('--resume', type=str, default=None,
                    help='ä»checkpointæ¢å¤è®­ç»ƒ (è·¯å¾„åˆ°.ptæ–‡ä»¶)')

# åœ¨è®­ç»ƒå¾ªç¯å‰æ·»åŠ :

start_epoch = 0
if args.resume:
    # æ¢å¤å¯¹ç…§ç»„
    control_resume = args.resume.replace('autopoietic', 'control')
    if Path(control_resume).exists():
        start_epoch = trainer.load_checkpoint(control_resume)

    # æ¢å¤å®éªŒç»„
    autopoietic_resume = args.resume.replace('control', 'autopoietic')
    if Path(autopoietic_resume).exists():
        trainer.load_checkpoint(autopoietic_resume)

# ä¿®æ”¹è®­ç»ƒå¾ªç¯:

for epoch in range(start_epoch, args.epochs):  # ä»start_epochå¼€å§‹
    print(f"\\nğŸ“ Epoch {epoch + 1}/{args.epochs}")
    ...
"""

    return example_code


# ============================================================================
# å¤šè®­ç»ƒç›‘æ§æ–¹æ¡ˆ
# ============================================================================

def multi_training_monitor_design():
    """
    è®¾è®¡å¤šè®­ç»ƒç›‘æ§ç³»ç»Ÿ

    æ–¹æ¡ˆ1: å¤šçª—å£æ¨¡å¼ï¼ˆå½“å‰ï¼‰
    - ä¼˜ç‚¹: ç®€å•ï¼Œæ¯ä¸ªçª—å£ç‹¬ç«‹
    - ç¼ºç‚¹: éœ€è¦æ‰‹åŠ¨å¼€å¤šä¸ªçª—å£

    æ–¹æ¡ˆ2: å•çª—å£å¤šé¢æ¿
    - ä¼˜ç‚¹: ç»Ÿä¸€ç•Œé¢ï¼Œæ–¹ä¾¿å¯¹æ¯”
    - ç¼ºç‚¹: å±å¹•ç©ºé—´æœ‰é™

    æ–¹æ¡ˆ3: è‡ªåŠ¨å‘ç°æ¨¡å¼
    - ä¼˜ç‚¹: è‡ªåŠ¨ç›‘æ§æ‰€æœ‰è®­ç»ƒ
    - ç¼ºç‚¹: å®ç°å¤æ‚
    """

    # æ–¹æ¡ˆ1ç¤ºä¾‹ï¼ˆå½“å‰å®ç°ï¼‰
    usage_current = """
# åŒæ—¶ç›‘æ§3ä¸ªå®éªŒ
python visualize_training.py --log-dir exp1_baseline &
python visualize_training.py --log-dir exp2_large_lr &
python visualize_training.py --log-dir exp3_small_model &

# æ¯ä¸ªçª—å£ç‹¬ç«‹æ˜¾ç¤º
"""

    # æ–¹æ¡ˆ2ç¤ºä¾‹ï¼ˆå•çª—å£å¤šé¢æ¿ï¼‰
    usage_multi_panel = """
# ä¸€ä¸ªçª—å£æ˜¾ç¤ºå¤šä¸ªå®éªŒ
python visualize_training.py \\
    --experiments exp1_baseline exp2_large_lr exp3_small_model \\
    --mode compare

# ç•Œé¢å¸ƒå±€:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Experiment Comparison                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Exp 1   â”‚  Exp 2   â”‚  Combined Loss   â”‚
â”‚  Loss    â”‚  Loss    â”‚  Curves          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Exp 3   â”‚  Stats   â”‚  Best Model      â”‚
â”‚  Loss    â”‚  Table   â”‚  Highlight       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

    # æ–¹æ¡ˆ3ç¤ºä¾‹ï¼ˆè‡ªåŠ¨å‘ç°ï¼‰
    usage_auto_discover = """
# è‡ªåŠ¨ç›‘æ§å½“å‰ç›®å½•ä¸‹æ‰€æœ‰è®­ç»ƒ
python visualize_training.py --auto-discover

# ä¼šæ‰«æ:
# - control_experiments/
# - playground_*/
# - tests/saved_models/
#
# å¹¶æ˜¾ç¤ºæ´»è·ƒçš„è®­ç»ƒåˆ—è¡¨:
ğŸ” å‘ç°3ä¸ªæ´»è·ƒè®­ç»ƒ:
  1. control_experiments (Epoch 42/100, æ´»è·ƒ)
  2. playground_wikitext (Epoch 15/50, æ´»è·ƒ)
  3. exp_custom (Epoch 8/20, æš‚åœ)

é€‰æ‹©è¦ç›‘æ§çš„è®­ç»ƒ: [1-3] æˆ– 'all':
"""

    return {
        'current': usage_current,
        'multi_panel': usage_multi_panel,
        'auto_discover': usage_auto_discover
    }


# ============================================================================
# å¿«é€Ÿè§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨tmuxå¤šçª—æ ¼
# ============================================================================

def tmux_multi_monitor_setup():
    """
    ä½¿ç”¨tmuxå®ç°å¤šè®­ç»ƒç›‘æ§

    ä¼˜ç‚¹:
    - ä¸éœ€è¦ä¿®æ”¹ä»£ç 
    - å¯ä»¥åŒæ—¶çœ‹åˆ°å¤šä¸ªå¯è§†åŒ–
    - å¯ä»¥è¿œç¨‹è¿æ¥
    """

    tmux_script = """#!/bin/bash
# åˆ›å»ºtmuxä¼šè¯ç”¨äºå¤šè®­ç»ƒç›‘æ§

# åˆ›å»ºæ–°ä¼šè¯
tmux new-session -d -s apt_training

# åˆ†å‰²çª—æ ¼
tmux split-window -h
tmux split-window -v
tmux select-pane -t 0
tmux split-window -v

# çª—æ ¼å¸ƒå±€:
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ Train 1 â”‚ Visual1 â”‚
# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
# â”‚ Train 2 â”‚ Visual2 â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# å¯åŠ¨è®­ç»ƒå’Œå¯è§†åŒ–
tmux select-pane -t 0
tmux send-keys "python train_control_experiment.py --epochs 100 --save-dir exp1" C-m

tmux select-pane -t 1
tmux send-keys "sleep 5 && python visualize_training.py --log-dir exp1 --refresh 2" C-m

tmux select-pane -t 2
tmux send-keys "python train_control_experiment.py --epochs 100 --save-dir exp2 --lr 1e-3" C-m

tmux select-pane -t 3
tmux send-keys "sleep 5 && python visualize_training.py --log-dir exp2 --refresh 2" C-m

# è¿æ¥åˆ°ä¼šè¯
tmux attach-session -t apt_training

# æ“ä½œè¯´æ˜:
# Ctrl+B + æ–¹å‘é”®: åˆ‡æ¢çª—æ ¼
# Ctrl+B + d: åˆ†ç¦»ä¼šè¯ï¼ˆåå°è¿è¡Œï¼‰
# tmux attach -t apt_training: é‡æ–°è¿æ¥
"""

    return tmux_script


if __name__ == "__main__":
    print("è®­ç»ƒæ¢å¤å’Œå¤šç›‘æ§è§£å†³æ–¹æ¡ˆ")
    print("=" * 60)

    print("\n1ï¸âƒ£  è®­ç»ƒæ¢å¤åŠŸèƒ½:")
    print(add_resume_to_control_experiment())

    print("\n2ï¸âƒ£  å¤šè®­ç»ƒç›‘æ§æ–¹æ¡ˆ:")
    designs = multi_training_monitor_design()
    print("\nå½“å‰æ–¹æ¡ˆï¼ˆå¤šçª—å£ï¼‰:")
    print(designs['current'])

    print("\n3ï¸âƒ£  å¿«é€Ÿè§£å†³æ–¹æ¡ˆï¼ˆtmuxï¼‰:")
    print(tmux_multi_monitor_setup())
