# æ•™å¸ˆæ¨¡å‹APIæ¥å£ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

æ•™å¸ˆæ¨¡å‹APIæ¥å£å…è®¸ä½ ä½¿ç”¨è¿œç¨‹çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚GPT-4ã€Claudeï¼‰ä½œä¸ºæ•™å¸ˆè¿›è¡ŒçŸ¥è¯†è’¸é¦ï¼Œè€Œæ— éœ€åœ¨æœ¬åœ°è¿è¡Œè¿™äº›å¤§æ¨¡å‹ã€‚

**æ ¸å¿ƒä¼˜åŠ¿:**
- æ— éœ€æœ¬åœ°GPUèµ„æºè¿è¡Œå¤§æ¨¡å‹
- å¯ä½¿ç”¨æœ€å…ˆè¿›çš„å•†ä¸šæ¨¡å‹ä½œä¸ºæ•™å¸ˆ
- çµæ´»çš„APIé€‰æ‹©
- è‡ªåŠ¨é‡è¯•å’Œé”™è¯¯å¤„ç†

---

## æ”¯æŒçš„API

### 1. OpenAI API
- GPT-4, GPT-4-turbo
- GPT-3.5-turbo
- GPT-3

### 2. Anthropic API
- Claude-3 (Opus, Sonnet, Haiku)
- Claude-2

### 3. ç¡…åŸºæµåŠ¨API (SiliconFlow)
- Qwen2ç³»åˆ— (é€šä¹‰åƒé—®)
- DeepSeekç³»åˆ—
- GLM-4ç³»åˆ— (æ™ºè°±)
- Llama-3ç³»åˆ—
- å…¶ä»–å›½äº§å¼€æºæ¨¡å‹

### 4. è‡ªå®šä¹‰API
- ä»»ä½•ç¬¦åˆRESTfulè§„èŒƒçš„API
- æœ¬åœ°éƒ¨ç½²çš„æ¨¡å‹æœåŠ¡

---

## å¿«é€Ÿå¼€å§‹

### æ–¹æ³•1: ä½¿ç”¨OpenAIä½œä¸ºæ•™å¸ˆ

```python
from apt_model.plugins.teacher_api import create_api_teacher_model
from apt_model.plugins.visual_distillation_plugin import quick_visual_distill
from transformers import AutoTokenizer

# 1. åˆ›å»ºæ•™å¸ˆæ¨¡å‹ï¼ˆGPT-4ï¼‰
tokenizer = AutoTokenizer.from_pretrained("gpt2")

teacher_model = create_api_teacher_model(
    provider='openai',
    api_key='sk-...',  # ä½ çš„OpenAI API key
    model_name='gpt-4',
    tokenizer=tokenizer,
    vocab_size=50000
)

# 2. åŠ è½½å­¦ç”Ÿæ¨¡å‹
from apt_model.training.checkpoint import load_model
student_model, _, _ = load_model("apt_model_small")

# 3. å‡†å¤‡æ•°æ®
train_dataloader = get_dataloader()

# 4. å¼€å§‹è’¸é¦
quick_visual_distill(
    student_model=student_model,
    teacher_model=teacher_model,  # APIæ•™å¸ˆæ¨¡å‹
    train_dataloader=train_dataloader,
    tokenizer=tokenizer,
    num_epochs=3,
    device='cuda'
)
```

### æ–¹æ³•2: ä½¿ç”¨Claudeä½œä¸ºæ•™å¸ˆ

```python
from apt_model.plugins.teacher_api import create_api_teacher_model

teacher_model = create_api_teacher_model(
    provider='anthropic',
    api_key='sk-ant-...',  # ä½ çš„Anthropic API key
    model_name='claude-3-sonnet-20240229',
    tokenizer=tokenizer,
    vocab_size=50000
)

# å…¶ä½™æ­¥éª¤ç›¸åŒ
```

### æ–¹æ³•3: ä½¿ç”¨ç¡…åŸºæµåŠ¨API

```python
from apt_model.plugins.teacher_api import create_api_teacher_model

teacher_model = create_api_teacher_model(
    provider='siliconflow',
    api_key='sk-...',  # ä½ çš„ç¡…åŸºæµåŠ¨ API key
    model_name='Qwen/Qwen2-7B-Instruct',
    tokenizer=tokenizer,
    vocab_size=50000
)

# å…¶ä½™æ­¥éª¤ç›¸åŒ
```

### æ–¹æ³•4: ä½¿ç”¨è‡ªå®šä¹‰API

```python
teacher_model = create_api_teacher_model(
    provider='custom',
    api_key='your-api-key',
    base_url='https://your-api.com',
    tokenizer=tokenizer,
    vocab_size=50000
)
```

---

## è¯¦ç»†é…ç½®

### OpenAIé…ç½®

```python
from apt_model.plugins.teacher_api import OpenAITeacherAPI

config = {
    'api_key': 'sk-...',
    'model_name': 'gpt-4',  # æˆ– 'gpt-3.5-turbo'
    'base_url': None,  # å¯é€‰ï¼Œä½¿ç”¨ä»£ç†æˆ–è‡ªå®šä¹‰ç«¯ç‚¹
    'timeout': 30,  # APIè¶…æ—¶ï¼ˆç§’ï¼‰
    'max_retries': 3,  # æœ€å¤§é‡è¯•æ¬¡æ•°
    'retry_delay': 1.0,  # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
}

api = OpenAITeacherAPI(config)
```

**å¯ç”¨æ¨¡å‹:**
- `gpt-4` - æœ€å¼ºå¤§ï¼ˆæœ€è´µï¼‰
- `gpt-4-turbo` - æ›´å¿«çš„GPT-4
- `gpt-3.5-turbo` - æ€§ä»·æ¯”é«˜
- `gpt-3.5-turbo-16k` - é•¿ä¸Šä¸‹æ–‡

### Anthropicé…ç½®

```python
from apt_model.plugins.teacher_api import AnthropicTeacherAPI

config = {
    'api_key': 'sk-ant-...',
    'model_name': 'claude-3-sonnet-20240229',
    'timeout': 30,
    'max_retries': 3,
    'retry_delay': 1.0,
}

api = AnthropicTeacherAPI(config)
```

**å¯ç”¨æ¨¡å‹:**
- `claude-3-opus-20240229` - æœ€å¼ºå¤§
- `claude-3-sonnet-20240229` - å¹³è¡¡æ€§èƒ½
- `claude-3-haiku-20240307` - æœ€å¿«é€Ÿ
- `claude-2.1` - å‰ä»£æ¨¡å‹

### ç¡…åŸºæµåŠ¨é…ç½®

```python
from apt_model.plugins.teacher_api import SiliconFlowTeacherAPI

config = {
    'api_key': 'sk-...',
    'model_name': 'Qwen/Qwen2-7B-Instruct',
    'base_url': 'https://api.siliconflow.cn/v1',  # é»˜è®¤å€¼ï¼Œå¯çœç•¥
    'timeout': 30,
    'max_retries': 3,
    'retry_delay': 1.0,
}

api = SiliconFlowTeacherAPI(config)
```

**å¯ç”¨æ¨¡å‹:**
- `Qwen/Qwen2-7B-Instruct` - é€šä¹‰åƒé—®2ä»£ 7Bï¼ˆæ¨èï¼‰
- `Qwen/Qwen2-72B-Instruct` - é€šä¹‰åƒé—®2ä»£ 72Bï¼ˆæ›´å¼ºå¤§ï¼‰
- `deepseek-ai/DeepSeek-V2.5` - DeepSeek V2.5
- `THUDM/glm-4-9b-chat` - æ™ºè°± GLM-4 9B
- `meta-llama/Meta-Llama-3-8B-Instruct` - Llama-3 8B
- `meta-llama/Meta-Llama-3-70B-Instruct` - Llama-3 70B

**ä¼˜åŠ¿:**
- å›½å†…è®¿é—®é€Ÿåº¦å¿«
- æ”¯æŒå¤šç§å›½äº§å¼€æºæ¨¡å‹
- ä»·æ ¼ç›¸å¯¹ä¾¿å®œ
- å…¼å®¹OpenAIæ¥å£æ ¼å¼

### è‡ªå®šä¹‰APIé…ç½®

```python
from apt_model.plugins.teacher_api import CustomTeacherAPI

config = {
    'api_key': 'your-key',
    'base_url': 'https://your-api.com',
    'model_name': 'your-model',  # å¯é€‰
    'timeout': 30,
    'max_retries': 3,
}

api = CustomTeacherAPI(config)
```

**APIè§„èŒƒè¦æ±‚:**

ç”Ÿæˆæ–‡æœ¬ç«¯ç‚¹:
```
POST {base_url}/generate
Content-Type: application/json
Authorization: Bearer {api_key}

Request:
{
    "input": "è¾“å…¥æ–‡æœ¬",
    "max_tokens": 100,
    "temperature": 1.0
}

Response:
{
    "text": "ç”Ÿæˆçš„æ–‡æœ¬",
    "output": "æˆ–è€…è¿™ä¸ªå­—æ®µ"
}
```

è·å–logitsç«¯ç‚¹:
```
POST {base_url}/logits
Content-Type: application/json
Authorization: Bearer {api_key}

Request:
{
    "input": "è¾“å…¥æ–‡æœ¬",
    "return_logits": true
}

Response:
{
    "logits": [[...], [...], ...]  # 3Dæ•°ç»„
}
```

---

## APIæ¥å£è¯¦è§£

### 1. æ–‡æœ¬ç”Ÿæˆ

```python
api = create_teacher_api(
    provider='openai',
    api_key='sk-...',
    model_name='gpt-4'
)

# ç”Ÿæˆæ–‡æœ¬
text = api.generate_text(
    input_text="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
    max_tokens=100,
    temperature=0.7
)

print(text)
# è¾“å‡º: äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯...
```

### 2. è·å–Logits

```python
# è·å–logitsï¼ˆç”¨äºè’¸é¦ï¼‰
logits = api.get_logits(
    input_text="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
    vocab_size=50000
)

print(logits.shape)  # [1, seq_len, vocab_size]
```

### 3. ç»Ÿè®¡ä¿¡æ¯

```python
# æŸ¥çœ‹APIè°ƒç”¨ç»Ÿè®¡
print(api.stats)
# {
#     'total_calls': 100,
#     'successful_calls': 98,
#     'failed_calls': 2,
#     'total_tokens': 15000
# }
```

---

## å®Œæ•´è’¸é¦ç¤ºä¾‹

### ç¤ºä¾‹1: GPT-4 â†’ å°æ¨¡å‹

```python
from apt_model.plugins.teacher_api import create_api_teacher_model
from apt_model.plugins.visual_distillation_plugin import VisualDistillationPlugin
from apt_model.training.checkpoint import load_model
from transformers import AutoTokenizer
import torch

# 1. é…ç½®
tokenizer = AutoTokenizer.from_pretrained("gpt2")

# 2. åˆ›å»ºGPT-4æ•™å¸ˆæ¨¡å‹
teacher_model = create_api_teacher_model(
    provider='openai',
    api_key='sk-...',
    model_name='gpt-4',
    tokenizer=tokenizer,
    vocab_size=50000,
    timeout=60,  # GPT-4å¯èƒ½è¾ƒæ…¢
    max_retries=5
)

# 3. åŠ è½½å­¦ç”Ÿæ¨¡å‹
student_model, _, config = load_model("apt_model_small")

# 4. å‡†å¤‡æ•°æ®
from torch.utils.data import DataLoader, TensorDataset
train_data = TensorDataset(torch.randint(0, 50000, (100, 32)))
train_dataloader = DataLoader(train_data, batch_size=4)

# 5. é…ç½®è’¸é¦
distill_config = {
    'temperature': 4.0,
    'alpha': 0.7,
    'beta': 0.3,
    'sample_frequency': 10,  # APIè°ƒç”¨è¾ƒæ…¢ï¼Œå°‘æ˜¾ç¤ºæ ·æœ¬
}

# 6. åˆ›å»ºè’¸é¦æ’ä»¶
plugin = VisualDistillationPlugin(distill_config)
optimizer = torch.optim.AdamW(student_model.parameters(), lr=1e-4)

# 7. å¼€å§‹è’¸é¦
plugin.visual_distill_model(
    student_model=student_model,
    teacher_model=teacher_model,
    train_dataloader=train_dataloader,
    optimizer=optimizer,
    tokenizer=tokenizer,
    num_epochs=3,
    device='cuda'
)

# 8. æŸ¥çœ‹ç»Ÿè®¡
print(f"\n[APIç»Ÿè®¡] æ€»è°ƒç”¨: {teacher_model.api.stats['total_calls']}")
print(f"[APIç»Ÿè®¡] æˆåŠŸ: {teacher_model.api.stats['successful_calls']}")
print(f"[APIç»Ÿè®¡] å¤±è´¥: {teacher_model.api.stats['failed_calls']}")
print(f"[APIç»Ÿè®¡] æ€»tokens: {teacher_model.api.stats['total_tokens']}")
```

### ç¤ºä¾‹2: Claude-3 â†’ å°æ¨¡å‹

```python
# ä½¿ç”¨Claude-3ä½œä¸ºæ•™å¸ˆ
teacher_model = create_api_teacher_model(
    provider='anthropic',
    api_key='sk-ant-...',
    model_name='claude-3-sonnet-20240229',
    tokenizer=tokenizer,
    vocab_size=50000
)

# å…¶ä½™æµç¨‹ç›¸åŒ
```

### ç¤ºä¾‹3: ç¡…åŸºæµåŠ¨Qwen2 â†’ å°æ¨¡å‹ï¼ˆä¸­æ–‡åœºæ™¯æ¨èï¼‰

```python
# ä½¿ç”¨ç¡…åŸºæµåŠ¨çš„Qwen2ä½œä¸ºæ•™å¸ˆï¼ˆé€‚åˆä¸­æ–‡ï¼‰
teacher_model = create_api_teacher_model(
    provider='siliconflow',
    api_key='sk-...',  # ç¡…åŸºæµåŠ¨API key
    model_name='Qwen/Qwen2-7B-Instruct',
    tokenizer=tokenizer,
    vocab_size=50000,
    timeout=30,
    max_retries=3
)

# é…ç½®ï¼šä¸­æ–‡åœºæ™¯ä¼˜åŒ–
distill_config = {
    'temperature': 3.0,  # ä¸­æ–‡æ¨¡å‹å¯ç”¨è¾ƒä½æ¸©åº¦
    'alpha': 0.7,
    'beta': 0.3,
    'sample_frequency': 5,  # ç¡…åŸºæµåŠ¨é€Ÿåº¦å¿«ï¼Œå¯å¤šæ˜¾ç¤ºæ ·æœ¬
    'show_samples': True,
}

# å…¶ä½™æµç¨‹ç›¸åŒ
```

**ä¼˜åŠ¿:**
- æˆæœ¬æä½ (~Â¥0.1/1000æ ·æœ¬)
- ä¸­æ–‡ç†è§£èƒ½åŠ›å¼º
- å›½å†…è®¿é—®é€Ÿåº¦å¿«
- é€‚åˆå¤§è§„æ¨¡ä¸­æ–‡æ•°æ®è’¸é¦

---

## æˆæœ¬ä¼°ç®—

### OpenAIå®šä»·ï¼ˆ2024å¹´ï¼‰

| æ¨¡å‹ | è¾“å…¥ä»·æ ¼/1M tokens | è¾“å‡ºä»·æ ¼/1M tokens |
|------|-------------------|-------------------|
| GPT-4 | $30 | $60 |
| GPT-4-turbo | $10 | $30 |
| GPT-3.5-turbo | $0.5 | $1.5 |

### Anthropicå®šä»·ï¼ˆ2024å¹´ï¼‰

| æ¨¡å‹ | è¾“å…¥ä»·æ ¼/1M tokens | è¾“å‡ºä»·æ ¼/1M tokens |
|------|-------------------|-------------------|
| Claude-3-Opus | $15 | $75 |
| Claude-3-Sonnet | $3 | $15 |
| Claude-3-Haiku | $0.25 | $1.25 |

### ç¡…åŸºæµåŠ¨å®šä»·ï¼ˆ2024å¹´ï¼‰

| æ¨¡å‹ | ä»·æ ¼/1M tokens | å¤‡æ³¨ |
|------|---------------|------|
| Qwen2-7B-Instruct | Â¥1.0 (~$0.14) | æ€§ä»·æ¯”é«˜ |
| Qwen2-72B-Instruct | Â¥5.0 (~$0.70) | æ›´å¼ºå¤§ |
| DeepSeek-V2.5 | Â¥1.0 (~$0.14) | æ¨ç†èƒ½åŠ›å¼º |
| GLM-4-9B | Â¥1.0 (~$0.14) | ä¸­æ–‡ä¼˜åŒ– |
| Llama-3-8B | Â¥0.6 (~$0.08) | æœ€ä¾¿å®œ |
| Llama-3-70B | Â¥3.0 (~$0.42) | æ€§èƒ½å¼º |

**æ³¨æ„:** ç¡…åŸºæµåŠ¨é€šå¸¸æŒ‰ç…§æ€»tokenæ•°è®¡è´¹ï¼ˆè¾“å…¥+è¾“å‡ºï¼‰ï¼Œä»·æ ¼ä»¥äººæ°‘å¸è®¡ä»·

### æˆæœ¬ä¼°ç®—ç¤ºä¾‹

å‡è®¾è®­ç»ƒ1000ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬å¹³å‡100 tokensï¼š

**ä½¿ç”¨GPT-3.5-turbo:**
- è¾“å…¥: 1000 Ã— 100 = 100,000 tokens = 0.1M
- æˆæœ¬: 0.1M Ã— $0.5 = **$0.05**

**ä½¿ç”¨GPT-4:**
- è¾“å…¥: 100,000 tokens = 0.1M
- æˆæœ¬: 0.1M Ã— $30 = **$3.00**

**ä½¿ç”¨Claude-3-Haiku:**
- è¾“å…¥: 100,000 tokens = 0.1M
- æˆæœ¬: 0.1M Ã— $0.25 = **$0.025**

**ä½¿ç”¨ç¡…åŸºæµåŠ¨Qwen2-7B:**
- æ€»tokens: 100,000 tokens = 0.1M
- æˆæœ¬: 0.1M Ã— Â¥1.0 = **Â¥0.1 (~$0.014)**

**ä½¿ç”¨ç¡…åŸºæµåŠ¨Llama-3-8Bï¼ˆæœ€ä¾¿å®œï¼‰:**
- æ€»tokens: 100,000 tokens = 0.1M
- æˆæœ¬: 0.1M Ã— Â¥0.6 = **Â¥0.06 (~$0.008)**

**æˆæœ¬å¯¹æ¯”æ€»ç»“:**
1. ç¡…åŸºæµåŠ¨ Llama-3-8B: ~$0.008 â­ **æœ€ä¾¿å®œ**
2. ç¡…åŸºæµåŠ¨ Qwen2-7B: ~$0.014
3. Claude-3-Haiku: $0.025
4. GPT-3.5-turbo: $0.05
5. GPT-4: $3.00

---

## æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹é‡å¤„ç†

```python
# ä¸æ¨èï¼šé€ä¸ªå¤„ç†
for sample in samples:
    logits = api.get_logits(sample, vocab_size)

# æ¨èï¼šæ‰¹é‡å¤„ç†ï¼ˆå¦‚æœAPIæ”¯æŒï¼‰
all_logits = []
for batch in batches:
    batch_logits = api.get_logits_batch(batch, vocab_size)
    all_logits.append(batch_logits)
```

### 2. ç¼“å­˜ç»“æœ

```python
import pickle
import os

# ç¼“å­˜æ•™å¸ˆè¾“å‡º
cache_dir = './teacher_cache'
os.makedirs(cache_dir, exist_ok=True)

def get_teacher_output_cached(input_text, api, cache_dir):
    """è·å–æ•™å¸ˆè¾“å‡ºï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    import hashlib
    cache_key = hashlib.md5(input_text.encode()).hexdigest()
    cache_file = f"{cache_dir}/{cache_key}.pkl"

    # æ£€æŸ¥ç¼“å­˜
    if os.path.exists(cache_file):
        with open(cache_file, 'rb') as f:
            return pickle.load(f)

    # APIè°ƒç”¨
    output = api.generate_text(input_text)

    # ä¿å­˜ç¼“å­˜
    with open(cache_file, 'wb') as f:
        pickle.dump(output, f)

    return output
```

### 3. å¼‚æ­¥è°ƒç”¨

```python
import asyncio
import aiohttp

async def async_generate(api, input_texts):
    """å¼‚æ­¥æ‰¹é‡ç”Ÿæˆ"""
    tasks = []
    for text in input_texts:
        task = asyncio.create_task(api.generate_text_async(text))
        tasks.append(task)

    results = await asyncio.gather(*tasks)
    return results
```

### 4. å‡å°‘APIè°ƒç”¨

```python
# é…ç½®ï¼šå‡å°‘æ˜¾ç¤ºé¢‘ç‡
distill_config = {
    'sample_frequency': 100,  # æ¯100ä¸ªbatchæ‰è°ƒç”¨ä¸€æ¬¡API
}

# æˆ–è€…ï¼šé¢„å…ˆç”Ÿæˆæ•™å¸ˆè¾“å‡º
teacher_outputs = []
for batch in train_dataloader:
    with torch.no_grad():
        teacher_output = teacher_model(batch['input_ids'])
        teacher_outputs.append(teacher_output)

# ç„¶ååœ¨è®­ç»ƒæ—¶ä½¿ç”¨ç¼“å­˜çš„è¾“å‡º
```

---

## é”™è¯¯å¤„ç†

### 1. APIé™æµ

```python
# é…ç½®é‡è¯•ç­–ç•¥
config = {
    'max_retries': 5,
    'retry_delay': 2.0,  # åˆå§‹å»¶è¿Ÿ2ç§’
    # è‡ªåŠ¨ä½¿ç”¨æŒ‡æ•°é€€é¿: 2s, 4s, 8s, 16s, 32s
}

api = OpenAITeacherAPI(config)
```

### 2. è¶…æ—¶å¤„ç†

```python
config = {
    'timeout': 60,  # 60ç§’è¶…æ—¶
}

try:
    text = api.generate_text(input_text)
except TimeoutError:
    print("APIè°ƒç”¨è¶…æ—¶")
    # ä½¿ç”¨fallback
```

### 3. APIé”™è¯¯

```python
try:
    teacher_model = create_api_teacher_model(...)
except ImportError as e:
    print(f"ç¼ºå°‘ä¾èµ–åº“: {e}")
    print("è¯·å®‰è£…: pip install openai anthropic")
except Exception as e:
    print(f"åˆ›å»ºå¤±è´¥: {e}")
```

---

## æœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„æ•™å¸ˆæ¨¡å‹

| åœºæ™¯ | æ¨èæ¨¡å‹ | åŸå›  |
|------|---------|------|
| é¢„ç®—å……è¶³ | GPT-4 | æœ€å¼ºå¤§ |
| å¹³è¡¡æ€§ä»·æ¯” | GPT-3.5-turbo / Claude-3-Sonnet | æ€§èƒ½å¥½ä¸”ä¾¿å®œ |
| å¤§è§„æ¨¡è®­ç»ƒ | ç¡…åŸºæµåŠ¨ Llama-3-8B | æœ€ä¾¿å®œ (~$0.008/1Kæ ·æœ¬) |
| ä¸­æ–‡åœºæ™¯ | ç¡…åŸºæµåŠ¨ Qwen2-7B / GLM-4 | ä¸­æ–‡ä¼˜åŒ–ä¸”ä¾¿å®œ |
| å›½å†…éƒ¨ç½² | ç¡…åŸºæµåŠ¨ | è®¿é—®é€Ÿåº¦å¿« |
| ç‰¹å®šé¢†åŸŸ | è‡ªå®šä¹‰API | ä¸“é—¨ä¼˜åŒ– |

### 2. æ··åˆç­–ç•¥

```python
# ä½¿ç”¨ä¾¿å®œçš„æ¨¡å‹åšåˆæ­¥è’¸é¦
cheap_teacher = create_api_teacher_model(
    provider='openai',
    model_name='gpt-3.5-turbo',
    ...
)

# ç¬¬ä¸€è½®è’¸é¦
distill_phase1(student_model, cheap_teacher, ...)

# ä½¿ç”¨å¼ºå¤§çš„æ¨¡å‹åšç²¾ç»†è’¸é¦
strong_teacher = create_api_teacher_model(
    provider='openai',
    model_name='gpt-4',
    ...
)

# ç¬¬äºŒè½®è’¸é¦
distill_phase2(student_model, strong_teacher, ...)
```

### 3. ç›‘æ§æˆæœ¬

```python
# å®æ—¶ç›‘æ§tokensæ¶ˆè€—
class CostMonitor:
    def __init__(self, price_per_million):
        self.price = price_per_million
        self.total_tokens = 0

    def update(self, tokens):
        self.total_tokens += tokens
        cost = (self.total_tokens / 1_000_000) * self.price
        print(f"[æˆæœ¬] å·²ä½¿ç”¨ {self.total_tokens} tokens, çº¦ ${cost:.2f}")

monitor = CostMonitor(price_per_million=0.5)  # GPT-3.5ä»·æ ¼

# åœ¨è’¸é¦å¾ªç¯ä¸­
for batch in dataloader:
    # ... è’¸é¦ ...
    monitor.update(teacher_model.api.stats['total_tokens'])
```

---

## å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆAPIè¿”å›çš„logitsæ˜¯æ¨¡æ‹Ÿçš„ï¼Ÿ

**A:** OpenAIå’ŒAnthropicçš„APIé»˜è®¤ä¸è¿”å›logitsï¼Œåªè¿”å›æ–‡æœ¬ã€‚æˆ‘ä»¬é€šè¿‡æ–‡æœ¬ç”Ÿæˆæ¨¡æ‹Ÿlogitsã€‚å¦‚æœéœ€è¦çœŸå®logitsï¼Œéœ€è¦ï¼š
1. ä½¿ç”¨æ”¯æŒlogprobsçš„APIï¼ˆå¦‚OpenAIçš„completion APIï¼‰
2. ä½¿ç”¨è‡ªå®šä¹‰APIå¹¶å®ç°logitsç«¯ç‚¹
3. åªä½¿ç”¨æ–‡æœ¬çº§åˆ«çš„è’¸é¦

### Q2: å¦‚ä½•å‡å°‘APIæˆæœ¬ï¼Ÿ

**A:**
1. ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹ï¼ˆClaude-3-Haikuæœ€ä¾¿å®œï¼‰
2. ç¼“å­˜æ•™å¸ˆè¾“å‡º
3. å‡å°‘sample_frequency
4. ä½¿ç”¨æ›´çŸ­çš„è¾“å…¥æ–‡æœ¬
5. é¢„å…ˆæ‰¹é‡ç”Ÿæˆæ•™å¸ˆè¾“å‡º

### Q3: APIè°ƒç”¨å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A:** æ’ä»¶ä¼šè‡ªåŠ¨é‡è¯•ï¼Œå¦‚æœå¤šæ¬¡å¤±è´¥ï¼š
1. æ£€æŸ¥API keyæ˜¯å¦æ­£ç¡®
2. æ£€æŸ¥ç½‘ç»œè¿æ¥
3. æ£€æŸ¥æ˜¯å¦è¶…è¿‡é…é¢
4. å¢åŠ timeoutå’Œmax_retries

### Q4: å¯ä»¥ç¦»çº¿ä½¿ç”¨å—ï¼Ÿ

**A:** å¯ä»¥ï¼é¢„å…ˆç”Ÿæˆæ•™å¸ˆè¾“å‡ºå¹¶ç¼“å­˜ï¼š

```python
# 1. é¢„å…ˆç”Ÿæˆï¼ˆåœ¨çº¿ï¼‰
cache_teacher_outputs(train_data, teacher_api, cache_dir)

# 2. ç¦»çº¿è®­ç»ƒï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
train_with_cached_outputs(student_model, cache_dir)
```

### Q5: å¦‚ä½•é€‰æ‹©APIæä¾›å•†ï¼Ÿ

**A:** é€‰æ‹©å»ºè®®ï¼š
- **ä¸­æ–‡ä»»åŠ¡**: ç¡…åŸºæµåŠ¨ï¼ˆQwen2/GLM-4ï¼‰ - ä¸­æ–‡ä¼˜åŒ–ï¼Œä»·æ ¼ä½
- **è‹±æ–‡ä»»åŠ¡**: GPT-3.5-turbo / Claude-3-Haiku - æ€§èƒ½å¥½
- **æœ€ä½³è´¨é‡**: GPT-4 / Claude-3-Opus - ä½†æˆæœ¬é«˜
- **æœ€ä½æˆæœ¬**: ç¡…åŸºæµåŠ¨ Llama-3-8B - $0.008/1Kæ ·æœ¬
- **å›½å†…ç½‘ç»œ**: ç¡…åŸºæµåŠ¨ - è®¿é—®é€Ÿåº¦å¿«ï¼Œæ— éœ€ä»£ç†

---

## æŠ€æœ¯æ”¯æŒ

- **ä»£ç **: `apt_model/plugins/teacher_api.py`
- **ç¤ºä¾‹**: æ–‡ä»¶æœ«å°¾çš„`if __name__ == "__main__"`éƒ¨åˆ†
- **é—®é¢˜åé¦ˆ**: GitHub Issues

---

**Happy Distilling with API! ğŸš€**
