# llama-cpp-python CUDA ç¼–è¯‘æŒ‡å— (Windows + RTX 3070 + Python 3.13 + CUDA 13.1)

## ğŸ“‹ ç›®å½•
- [æ¦‚è¿°](#æ¦‚è¿°)
- [ç³»ç»Ÿç¯å¢ƒ](#ç³»ç»Ÿç¯å¢ƒ)
- [é—®é¢˜åˆ†æ](#é—®é¢˜åˆ†æ)
- [ç¼–è¯‘æ­¥éª¤](#ç¼–è¯‘æ­¥éª¤)
- [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
- [å…³é”®å‘ç°](#å…³é”®å‘ç°)

---

## æ¦‚è¿°

æœ¬æ–‡æ¡£è®°å½•äº†åœ¨ Windows 10/11 ä¸Šä¸º **Python 3.13** ç¼–è¯‘æ”¯æŒ **CUDA 13.1** çš„ `llama-cpp-python` çš„å®Œæ•´è¿‡ç¨‹ï¼Œé€‚ç”¨äº **RTX 3070 (sm86/Ampere)** GPUã€‚

**æœ€ç»ˆæˆæœ**ï¼šæˆåŠŸç¼–è¯‘ `llama_cpp_python-0.3.16`ï¼ŒGPU æ¨ç†é€Ÿåº¦çº¦ **207 tokens/ç§’**ã€‚

---

## ç³»ç»Ÿç¯å¢ƒ

### ç¡¬ä»¶
- **GPU**: NVIDIA GeForce RTX 3070 Laptop GPU
- **Compute Capability**: 8.6 (sm86/Ampere)
- **GPU Memory**: 7114 MiB å¯ç”¨

### è½¯ä»¶
- **æ“ä½œç³»ç»Ÿ**: Windows 10/11 (64-bit)
- **Python**: 3.13.x
- **CUDA**: 13.1 (v13.1.115)
- **Visual Studio**: 2022 BuildTools (MSVC 14.44)
- **Visual Studio**: 18 2026 Community (å·²å®‰è£…ä½†ä¸ç”¨)

### å…³é”®ä¾èµ–
```
CMake >= 4.2.1
NVIDIA CUDA Toolkit 13.1
Visual Studio 2022 BuildTools with C++ tools
```

---

## é—®é¢˜åˆ†æ

### 1. ä¸ºä»€ä¹ˆéœ€è¦è‡ªå·±ç¼–è¯‘ï¼Ÿ

**é¢„ç¼–è¯‘ wheel çš„é—®é¢˜**ï¼š
- [dougeeai/llama-cpp-python-wheels](https://github.com/dougeeai/llama-cpp-python-wheels) åªæœ‰ Python 3.12 çš„ sm86 ç‰ˆæœ¬
- Python 3.13 æ— æ³•ä½¿ç”¨ Python 3.12 çš„ wheel
- å®˜æ–¹ä¸æä¾› CUDA ç‰ˆæœ¬çš„é¢„ç¼–è¯‘åŒ…

### 2. ç¼–è¯‘è¿‡ç¨‹ä¸­çš„ä¸»è¦å‘ç‚¹

#### å‘ç‚¹ #1: å¤š CUDA ç‰ˆæœ¬å†²çª
```
ç³»ç»Ÿå­˜åœ¨:
- C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.3\
- C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.1\

é—®é¢˜: CMake é»˜è®¤é€‰æ‹© v12.3ï¼Œä½† v12.3 æ²¡æœ‰ VS 2022 Integration
```

**è§£å†³æ–¹æ¡ˆ**: ç¼–è¯‘æ—¶ä½¿ç”¨ `CMAKE_GENERATOR=Visual Studio 17 2022` å¼ºåˆ¶ä½¿ç”¨ VS 2022

#### å‘ç‚¹ #2: å¤š Visual Studio ç‰ˆæœ¬
```
ç³»ç»Ÿå­˜åœ¨:
- Visual Studio 18 2026 Community
- Visual Studio 2022 BuildTools

é—®é¢˜: CMake é»˜è®¤é€‰æ‹© VS 18 2026ï¼Œä½† CUDA Integration åªä¸º VS 2022 å®‰è£…
```

**è§£å†³æ–¹æ¡ˆ**: è®¾ç½® `CMAKE_GENERATOR=Visual Studio 17 2022`

#### å‘ç‚¹ #3: éšè—çš„ç¯å¢ƒå˜é‡ (æœ€å…³é”®çš„å‘ç°ï¼)
```xml
<!-- CUDA 13.1.Version.props æ–‡ä»¶å†…å®¹ -->
<PropertyGroup>
    <CudaToolkitVersionedPath>$(CUDA_PATH_V13_1)</CudaToolkitVersionedPath>
</PropertyGroup>
```

**é—®é¢˜**:
- ç¼–è¯‘æ—¶éœ€è¦ `CUDA_PATH_V13_1` ç¯å¢ƒå˜é‡ï¼ˆéæ ‡å‡†ï¼ï¼‰
- è¿è¡Œæ—¶éœ€è¦ `CUDA_PATH` ç¯å¢ƒå˜é‡ï¼ˆæ ‡å‡†ï¼ï¼‰
- **ä¸¤è€…æ˜¯ä¸åŒçš„å˜é‡åï¼**

#### å‘ç‚¹ #4: CUDA DLL è·¯å¾„
```
CUDA 13.1 çš„ DLL åœ¨: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.1\bin\x64\
ä½† llama-cpp-python åªæœç´¢: %CUDA_PATH%\bin
```

**è§£å†³æ–¹æ¡ˆ**: è¿è¡Œæ—¶éœ€è¦åŒæ—¶æ·»åŠ  `bin` å’Œ `bin\x64` åˆ° DLL æœç´¢è·¯å¾„

---

## ç¼–è¯‘æ­¥éª¤

### æ­¥éª¤ 1: å‡†å¤‡ç¯å¢ƒ

ç¡®ä¿å·²å®‰è£…ï¼š
- [ ] CUDA Toolkit 13.1
- [ ] Visual Studio 2022 BuildTools (å« "Desktop development with C++")
- [ ] Python 3.13
- [ ] Git (ç”¨äºå…‹éš†æºç )

### æ­¥éª¤ 2: åˆ›å»ºç¼–è¯‘è„šæœ¬

åˆ›å»º `build_llama_cpp_python.bat`:

```batch
@echo off
chcp 65001 >nul
echo ============================================================
echo Building llama-cpp-python with CUDA 13.1 + Python 3.13
echo ============================================================
echo.

REM === å…³é”®ç¯å¢ƒå˜é‡ ===
REM ç¼–è¯‘æ—¶ç”¨çš„å˜é‡ (VS Integration éœ€è¦)
set CUDA_PATH_V13_1=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.1

REM è¿è¡Œæ—¶ç”¨çš„å˜é‡ (llama-cpp-python éœ€è¦)
set CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.1
set CUDA_HOME=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.1

REM CMake é…ç½®
set CMAKE_ARGS=-DGGML_CUDA=on -DCMAKE_CUDA_ARCHITECTURES=86
set FORCE_CMAKE=1
set GGML_CUDA=1

REM å¼ºåˆ¶ä½¿ç”¨ VS 2022 (é‡è¦ï¼)
set CMAKE_GENERATOR=Visual Studio 17 2022

REM æ·»åŠ åˆ° PATH
set PATH=%CUDA_PATH%\bin;%PATH%

echo Environment:
echo   CUDA_HOME=%CUDA_HOME%
echo   CMAKE_ARGS=%CMAKE_ARGS%
echo   CMAKE_GENERATOR=%CMAKE_GENERATOR%
echo.

REM === æ£€æŸ¥ CUDA ===
"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.1\bin\nvcc.exe" --version
echo.

REM === å¸è½½æ—§ç‰ˆæœ¬ ===
pip uninstall llama-cpp-python -y 2>nul
echo.

REM === å¼€å§‹ç¼–è¯‘ ===
echo Compiling... (this takes 5-10 minutes)
echo.
pip install llama-cpp-python --no-cache-dir --force-reinstall -vvv

echo.
echo ============================================================
echo Build complete!
echo ============================================================
pause
```

### æ­¥éª¤ 3: è¿è¡Œç¼–è¯‘

ä»¥**æ™®é€šç”¨æˆ·æƒé™**è¿è¡Œï¼š
```cmd
build_llama_cpp_python.bat
```

ç­‰å¾… 5-10 åˆ†é’Ÿï¼Œç¼–è¯‘æˆåŠŸåä¼šçœ‹åˆ°ï¼š
```
Successfully built llama-cpp-python
Successfully installed llama-cpp-python-0.3.16
```

**å…³é”®æ—¥å¿—**ï¼ˆç¡®è®¤ CUDA è¢«æ­£ç¡®ä½¿ç”¨ï¼‰ï¼š
```
-- Found CUDAToolkit: C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v13.1/include (found version "13.1.115")
-- CUDA Toolkit found
-- Using CUDA architectures: 86
```

---

## ä½¿ç”¨æ–¹æ³•

### Python ä»£ç ä¸­ä½¿ç”¨

```python
import os
import sys

# === å¿…é¡»åœ¨ä½¿ç”¨ llama_cpp ä¹‹å‰è®¾ç½® ===
if sys.platform == 'win32':
    cuda_path = r'C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.1'

    # å…³é”®ï¼šè®¾ç½® CUDA_PATH (è¿è¡Œæ—¶éœ€è¦)
    os.environ['CUDA_PATH'] = cuda_path

    # æ·»åŠ  DLL æœç´¢è·¯å¾„
    os.add_dll_directory(cuda_path + r'\bin')
    os.add_dll_directory(cuda_path + r'\bin\x64')  # CUDA 13.1 çš„ DLL åœ¨è¿™é‡Œï¼

# ç°åœ¨å¯ä»¥å®‰å…¨å¯¼å…¥
from llama_cpp import Llama

# åŠ è½½æ¨¡å‹ï¼ˆæ‰€æœ‰å±‚éƒ½æ”¾åˆ° GPUï¼‰
llm = Llama(
    model_path="path/to/your/model.gguf",
    n_gpu_layers=-1,  # -1 è¡¨ç¤ºæ‰€æœ‰å±‚éƒ½ä½¿ç”¨ GPU
    n_ctx=4096,
    verbose=True  # è®¾ä¸º True å¯ä»¥çœ‹åˆ° GPU ä½¿ç”¨æƒ…å†µ
)

# æ¨ç†
output = llm("Q: What is AI?\nA:", max_tokens=50)
print(output['choices'][0]['text'])
```

### éªŒè¯ GPU æ˜¯å¦å·¥ä½œ

è¿è¡Œä¸Šè¿°ä»£ç åï¼ŒæŸ¥çœ‹æ—¥å¿—ä¸­çš„å…³é”®è¾“å‡ºï¼š

```
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 3070 Laptop GPU, compute capability 8.6, VMM: yes
llama_model_load_from_file_impl: using device CUDA0 (NVIDIA GeForce RTX 3070 Laptop GPU) - 7114 MiB free
```

å¦‚æœçœ‹åˆ° `using device CUDA0`ï¼Œè¯´æ˜ GPU åŠ é€ŸæˆåŠŸï¼

### æ€§èƒ½æµ‹è¯•ç»“æœ

```
æ¨¡å‹: Llama-3.2-1B-Instruct-Q4_0.gguf
GPU: NVIDIA GeForce RTX 3070 Laptop GPU

æ€§èƒ½æŒ‡æ ‡:
  prompt eval time: 13.66 ms per token (73.22 tokens/s)
  eval time: 4.83 ms per token (207.19 tokens/s)
  total time: 302.36 ms / 42 tokens
```

---

## æ•…éšœæ’é™¤

### é—®é¢˜ 1: ç¼–è¯‘æ—¶å‡ºç° "No CUDA toolset found"

**ç—‡çŠ¶**:
```
error : The CUDA Toolkit directory '' does not exist.
```

**åŸå› **:
- `CUDA_PATH_V13_1` ç¯å¢ƒå˜é‡æœªè®¾ç½®
- æˆ– CMake é€‰æ‹©äº†é”™è¯¯çš„ CUDA ç‰ˆæœ¬

**è§£å†³æ–¹æ¡ˆ**:
1. ç¡®è®¤è®¾ç½®äº† `CUDA_PATH_V13_1`
2. å¼ºåˆ¶ä½¿ç”¨ VS 2022: `set CMAKE_GENERATOR=Visual Studio 17 2022`

### é—®é¢˜ 2: è¿è¡Œæ—¶å‡ºç° "Could not find module 'llama.dll'"

**ç—‡çŠ¶**:
```
RuntimeError: Failed to load shared library 'llama.dll': Could not find module
```

**åŸå› **: CUDA DLL ä¸åœ¨ DLL æœç´¢è·¯å¾„ä¸­

**è§£å†³æ–¹æ¡ˆ**:
```python
import os
cuda_path = r'C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.1'
os.environ['CUDA_PATH'] = cuda_path
os.add_dll_directory(cuda_path + r'\bin')
os.add_dll_directory(cuda_path + r'\bin\x64')  # é‡è¦ï¼CUDA 13.1 ç‰¹æœ‰
```

### é—®é¢˜ 3: GPU å†…å­˜ä¸è¶³

**ç—‡çŠ¶**:
```
CUDA error: out of memory
```

**è§£å†³æ–¹æ¡ˆ**:
```python
# å‡å°‘ n_ctx (ä¸Šä¸‹æ–‡é•¿åº¦)
llm = Llama(model_path="...", n_ctx=2048)  # é»˜è®¤ 4096

# æˆ–å‡å°‘ GPU å±‚æ•°
llm = Llama(model_path="...", n_gpu_layers=20)  # è€Œä¸æ˜¯ -1
```

### é—®é¢˜ 4: CMake æ‰¾åˆ°äº†é”™è¯¯çš„ CUDA ç‰ˆæœ¬

**ç—‡çŠ¶**:
```
-- Found CUDAToolkit: .../CUDA/v12.3/include (found version "12.3.107")
```

**åŸå› **: å¤š CUDA ç‰ˆæœ¬å†²çª

**è§£å†³æ–¹æ¡ˆ**:
```batch
REM æ–¹æ¡ˆ 1: ä¸´æ—¶é‡å‘½å v12.3 ç›®å½•ï¼ˆéœ€ç®¡ç†å‘˜æƒé™ï¼‰
ren "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.3" v12.3.hidden

REM æ–¹æ¡ˆ 2: å¼ºåˆ¶ CMake ä½¿ç”¨ VS 2022 (æ›´å®‰å…¨)
set CMAKE_GENERATOR=Visual Studio 17 2022
```

---

## å…³é”®å‘ç°

### å‘ç° 1: éæ ‡å‡†çš„ç¯å¢ƒå˜é‡

**CUDA 13.1 çš„ VS Integration ä½¿ç”¨éæ ‡å‡†ç¯å¢ƒå˜é‡**:
```xml
<!-- æ–‡ä»¶: CUDA 13.1.Version.props -->
<CudaToolkitVersionedPath>$(CUDA_PATH_V13_1)</CudaToolkitVersionedPath>
```

è¿™ä¸æ ‡å‡†å˜é‡ `CUDA_PATH` ä¸åŒï¼Œå¯¼è‡´å¤§é‡ç”¨æˆ·ç¼–è¯‘å¤±è´¥ã€‚

### å‘ç° 2: ç‰ˆæœ¬åŒ¹é…é™·é˜±

| ç»„ä»¶ | ç‰ˆæœ¬ | è¦æ±‚ |
|------|------|------|
| CUDA | 13.1 | éœ€è¦ VS 2022 Integration |
| VS | 2022 BuildTools | å¿…é¡»å¼ºåˆ¶ä½¿ç”¨ |
| Python | 3.13 | æ— é¢„ç¼–è¯‘ wheelï¼Œå¿…é¡»è‡ªç¼–è¯‘ |
| GPU | RTX 3070 | sm86 (Ampere) æ¶æ„ |

**VS 18 2026 ä¸èƒ½ç”¨**ï¼Œå³ä½¿å®ƒæ›´æ–°ï¼Œå› ä¸º CUDA 13.1 æ²¡æœ‰ä¸ºå®ƒæä¾› Integrationã€‚

### å‘ç° 3: DLL æœç´¢è·¯å¾„çš„ç»†å¾®å·®åˆ«

```
CUDA 12.x: DLL åœ¨ bin\
CUDA 13.1: DLL åœ¨ bin\x64\
```

è¿è¡Œæ—¶å¿…é¡»ä¸¤ä¸ªè·¯å¾„éƒ½æ·»åŠ ï¼š
```python
os.add_dll_directory(cuda_path + r'\bin')
os.add_dll_directory(cuda_path + r'\bin\x64')
```

### å‘ç° 4: ç¼–è¯‘æ—¶ vs è¿è¡Œæ—¶çš„ç¯å¢ƒå˜é‡

| æ—¶é—´ç‚¹ | éœ€è¦çš„å˜é‡ | ç”¨é€” |
|--------|-----------|------|
| ç¼–è¯‘æ—¶ | `CUDA_PATH_V13_1` | VS Integration æŸ¥æ‰¾ CUDA |
| è¿è¡Œæ—¶ | `CUDA_PATH` | llama-cpp-python æŸ¥æ‰¾ CUDA DLL |

**å¿…é¡»ä½¿ç”¨ä¸åŒçš„å˜é‡åï¼**

---

## æ–‡ä»¶æ¸…å•

ç¼–è¯‘è„šæœ¬ï¼š
- `build_llama_cpp_python.bat` - ä¸»ç¼–è¯‘è„šæœ¬
- `test_gpu_final_v3.py` - GPU æµ‹è¯•è„šæœ¬

è¿è¡Œæ—¶é…ç½®ï¼š
- `ai_chatroom.py` - å·²é›†æˆ CUDA ç¯å¢ƒè®¾ç½®

å…³é”®ä½ç½®ï¼š
```
CUDA å®‰è£…: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.1\
VS Integration: C:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\MSBuild\Microsoft\VC\v170\BuildCustomizations\
Python åŒ…: %LOCALAPPDATA%\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\llama_cpp\
```

---

## å‚è€ƒèµ„æ–™

- [llama-cpp-python GitHub](https://github.com/abetlen/llama-cpp-python)
- [llama.cpp GitHub](https://github.com/ggerganov/llama.cpp)
- [Medium: llama-cpp-python with CUDA support on Windows 11](https://medium.com/@eddieoffermann/llama-cpp-python-with-cuda-support-on-windows-11-51a4dd295b25)
- [Stack Overflow: llama-cpp-python not using NVIDIA GPU CUDA](https://stackoverflow.com/questions/76963311/llama-cpp-python-not-using-nvidia-gpu-cuda)
- [dougeeai/llama-cpp-python-wheels](https://github.com/dougeeai/llama-cpp-python-wheels) (é¢„ç¼–è¯‘ wheel)

---

## æ›´æ–°æ—¥å¿—

**2026-02-11**
- âœ… æˆåŠŸç¼–è¯‘ llama-cpp-python 0.3.16 with CUDA 13.1
- âœ… ç¡®è®¤ RTX 3070 GPU å·¥ä½œæ­£å¸¸
- âœ… æ€§èƒ½æµ‹è¯•: 207 tokens/ç§’
- âœ… åˆ›å»ºæœ¬æ–‡æ¡£

---

## è´¡çŒ®è€…

- ç¼–è¯‘å’Œæµ‹è¯•: [Your Name]
- Agent è¾…åŠ©: Claude (Anthropic)

**å…³é”®è¯**: `llama-cpp-python`, `CUDA 13.1`, `Windows`, `RTX 3070`, `Python 3.13`, `sm86`, `Ampere`
