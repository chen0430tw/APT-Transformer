{
  "vocab_size": 749,
  "d_model": 768,
  "d_ff": 2048,
  "num_heads": 12,
  "num_encoder_layers": 4,
  "num_decoder_layers": 4,
  "dropout": 0.2,
  "max_seq_len": 128,
  "epsilon": 2.0,
  "alpha": 0.001,
  "beta": 0.001,
  "base_lr": 3e-05,
  "pad_token_id": 0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "activation": "gelu",
  "use_autopoietic": true,
  "sr_ratio": 8,
  "init_tau": 1.5,
  "batch_first": true,
  "warmup_steps": 1000,
  "weight_decay": 0.01,
  "attention_dropout": 0.1,
  "layer_norm_eps": 1e-05,
  "gradient_clip": 1.0
}