# virtual_vram.py
# -*- coding: utf-8 -*-
"""
Virtual VRAM v0.2 (Storage-Aware Activation Offload)

æ ¸å¿ƒé—®é¢˜ï¼ˆv0.1 çš„è‡´å‘½ç¼ºé™·ï¼‰ï¼š
  Autograd å¯¹åŒä¸€ storage çš„å¤šä¸ª viewï¼ˆreshape/transpose/slice äº§ç”Ÿï¼‰
  åˆ†åˆ«è°ƒç”¨ pack_hookï¼Œv0.1 å¯¹æ¯ä¸ª view ç‹¬ç«‹åš contiguous().to("cpu")ï¼Œ
  ç ´åäº† view ä¹‹é—´çš„åˆ«åå…³ç³»ï¼ˆaliasingï¼‰ã€‚Backward æ—¶ autograd æœŸæœ›
  è¿™äº› view å…±äº«åŒä¸€å— CUDA å†…å­˜ï¼Œä½† v0.1 æ¢å¤å‡ºçš„æ˜¯äº’ç›¸ç‹¬ç«‹çš„å‰¯æœ¬
  â†’ CUDA illegal memory accessã€‚

v0.2 ä¿®å¤æ–¹æ¡ˆï¼šStorage çº§åˆ«çš„ç”Ÿå‘½å‘¨æœŸæ³¨å†Œè¡¨
  Pack é˜¶æ®µï¼š
    - ç”¨ id(tensor.untyped_storage()) ä½œä¸ºå”¯ä¸€ keyï¼ˆPython å¯¹è±¡ idï¼Œ
      ä¸æ˜¯ CUDA ç‰©ç†åœ°å€ï¼Œä¸ä¼šå› å†…å­˜å¤ç”¨è€Œå†²çªï¼‰
    - é¦–æ¬¡è§åˆ°æŸ storageï¼šæŠŠæ•´å— storage æ¬åˆ° CPUï¼Œå­˜å…¥æ³¨å†Œè¡¨
    - å†æ¬¡è§åˆ°åŒä¸€ storageï¼šç›´æ¥å¼•ç”¨å·²æœ‰çš„ CPU storageï¼Œåªè®°å½•
      è¯¥ view çš„ shape/stride/storage_offsetï¼ˆ"çµé­‚å¯†ç "ï¼‰

  Unpack é˜¶æ®µï¼š
    - é¦–æ¬¡æœ‰äººè¦è¿™å— storageï¼šæŠŠ CPU storage æ•´ä½“æ¬å› CUDAï¼Œ
      æ³¨å†Œæ–°çš„ CUDA storage å¯¹è±¡
    - åç»­ viewï¼šå¤ç”¨å·²æ¢å¤çš„ CUDA storage
    - æ‰€æœ‰ view ç»Ÿä¸€ç”¨ as_strided ä»å…±äº« CUDA storage é‡å»ºï¼Œ
      å®Œæ•´è¿˜åŸåˆ«åå…³ç³»

Usage:
    from apt.vgpu.runtime.virtual_vram import VirtualVRAMConfig, virtual_vram

    cfg = VirtualVRAMConfig(enabled=True, min_storage_bytes=1<<20)
    with virtual_vram(cfg):
        loss = model(x).sum()
        loss.backward()
"""

from __future__ import annotations

import math
import threading
from dataclasses import dataclass, field
from contextlib import contextmanager
from typing import Dict, Optional, Tuple

import torch

# è‡ªç„¶å¹³è¡¡å¸¸æ•°ï¼š4/e â‰ˆ 1.4715ï¼Œç”¨äº LECaC é‡åŒ–è¡¥å¿
NATURAL_EQUILIBRIUM_CONSTANT: float = 4.0 / math.e


@dataclass
class VirtualVRAMConfig:
    enabled: bool = True
    # æŒ‰ storage å¤§å°è¿‡æ»¤ï¼ˆæ•´å— storageï¼Œä¸æ˜¯å•ä¸ª tensor çš„ numel*itemsizeï¼‰
    min_storage_bytes: int = 1 << 20   # 1MB
    verbose: bool = False
    # å…¼å®¹æ—§å­—æ®µå
    min_tensor_bytes: int = 0  # å·²åºŸå¼ƒï¼Œä¿ç•™å‘åå…¼å®¹


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Storage æ³¨å†Œè¡¨ï¼ˆæ¯æ¬¡ virtual_vram context ç‹¬ç«‹ä¸€ä»½ï¼Œçº¿ç¨‹å±€éƒ¨ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class _StorageRecord:
    """ä¸€å— CUDA storage åœ¨ CPU ä¸Šçš„å®Œæ•´å‰¯æœ¬ + æ¢å¤çŠ¶æ€"""
    __slots__ = ('cpu_storage', 'nbytes', 'dtype', 'device',
                 'cuda_storage', 'lock')

    def __init__(self, cpu_storage: torch.Storage,
                 nbytes: int, dtype: torch.dtype, device: torch.device):
        self.cpu_storage = cpu_storage   # CPU ä¸Šçš„ storageï¼ˆå­—èŠ‚çº§ï¼‰
        self.nbytes = nbytes
        self.dtype = dtype
        self.device = device
        self.cuda_storage: Optional[torch.Storage] = None  # æ¢å¤åå¡«å……
        self.lock = threading.Lock()     # é˜²æ­¢å¤šçº¿ç¨‹é‡å¤æ¢å¤


class _ViewPacked:
    """
    pack_hook è¿”å›å€¼ï¼šæè¿°ä¸€ä¸ª view å¦‚ä½•ä»å…±äº« storage é‡å»ºã€‚
    """
    __slots__ = ('storage_key', 'shape', 'stride', 'storage_offset',
                 'dtype', 'device', 'requires_grad')

    def __init__(self, storage_key: int,
                 shape: Tuple, stride: Tuple, storage_offset: int,
                 dtype: torch.dtype, device: torch.device,
                 requires_grad: bool):
        self.storage_key = storage_key
        self.shape = shape
        self.stride = stride
        self.storage_offset = storage_offset
        self.dtype = dtype
        self.device = device
        self.requires_grad = requires_grad


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Context manager
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@contextmanager
def virtual_vram(cfg: VirtualVRAMConfig):
    """
    Storage-aware activation offload context manager.
    """
    if not cfg.enabled:
        yield
        return

    # å…¼å®¹æ—§å­—æ®µå
    min_bytes = cfg.min_storage_bytes or cfg.min_tensor_bytes or (1 << 20)

    # æœ¬æ¬¡ context çš„ storage æ³¨å†Œè¡¨ï¼ˆstorage_id â†’ _StorageRecordï¼‰
    registry: Dict[int, _StorageRecord] = {}

    def pack_hook(t: torch.Tensor):
        # â”€â”€ å¿«é€Ÿç­›é€‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if not torch.is_tensor(t) or not t.is_cuda:
            return t

        try:
            raw_storage = t.untyped_storage()
        except Exception:
            return t

        storage_nbytes = raw_storage.nbytes()
        if storage_nbytes < min_bytes:
            return t

        storage_key = id(raw_storage)

        # â”€â”€ é¦–æ¬¡è§åˆ°æ­¤ storageï¼šæ¬åˆ° CPU â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if storage_key not in registry:
            try:
                with torch.no_grad():
                    # æŠŠæ•´å— CUDA storage ä»¥å­—èŠ‚å½¢å¼æ‹·åˆ° CPU
                    cpu_raw = raw_storage.cpu()   # è¿”å› CPU UntypedStorage
            except Exception as e:
                if cfg.verbose:
                    print(f"[VirtualVRAM] âŒ storage è½¬ç§»å¤±è´¥: {e}")
                return t

            registry[storage_key] = _StorageRecord(
                cpu_storage=cpu_raw,
                nbytes=storage_nbytes,
                dtype=t.dtype,
                device=t.device,
            )
            if cfg.verbose:
                mb = storage_nbytes / 1024 / 1024
                print(f"[VirtualVRAM] âœ… offload storage {storage_key} "
                      f"{mb:.2f}MB â†’ cpu, view shape={tuple(t.shape)}")
        else:
            if cfg.verbose:
                print(f"[VirtualVRAM] ğŸ”— alias storage {storage_key}, "
                      f"view shape={tuple(t.shape)}")

        # â”€â”€ è®°å½•è¯¥ view çš„"çµé­‚å¯†ç " â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        return _ViewPacked(
            storage_key=storage_key,
            shape=tuple(t.shape),
            stride=tuple(t.stride()),
            storage_offset=t.storage_offset(),
            dtype=t.dtype,
            device=t.device,
            requires_grad=bool(t.requires_grad),
        )

    def unpack_hook(packed):
        # éæˆ‘ä»¬çš„åŒ…è£…å¯¹è±¡ç›´æ¥è¿”å›
        if not isinstance(packed, _ViewPacked):
            return packed

        key = packed.storage_key
        if key not in registry:
            # æ‰¾ä¸åˆ° storageï¼Œè¯´æ˜è¯¥ tensor å°äºé˜ˆå€¼è¢«è·³è¿‡äº†ï¼ˆä¸åº”å‘ç”Ÿï¼‰
            raise RuntimeError(
                f"[VirtualVRAM] unpack: storage {key} ä¸åœ¨æ³¨å†Œè¡¨ä¸­")

        record = registry[key]

        # â”€â”€ ç¡®ä¿ CUDA storage å·²æ¢å¤ï¼ˆåªæ¢å¤ä¸€æ¬¡ï¼Œåç»­ view å…±äº«ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€
        with record.lock:
            if record.cuda_storage is None:
                try:
                    with torch.no_grad():
                        # CPU storage â†’ CUDA storageï¼ˆæ•´å—æ¢å¤ï¼‰
                        record.cuda_storage = record.cpu_storage.cuda(
                            packed.device.index
                        )
                except Exception as e:
                    raise RuntimeError(
                        f"Failed to restore storage from CPU: {e}")
                if cfg.verbose:
                    mb = record.nbytes / 1024 / 1024
                    print(f"[VirtualVRAM] â†©ï¸  restore storage {key} "
                          f"{mb:.2f}MB â†’ cuda")

        # â”€â”€ ç”¨ as_strided ä»å…±äº« CUDA storage é‡å»ºæ­¤ view â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # as_strided ä¸æ‹·è´æ•°æ®ï¼Œåªæ”¹å˜è§£é‡Šæ–¹å¼ï¼Œå®Œæ•´è¿˜åŸåˆ«åå…³ç³»
        with torch.no_grad():
            # å…ˆé€ ä¸€ä¸ªå’Œ storage åŒ dtype çš„ 1D å ä½ tensor
            # storage å­—èŠ‚æ•° / dtype å­—èŠ‚æ•° = å…ƒç´ æ•°
            elem_size = torch.tensor([], dtype=packed.dtype).element_size()
            n_elems = record.nbytes // elem_size
            base = torch.empty(n_elems, dtype=packed.dtype,
                               device=packed.device)
            # æŠŠ base çš„ storage æ›¿æ¢ä¸ºæˆ‘ä»¬æ¢å¤çš„ cuda_storage
            base.set_(record.cuda_storage, 0,
                      (n_elems,), (1,))
            # ç”¨åŸå§‹ shape/stride/offset é‡å»º view
            restored = torch.as_strided(
                base,
                size=packed.shape,
                stride=packed.stride,
                storage_offset=packed.storage_offset,
            )

        restored = restored.requires_grad_(packed.requires_grad)

        if cfg.verbose:
            print(f"[VirtualVRAM] ğŸ”§ as_strided view {tuple(packed.shape)} "
                  f"stride={packed.stride} offset={packed.storage_offset}")

        return restored

    with torch.autograd.graph.saved_tensors_hooks(pack_hook, unpack_hook):
        yield

    # context é€€å‡ºåæ¸…ç†æ³¨å†Œè¡¨ï¼ˆé‡Šæ”¾ CPU å†…å­˜ï¼‰
    registry.clear()
