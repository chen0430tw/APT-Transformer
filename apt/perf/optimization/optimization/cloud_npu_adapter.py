"""
äº‘ç«¯NPUé€‚é…å™¨ - é€šè¿‡APIè°ƒç”¨è¿œç¨‹NPUè¿›è¡Œæ¨ç†

æ”¯æŒçš„äº‘æœåŠ¡å•†ï¼š
- ğŸŸ¡ Huawei Cloud ModelArts (Ascend NPU)
- ğŸŸ¢ æœªæ¥æ‰©å±•ï¼šSaladCloud, RunPod (å½“æ”¯æŒNPUæ—¶)

æ— éœ€æœ¬åœ°NPUç¡¬ä»¶ï¼Œé€šè¿‡REST APIè°ƒç”¨äº‘ç«¯NPUè¿›è¡Œæ¨ç†ã€‚

ä½œè€…: claude + chen0430tw
ç‰ˆæœ¬: 1.0 (Cloud NPU Adapter)
"""

import torch
import torch.nn as nn
import requests
import os
from typing import Optional, Dict, List, Any, Union
import json
import warnings


class CloudNPUBackend:
    """äº‘ç«¯NPUåç«¯åŸºç±»"""

    def __init__(self, api_key: str, endpoint_url: str, **kwargs):
        """
        åˆå§‹åŒ–äº‘ç«¯NPUåç«¯

        Args:
            api_key: APIå¯†é’¥
            endpoint_url: æ¨ç†ç«¯ç‚¹URL
            **kwargs: å…¶ä»–é…ç½®å‚æ•°
        """
        self.api_key = api_key
        self.endpoint_url = endpoint_url
        self.config = kwargs
        self.session = requests.Session()
        self.session.headers.update({
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        })

    def inference(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ¨ç†è¯·æ±‚

        Args:
            inputs: è¾“å…¥æ•°æ®

        Returns:
            æ¨ç†ç»“æœ
        """
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°inferenceæ–¹æ³•")

    def is_available(self) -> bool:
        """æ£€æŸ¥äº‘ç«¯NPUæ˜¯å¦å¯ç”¨"""
        try:
            response = self.session.get(f"{self.endpoint_url}/health", timeout=5)
            return response.status_code == 200
        except Exception:
            return False

    def close(self):
        """å…³é—­è¿æ¥"""
        self.session.close()


class HuaweiModelArtsNPU(CloudNPUBackend):
    """åä¸ºäº‘ModelArts Ascend NPUåç«¯"""

    def __init__(self,
                 api_key: str,
                 endpoint_url: str,
                 model_name: str = "deepseek-r1",
                 region: str = "cn-north-4",
                 **kwargs):
        """
        åˆå§‹åŒ–åä¸ºäº‘ModelArts NPU

        Args:
            api_key: åä¸ºäº‘APIå¯†é’¥
            endpoint_url: ModelArtsæ¨ç†ç«¯ç‚¹URL
            model_name: éƒ¨ç½²çš„æ¨¡å‹åç§°
            region: åä¸ºäº‘åŒºåŸŸ
        """
        super().__init__(api_key, endpoint_url, **kwargs)
        self.model_name = model_name
        self.region = region

        # åä¸ºäº‘ç‰¹å®šheaders
        self.session.headers.update({
            'X-HuaweiCloud-Region': region
        })

    def inference(self, inputs: Union[torch.Tensor, Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ¨ç† - æ”¯æŒOpenAIå…¼å®¹API

        Args:
            inputs: è¾“å…¥æ•°æ®ï¼ˆå¯ä»¥æ˜¯torch.Tensoræˆ–å­—å…¸ï¼‰

        Returns:
            æ¨ç†ç»“æœ
        """
        # å¦‚æœè¾“å…¥æ˜¯torch.Tensorï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
        if isinstance(inputs, torch.Tensor):
            inputs = inputs.cpu().numpy().tolist()

        # æ„é€ è¯·æ±‚ä½“
        payload = {
            "model": self.model_name,
            "inputs": inputs
        }

        # å¦‚æœæ˜¯OpenAIæ ¼å¼ï¼ˆç”¨äºLLMï¼‰
        if isinstance(inputs, dict) and 'messages' in inputs:
            payload = inputs

        try:
            response = self.session.post(
                f"{self.endpoint_url}/v1/inferences",
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            raise RuntimeError(f"åä¸ºäº‘NPUæ¨ç†å¤±è´¥: {e}")

    def chat_completion(self,
                       messages: List[Dict[str, str]],
                       temperature: float = 0.7,
                       max_tokens: int = 1024) -> str:
        """
        Chat Completion APIï¼ˆOpenAIå…¼å®¹ï¼‰

        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°

        Returns:
            ç”Ÿæˆçš„å›å¤
        """
        payload = {
            "model": self.model_name,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens
        }

        result = self.inference(payload)

        if 'choices' in result and len(result['choices']) > 0:
            return result['choices'][0]['message']['content']
        else:
            raise RuntimeError("æ— æ•ˆçš„APIå“åº”æ ¼å¼")


class CloudNPULinear(nn.Module):
    """äº‘ç«¯NPUåŠ é€Ÿçš„Linearå±‚"""

    def __init__(self,
                 in_features: int,
                 out_features: int,
                 cloud_backend: CloudNPUBackend,
                 fallback_local: bool = True,
                 bias: bool = True):
        """
        Args:
            in_features: è¾“å…¥ç‰¹å¾æ•°
            out_features: è¾“å‡ºç‰¹å¾æ•°
            cloud_backend: äº‘ç«¯NPUåç«¯
            fallback_local: å¦‚æœäº‘ç«¯ä¸å¯ç”¨ï¼Œæ˜¯å¦å›é€€åˆ°æœ¬åœ°CPU
            bias: æ˜¯å¦ä½¿ç”¨bias
        """
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.cloud_backend = cloud_backend
        self.fallback_local = fallback_local

        # æœ¬åœ°æƒé‡ï¼ˆç”¨äºfallbackæˆ–åˆå§‹åŒ–ï¼‰
        self.weight = nn.Parameter(torch.randn(out_features, in_features))
        if bias:
            self.bias = nn.Parameter(torch.randn(out_features))
        else:
            self.register_parameter('bias', None)

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'cloud_calls': 0,
            'local_calls': 0,
            'cloud_errors': 0
        }

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """å‰å‘ä¼ æ’­ - å°è¯•ä½¿ç”¨äº‘ç«¯NPU"""
        batch_size = x.shape[0]

        # å°è¯•äº‘ç«¯æ¨ç†
        if self.cloud_backend.is_available():
            try:
                # å‡†å¤‡è¾“å…¥
                inputs = {
                    'x': x.cpu().numpy().tolist(),
                    'weight': self.weight.detach().cpu().numpy().tolist(),
                    'bias': self.bias.detach().cpu().numpy().tolist() if self.bias is not None else None
                }

                # è°ƒç”¨äº‘ç«¯API
                result = self.cloud_backend.inference(inputs)

                # è§£æç»“æœ
                if 'output' in result:
                    output = torch.tensor(result['output'], device=x.device)
                    self.stats['cloud_calls'] += 1
                    return output
                else:
                    raise ValueError("äº‘ç«¯è¿”å›æ— æ•ˆæ ¼å¼")

            except Exception as e:
                self.stats['cloud_errors'] += 1
                warnings.warn(f"äº‘ç«¯NPUæ¨ç†å¤±è´¥: {e}ï¼Œå›é€€åˆ°æœ¬åœ°è®¡ç®—")
                if not self.fallback_local:
                    raise

        # Fallbackåˆ°æœ¬åœ°è®¡ç®—
        self.stats['local_calls'] += 1
        return nn.functional.linear(x, self.weight, self.bias)

    def get_stats(self) -> Dict[str, int]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total = self.stats['cloud_calls'] + self.stats['local_calls']
        return {
            **self.stats,
            'total_calls': total,
            'cloud_ratio': self.stats['cloud_calls'] / total if total > 0 else 0
        }


class CloudNPUManager:
    """äº‘ç«¯NPUç®¡ç†å™¨"""

    def __init__(self):
        self.backends: Dict[str, CloudNPUBackend] = {}
        self._load_from_env()

    def _load_from_env(self):
        """ä»ç¯å¢ƒå˜é‡åŠ è½½äº‘ç«¯NPUé…ç½®"""
        # åä¸ºäº‘ModelArts
        if os.getenv('HUAWEI_CLOUD_API_KEY'):
            try:
                backend = HuaweiModelArtsNPU(
                    api_key=os.getenv('HUAWEI_CLOUD_API_KEY'),
                    endpoint_url=os.getenv('HUAWEI_CLOUD_ENDPOINT', 'https://modelarts.cn-north-4.myhuaweicloud.com'),
                    model_name=os.getenv('HUAWEI_CLOUD_MODEL', 'deepseek-r1'),
                    region=os.getenv('HUAWEI_CLOUD_REGION', 'cn-north-4')
                )
                self.backends['huawei'] = backend
                print("âœ… å·²åŠ è½½åä¸ºäº‘ModelArts NPU")
            except Exception as e:
                warnings.warn(f"åä¸ºäº‘NPUåŠ è½½å¤±è´¥: {e}")

    def add_backend(self, name: str, backend: CloudNPUBackend):
        """æ·»åŠ äº‘ç«¯NPUåç«¯"""
        self.backends[name] = backend
        print(f"âœ… å·²æ·»åŠ äº‘ç«¯NPUåç«¯: {name}")

    def get_backend(self, name: Optional[str] = None) -> Optional[CloudNPUBackend]:
        """
        è·å–äº‘ç«¯NPUåç«¯

        Args:
            name: åç«¯åç§°ï¼ŒNoneåˆ™è¿”å›ç¬¬ä¸€ä¸ªå¯ç”¨çš„
        """
        if name:
            return self.backends.get(name)

        # è¿”å›ç¬¬ä¸€ä¸ªå¯ç”¨çš„åç«¯
        for backend in self.backends.values():
            if backend.is_available():
                return backend

        return None

    def list_backends(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰äº‘ç«¯NPUåç«¯"""
        return list(self.backends.keys())

    def is_any_available(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•äº‘ç«¯NPUå¯ç”¨"""
        return any(b.is_available() for b in self.backends.values())

    def cleanup(self):
        """æ¸…ç†æ‰€æœ‰è¿æ¥"""
        for backend in self.backends.values():
            backend.close()


# å…¨å±€äº‘ç«¯NPUç®¡ç†å™¨
_cloud_npu_manager = None


def get_cloud_npu_manager() -> CloudNPUManager:
    """è·å–å…¨å±€äº‘ç«¯NPUç®¡ç†å™¨"""
    global _cloud_npu_manager
    if _cloud_npu_manager is None:
        _cloud_npu_manager = CloudNPUManager()
    return _cloud_npu_manager


def enable_cloud_npu(provider: str = 'auto', **kwargs):
    """
    å¯ç”¨äº‘ç«¯NPU

    Args:
        provider: äº‘æœåŠ¡å•† ('huawei', 'auto')
        **kwargs: äº‘æœåŠ¡å•†ç‰¹å®šå‚æ•°

    Example:
        >>> enable_cloud_npu('huawei',
        ...                  api_key='your-key',
        ...                  endpoint_url='https://...')
    """
    manager = get_cloud_npu_manager()

    if provider == 'auto':
        if not manager.is_any_available():
            print("âš ï¸ æœªæ‰¾åˆ°å¯ç”¨çš„äº‘ç«¯NPU")
            print("ğŸ’¡ æç¤ºï¼šè¯·è®¾ç½®ç¯å¢ƒå˜é‡ï¼š")
            print("   export HUAWEI_CLOUD_API_KEY=your-key")
            print("   export HUAWEI_CLOUD_ENDPOINT=https://...")
        return

    # æ‰‹åŠ¨æ·»åŠ åç«¯
    if provider == 'huawei':
        backend = HuaweiModelArtsNPU(**kwargs)
        manager.add_backend('huawei', backend)


__all__ = [
    'CloudNPUBackend',
    'HuaweiModelArtsNPU',
    'CloudNPULinear',
    'CloudNPUManager',
    'get_cloud_npu_manager',
    'enable_cloud_npu',
]
