#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
APT Model Administrator Mode
APTæ¨¡å‹ç®¡ç†å‘˜æ¨¡å¼ - æä¾›é«˜çº§è°ƒè¯•å’Œæ¨¡å‹æ§åˆ¶åŠŸèƒ½

è­¦å‘Šï¼šæ­¤æ¨¡å—ä»…ä¾›ç ”ç©¶å’Œå¼€å‘ç›®çš„ä½¿ç”¨
"""

import os
import sys
import time
import logging
import json
import traceback
from typing import Dict, List, Optional, Tuple, Any, Union
from pathlib import Path

import torch
import torch.nn.functional as F


class APTAdminMode:
    """
    APTæ¨¡å‹ç®¡ç†å‘˜æ¨¡å¼
    æä¾›é«˜çº§æ¨¡å‹è°ƒè¯•åŠŸèƒ½å’Œå‚æ•°æ§åˆ¶
    """
    
    def __init__(
        self,
        model_path: str = "apt_model",
        temperature: float = 0.7,
        top_p: float = 0.9,
        max_length: int = 100,
        logger: Optional[logging.Logger] = None,
        admin_password: str = "aptadmin",
        tokenizer_type: Optional[str] = None,
        force_cpu: bool = False
    ):
        """
        åˆå§‹åŒ–APTæ¨¡å‹ç®¡ç†å‘˜æ¨¡å¼
        
        å‚æ•°:
            model_path: æ¨¡å‹è·¯å¾„
            temperature: ç”Ÿæˆæ¸©åº¦
            top_p: top-pé‡‡æ ·å‚æ•°
            max_length: æœ€å¤§ç”Ÿæˆé•¿åº¦
            logger: æ—¥å¿—è®°å½•å™¨
            admin_password: ç®¡ç†å‘˜å¯†ç 
            tokenizer_type: åˆ†è¯å™¨ç±»å‹
            force_cpu: æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨CPU
        """
        self.model_path = model_path
        self.temperature = temperature
        self.top_p = top_p
        self.max_length = max_length
        self.admin_password = admin_password
        self.tokenizer_type = tokenizer_type
        self.force_cpu = force_cpu
        
        # è®¾ç½®æ—¥å¿—
        self.logger = logger or self._setup_logger()
        
        # çŠ¶æ€å˜é‡
        self.model = None
        self.tokenizer = None
        self.config = None
        self.device = "cpu" if force_cpu else ("cuda" if torch.cuda.is_available() else "cpu")
        self.context = []  # å¯¹è¯å†å²
        self.authenticated = False
        self.safety_layer_enabled = True
        self.advanced_debugging = False
        self.show_metrics = True
        self.raw_mode = False
        self.show_token_probabilities = False
        self.custom_system_prompt = None
        
        # ç³»ç»Ÿæç¤º
        self.system_prompts = {
            "welcome": f"\n{'='*60}\nğŸ”§ APTæ¨¡å‹ç®¡ç†å‘˜æ¨¡å¼\n{'='*60}\nè¾“å…¥ '/login <å¯†ç >' è¿›è¡Œèº«ä»½éªŒè¯\nè¾“å…¥ '/help' æŸ¥çœ‹åŸºæœ¬å‘½ä»¤\n{'='*60}",
            "auth_success": "\nâœ… ç®¡ç†å‘˜èº«ä»½éªŒè¯æˆåŠŸ!\nè¿›å…¥ç®¡ç†å‘˜æ¨¡å¼! è¾“å…¥ '/admin' æŸ¥çœ‹ç®¡ç†å‘˜å‘½ä»¤\n",
            "auth_failed": "\nâŒ èº«ä»½éªŒè¯å¤±è´¥ï¼å¯†ç é”™è¯¯ã€‚\n",
            "need_auth": "\nâš ï¸  æ­¤å‘½ä»¤éœ€è¦ç®¡ç†å‘˜æƒé™ã€‚è¯·å…ˆä½¿ç”¨ '/login <å¯†ç >' è¿›è¡Œèº«ä»½éªŒè¯ã€‚\n"
        }
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_interactions': 0,
            'avg_generation_time': 0,
            'safety_bypasses': 0,
            'parameter_overrides': 0
        }
        
        self.logger.info("APTç®¡ç†å‘˜æ¨¡å¼åˆå§‹åŒ–å®Œæˆ")
    
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger('APTAdminMode')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    # ==================== æ¨¡å‹åŠ è½½ ====================
    
    def load_model(self):
        """åŠ è½½APTæ¨¡å‹"""
        try:
            self.logger.info(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_path}")
            
            # å°è¯•å¯¼å…¥APTæ¨¡å‹
            try:
                from apt_model.modeling.apt_model import APTModel, APTLargeModel
                from apt.core.config.apt_config import APTConfig
            except ImportError:
                self.logger.error("æ— æ³•å¯¼å…¥APTæ¨¡å‹ã€‚è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…apt_modelåŒ…ã€‚")
                return False
            
            # åŠ è½½é…ç½®
            config_path = os.path.join(self.model_path, 'config.json')
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    config_dict = json.load(f)
                self.config = APTConfig(**config_dict)
            else:
                self.config = APTConfig()
            
            # åŠ è½½æ¨¡å‹
            if hasattr(self.config, 'large_model') and self.config.large_model:
                self.model = APTLargeModel(self.config)
            else:
                self.model = APTModel(self.config)
            
            # åŠ è½½æƒé‡
            model_file = os.path.join(self.model_path, 'pytorch_model.bin')
            if os.path.exists(model_file):
                state_dict = torch.load(model_file, map_location=self.device)
                self.model.load_state_dict(state_dict)
                self.logger.info("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")
            else:
                self.logger.warning("âš ï¸  æœªæ‰¾åˆ°æ¨¡å‹æƒé‡æ–‡ä»¶ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")
            
            self.model.to(self.device)
            self.model.eval()
            
            # åŠ è½½åˆ†è¯å™¨
            self._load_tokenizer()
            
            self.logger.info("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
            return True
            
        except Exception as e:
            self.logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.logger.error(traceback.format_exc())
            return False
    
    def _load_tokenizer(self):
        """åŠ è½½åˆ†è¯å™¨"""
        try:
            if self.tokenizer_type == 'gpt2':
                from transformers import GPT2Tokenizer
                self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
            elif self.tokenizer_type == 'chinese-char':
                # ç®€å•çš„ä¸­æ–‡å­—ç¬¦çº§åˆ†è¯å™¨
                self.tokenizer = self._create_chinese_char_tokenizer()
            elif self.tokenizer_type == 'chinese-word':
                # ç®€å•çš„ä¸­æ–‡è¯çº§åˆ†è¯å™¨
                self.tokenizer = self._create_chinese_word_tokenizer()
            else:
                # é»˜è®¤ä½¿ç”¨GPT2
                from transformers import GPT2Tokenizer
                self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
            
            self.logger.info(f"âœ… åˆ†è¯å™¨åŠ è½½å®Œæˆ: {self.tokenizer_type or 'gpt2'}")
            
        except Exception as e:
            self.logger.warning(f"åˆ†è¯å™¨åŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨ç®€å•åˆ†è¯å™¨")
            self.tokenizer = self._create_simple_tokenizer()
    
    def _create_simple_tokenizer(self):
        """åˆ›å»ºç®€å•çš„åˆ†è¯å™¨"""
        class SimpleTokenizer:
            def encode(self, text):
                return [ord(c) for c in text]
            
            def decode(self, tokens):
                return ''.join([chr(t) for t in tokens if 0 <= t < 1114112])
            
            @property
            def vocab_size(self):
                return 50000
        
        return SimpleTokenizer()
    
    def _create_chinese_char_tokenizer(self):
        """åˆ›å»ºä¸­æ–‡å­—ç¬¦çº§åˆ†è¯å™¨"""
        class ChineseCharTokenizer:
            def __init__(self):
                # ç®€å•çš„å­—ç¬¦æ˜ å°„
                self.char_to_id = {}
                self.id_to_char = {}
                self.next_id = 0
            
            def encode(self, text):
                tokens = []
                for char in text:
                    if char not in self.char_to_id:
                        self.char_to_id[char] = self.next_id
                        self.id_to_char[self.next_id] = char
                        self.next_id += 1
                    tokens.append(self.char_to_id[char])
                return tokens
            
            def decode(self, tokens):
                return ''.join([self.id_to_char.get(t, '') for t in tokens])
            
            @property
            def vocab_size(self):
                return max(50000, self.next_id)
        
        return ChineseCharTokenizer()
    
    def _create_chinese_word_tokenizer(self):
        """åˆ›å»ºä¸­æ–‡è¯çº§åˆ†è¯å™¨"""
        class ChineseWordTokenizer:
            def __init__(self):
                # ç®€å•çš„è¯æ˜ å°„
                self.word_to_id = {}
                self.id_to_word = {}
                self.next_id = 0
            
            def encode(self, text):
                # ç®€å•æŒ‰ç©ºæ ¼åˆ†è¯
                words = text.split()
                tokens = []
                for word in words:
                    if word not in self.word_to_id:
                        self.word_to_id[word] = self.next_id
                        self.id_to_word[self.next_id] = word
                        self.next_id += 1
                    tokens.append(self.word_to_id[word])
                return tokens
            
            def decode(self, tokens):
                return ' '.join([self.id_to_word.get(t, '') for t in tokens])
            
            @property
            def vocab_size(self):
                return max(50000, self.next_id)
        
        return ChineseWordTokenizer()
    
    # ==================== å‘½ä»¤å¤„ç† ====================
    
    def process_command(self, command: str) -> Optional[str]:
        """
        å¤„ç†å‘½ä»¤
        
        å‚æ•°:
            command: ç”¨æˆ·è¾“å…¥çš„å‘½ä»¤
            
        è¿”å›:
            å‘½ä»¤æ‰§è¡Œç»“æœæˆ–None
        """
        if not command.startswith('/'):
            return None
        
        parts = command[1:].split()
        if not parts:
            return None
        
        cmd = parts[0].lower()
        args = parts[1:] if len(parts) > 1 else []
        
        # åŸºæœ¬å‘½ä»¤ï¼ˆä¸éœ€è¦è®¤è¯ï¼‰
        if cmd == 'login':
            return self._cmd_login(args)
        elif cmd == 'help':
            return self._cmd_help()
        elif cmd == 'exit' or cmd == 'quit' or cmd == 'bye':
            return self._cmd_exit()
        elif cmd == 'clear':
            return self._cmd_clear()
        
        # å‚æ•°è°ƒæ•´å‘½ä»¤ï¼ˆä¸éœ€è¦è®¤è¯ï¼‰
        elif cmd == 'temp':
            return self._cmd_set_temperature(args)
        elif cmd == 'top_p':
            return self._cmd_set_top_p(args)
        elif cmd == 'length':
            return self._cmd_set_max_length(args)
        
        # ç®¡ç†å‘˜å‘½ä»¤ï¼ˆéœ€è¦è®¤è¯ï¼‰
        if not self.authenticated:
            return self.system_prompts['need_auth']
        
        if cmd == 'admin':
            return self._cmd_admin_help()
        elif cmd == 'safety':
            return self._cmd_toggle_safety(args)
        elif cmd == 'debug':
            return self._cmd_toggle_debug(args)
        elif cmd == 'raw':
            return self._cmd_toggle_raw_mode(args)
        elif cmd == 'probabilities' or cmd == 'probs':
            return self._cmd_toggle_probabilities(args)
        elif cmd == 'system':
            return self._cmd_set_system_prompt(args)
        elif cmd == 'reset_system':
            return self._cmd_reset_system_prompt()
        elif cmd == 'inspect':
            return self._cmd_inspect_model()
        elif cmd == 'benchmark':
            return self._cmd_benchmark()
        elif cmd == 'export':
            return self._cmd_export_session(args)
        elif cmd == 'visualize':
            return self._cmd_visualize()
        elif cmd == 'override':
            return self._cmd_override_params(args)
        elif cmd == 'stats':
            return self._cmd_show_stats()
        else:
            return f"âŒ æœªçŸ¥å‘½ä»¤: /{cmd}\nè¾“å…¥ '/help' æŸ¥çœ‹å¯ç”¨å‘½ä»¤"
    
    # ==================== åŸºæœ¬å‘½ä»¤ ====================
    
    def _cmd_login(self, args: List[str]) -> str:
        """ç™»å½•å‘½ä»¤"""
        if not args:
            return "âŒ ç”¨æ³•: /login <å¯†ç >"
        
        password = args[0]
        if password == self.admin_password:
            self.authenticated = True
            return self.system_prompts['auth_success']
        else:
            return self.system_prompts['auth_failed']
    
    def _cmd_help(self) -> str:
        """å¸®åŠ©å‘½ä»¤"""
        help_text = """
ğŸ“– APTç®¡ç†å‘˜æ¨¡å¼ - å‘½ä»¤å¸®åŠ©

åŸºæœ¬å‘½ä»¤:
  /login <å¯†ç >     - ç®¡ç†å‘˜èº«ä»½éªŒè¯
  /help             - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
  /exit, /quit      - é€€å‡ºç¨‹åº
  /clear            - æ¸…é™¤å¯¹è¯å†å²
  
å‚æ•°è°ƒæ•´:
  /temp <å€¼>        - è®¾ç½®æ¸©åº¦å‚æ•° (0.0-2.0)
  /top_p <å€¼>       - è®¾ç½®top-på‚æ•° (0.0-1.0)
  /length <å€¼>      - è®¾ç½®æœ€å¤§ç”Ÿæˆé•¿åº¦
  
ç®¡ç†å‘˜å‘½ä»¤ (éœ€è¦å…ˆç™»å½•):
  /admin            - æ˜¾ç¤ºç®¡ç†å‘˜å‘½ä»¤å¸®åŠ©
  /safety <on/off>  - å¯ç”¨/ç¦ç”¨å®‰å…¨å±‚
  /debug <on/off>   - å¯ç”¨/ç¦ç”¨é«˜çº§è°ƒè¯•
  /raw <on/off>     - å¯ç”¨/ç¦ç”¨åŸå§‹è¾“å‡ºæ¨¡å¼
  /probs <on/off>   - æ˜¾ç¤º/éšè—è¯å…ƒæ¦‚ç‡
  /system <prompt>  - è®¾ç½®è‡ªå®šä¹‰ç³»ç»Ÿæç¤º
  /reset_system     - é‡ç½®ç³»ç»Ÿæç¤º
  /inspect          - æ£€æŸ¥æ¨¡å‹å’Œåˆ†è¯å™¨ä¿¡æ¯
  /benchmark        - è¿è¡ŒåŸºå‡†æµ‹è¯•
  /export <file>    - å¯¼å‡ºå½“å‰ä¼šè¯
  /visualize        - å¯è§†åŒ–æ³¨æ„åŠ›å±‚
  /override <json>  - è¦†ç›–æ¨¡å‹å‚æ•°
  /stats            - æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
"""
        return help_text
    
    def _cmd_exit(self) -> str:
        """é€€å‡ºå‘½ä»¤"""
        print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨APTç®¡ç†å‘˜æ¨¡å¼ï¼å†è§ï¼")
        sys.exit(0)
    
    def _cmd_clear(self) -> str:
        """æ¸…é™¤å¯¹è¯å†å²"""
        self.context.clear()
        return "âœ… å¯¹è¯å†å²å·²æ¸…é™¤"
    
    # ==================== å‚æ•°è°ƒæ•´å‘½ä»¤ ====================
    
    def _cmd_set_temperature(self, args: List[str]) -> str:
        """è®¾ç½®æ¸©åº¦å‚æ•°"""
        if not args:
            return f"ğŸ“Š å½“å‰æ¸©åº¦: {self.temperature}\nç”¨æ³•: /temp <å€¼> (0.0-2.0)"
        
        try:
            temp = float(args[0])
            if 0.0 <= temp <= 2.0:
                self.temperature = temp
                return f"âœ… æ¸©åº¦å·²è®¾ç½®ä¸º: {temp}"
            else:
                return "âŒ æ¸©åº¦å€¼å¿…é¡»åœ¨0.0åˆ°2.0ä¹‹é—´"
        except ValueError:
            return "âŒ æ— æ•ˆçš„æ•°å€¼"
    
    def _cmd_set_top_p(self, args: List[str]) -> str:
        """è®¾ç½®top-på‚æ•°"""
        if not args:
            return f"ğŸ“Š å½“å‰top-p: {self.top_p}\nç”¨æ³•: /top_p <å€¼> (0.0-1.0)"
        
        try:
            top_p = float(args[0])
            if 0.0 <= top_p <= 1.0:
                self.top_p = top_p
                return f"âœ… Top-på·²è®¾ç½®ä¸º: {top_p}"
            else:
                return "âŒ Top-på€¼å¿…é¡»åœ¨0.0åˆ°1.0ä¹‹é—´"
        except ValueError:
            return "âŒ æ— æ•ˆçš„æ•°å€¼"
    
    def _cmd_set_max_length(self, args: List[str]) -> str:
        """è®¾ç½®æœ€å¤§ç”Ÿæˆé•¿åº¦"""
        if not args:
            return f"ğŸ“Š å½“å‰æœ€å¤§é•¿åº¦: {self.max_length}\nç”¨æ³•: /length <å€¼>"
        
        try:
            length = int(args[0])
            if length > 0:
                self.max_length = length
                return f"âœ… æœ€å¤§ç”Ÿæˆé•¿åº¦å·²è®¾ç½®ä¸º: {length}"
            else:
                return "âŒ é•¿åº¦å¿…é¡»å¤§äº0"
        except ValueError:
            return "âŒ æ— æ•ˆçš„æ•°å€¼"
    
    # ==================== ç®¡ç†å‘˜å‘½ä»¤ ====================
    
    def _cmd_admin_help(self) -> str:
        """ç®¡ç†å‘˜å‘½ä»¤å¸®åŠ©"""
        help_text = """
ğŸ”§ ç®¡ç†å‘˜å‘½ä»¤è¯¦ç»†è¯´æ˜

å®‰å…¨ä¸è°ƒè¯•:
  /safety on/off    - æ§åˆ¶å®‰å…¨å±‚ (WARNING: offä¼šç»•è¿‡å®‰å…¨æ£€æŸ¥)
  /debug on/off     - å¯ç”¨é«˜çº§è°ƒè¯•æ¨¡å¼ï¼Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
  /raw on/off       - åŸå§‹è¾“å‡ºæ¨¡å¼ï¼Œä¸è¿›è¡Œåå¤„ç†
  /probs on/off     - æ˜¾ç¤ºæ¯ä¸ªè¯å…ƒçš„ç”Ÿæˆæ¦‚ç‡
  
ç³»ç»Ÿæç¤º:
  /system <prompt>  - è®¾ç½®è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºæ¥å¼•å¯¼æ¨¡å‹è¡Œä¸º
  /reset_system     - æ¢å¤é»˜è®¤ç³»ç»Ÿæç¤º
  
æ¨¡å‹åˆ†æ:
  /inspect          - æ˜¾ç¤ºæ¨¡å‹æ¶æ„ã€å‚æ•°æ•°é‡ç­‰è¯¦ç»†ä¿¡æ¯
  /benchmark        - æµ‹è¯•æ¨¡å‹ç”Ÿæˆé€Ÿåº¦å’Œæ€§èƒ½
  /visualize        - å°è¯•å¯è§†åŒ–æ¨¡å‹æ³¨æ„åŠ›å±‚
  
é«˜çº§æ“ä½œ:
  /override <json>  - ç›´æ¥è¦†ç›–æ¨¡å‹å†…éƒ¨å‚æ•° (JSONæ ¼å¼)
  /export <file>    - å¯¼å‡ºå½“å‰ä¼šè¯åˆ°JSONæ–‡ä»¶
  /stats            - æ˜¾ç¤ºä¼šè¯ç»Ÿè®¡ä¿¡æ¯

âš ï¸  æ³¨æ„: ç®¡ç†å‘˜å‘½ä»¤æ˜¯ä¸ºç ”ç©¶å’Œè°ƒè¯•è®¾è®¡çš„ï¼Œè¯·è´Ÿè´£ä»»ä½¿ç”¨ã€‚
"""
        return help_text
    
    def _cmd_toggle_safety(self, args: List[str]) -> str:
        """åˆ‡æ¢å®‰å…¨å±‚"""
        if not args:
            status = "å¯ç”¨" if self.safety_layer_enabled else "ç¦ç”¨"
            return f"ğŸ“Š å½“å‰å®‰å…¨å±‚çŠ¶æ€: {status}\nç”¨æ³•: /safety <on/off>"
        
        action = args[0].lower()
        if action == 'on':
            self.safety_layer_enabled = True
            return "âœ… å®‰å…¨å±‚å·²å¯ç”¨"
        elif action == 'off':
            self.safety_layer_enabled = False
            self.stats['safety_bypasses'] += 1
            return "âš ï¸  è­¦å‘Š: å®‰å…¨å±‚å·²ç¦ç”¨ï¼Œæ¨¡å‹è¡Œä¸ºå°†ä¸å—é™åˆ¶ âš ï¸"
        else:
            return "âŒ ç”¨æ³•: /safety <on/off>"
    
    def _cmd_toggle_debug(self, args: List[str]) -> str:
        """åˆ‡æ¢è°ƒè¯•æ¨¡å¼"""
        if not args:
            status = "å¯ç”¨" if self.advanced_debugging else "ç¦ç”¨"
            return f"ğŸ“Š å½“å‰è°ƒè¯•æ¨¡å¼: {status}\nç”¨æ³•: /debug <on/off>"
        
        action = args[0].lower()
        if action == 'on':
            self.advanced_debugging = True
            return "âœ… é«˜çº§è°ƒè¯•å·²å¯ç”¨"
        elif action == 'off':
            self.advanced_debugging = False
            return "âœ… é«˜çº§è°ƒè¯•å·²ç¦ç”¨"
        else:
            return "âŒ ç”¨æ³•: /debug <on/off>"
    
    def _cmd_toggle_raw_mode(self, args: List[str]) -> str:
        """åˆ‡æ¢åŸå§‹è¾“å‡ºæ¨¡å¼"""
        if not args:
            status = "å¯ç”¨" if self.raw_mode else "ç¦ç”¨"
            return f"ğŸ“Š å½“å‰åŸå§‹è¾“å‡ºæ¨¡å¼: {status}\nç”¨æ³•: /raw <on/off>"
        
        action = args[0].lower()
        if action == 'on':
            self.raw_mode = True
            return "âœ… åŸå§‹è¾“å‡ºæ¨¡å¼å·²å¯ç”¨"
        elif action == 'off':
            self.raw_mode = False
            return "âœ… åŸå§‹è¾“å‡ºæ¨¡å¼å·²ç¦ç”¨"
        else:
            return "âŒ ç”¨æ³•: /raw <on/off>"
    
    def _cmd_toggle_probabilities(self, args: List[str]) -> str:
        """åˆ‡æ¢è¯å…ƒæ¦‚ç‡æ˜¾ç¤º"""
        if not args:
            status = "å¯ç”¨" if self.show_token_probabilities else "ç¦ç”¨"
            return f"ğŸ“Š å½“å‰è¯å…ƒæ¦‚ç‡æ˜¾ç¤º: {status}\nç”¨æ³•: /probs <on/off>"
        
        action = args[0].lower()
        if action == 'on':
            self.show_token_probabilities = True
            return "âœ… è¯å…ƒæ¦‚ç‡æ˜¾ç¤ºå·²å¯ç”¨"
        elif action == 'off':
            self.show_token_probabilities = False
            return "âœ… è¯å…ƒæ¦‚ç‡æ˜¾ç¤ºå·²ç¦ç”¨"
        else:
            return "âŒ ç”¨æ³•: /probs <on/off>"
    
    def _cmd_set_system_prompt(self, args: List[str]) -> str:
        """è®¾ç½®ç³»ç»Ÿæç¤º"""
        if not args:
            current = self.custom_system_prompt or "æœªè®¾ç½®"
            return f"ğŸ“Š å½“å‰ç³»ç»Ÿæç¤º: {current}\nç”¨æ³•: /system <æç¤ºå†…å®¹>"
        
        prompt = ' '.join(args)
        self.custom_system_prompt = prompt
        return f"âœ… ç³»ç»Ÿæç¤ºå·²æ›´æ”¹\næ–°ç³»ç»Ÿæç¤º: {prompt}"
    
    def _cmd_reset_system_prompt(self) -> str:
        """é‡ç½®ç³»ç»Ÿæç¤º"""
        self.custom_system_prompt = None
        return "âœ… ç³»ç»Ÿæç¤ºå·²é‡ç½®ä¸ºé»˜è®¤"
    
    def _cmd_inspect_model(self) -> str:
        """æ£€æŸ¥æ¨¡å‹ä¿¡æ¯"""
        if self.model is None:
            return "âŒ æ¨¡å‹å°šæœªåŠ è½½"
        
        info = [
            "\n" + "="*60,
            "ğŸ” æ¨¡å‹ä¿¡æ¯æ£€æŸ¥",
            "="*60,
            f"è®¾å¤‡: {self.device}",
            f"æ¨¡å‹ç±»å‹: {type(self.model).__name__}",
        ]
        
        # æ¨¡å‹å‚æ•°æ•°é‡
        try:
            total_params = sum(p.numel() for p in self.model.parameters())
            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
            info.append(f"æ€»å‚æ•°æ•°: {total_params:,}")
            info.append(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        except:
            info.append("æ— æ³•è®¡ç®—å‚æ•°æ•°é‡")
        
        # é…ç½®ä¿¡æ¯
        if self.config:
            info.append(f"\né…ç½®ä¿¡æ¯:")
            info.append(f"  è¯æ±‡è¡¨å¤§å°: {self.config.vocab_size}")
            info.append(f"  éšè—å±‚å¤§å°: {self.config.d_model}")
            info.append(f"  æ³¨æ„åŠ›å¤´æ•°: {self.config.n_heads}")
            info.append(f"  å±‚æ•°: {self.config.n_layers}")
        
        # åˆ†è¯å™¨ä¿¡æ¯
        if self.tokenizer:
            info.append(f"\nåˆ†è¯å™¨ä¿¡æ¯:")
            info.append(f"  ç±»å‹: {type(self.tokenizer).__name__}")
            try:
                info.append(f"  è¯æ±‡è¡¨å¤§å°: {self.tokenizer.vocab_size}")
            except:
                info.append(f"  è¯æ±‡è¡¨å¤§å°: æœªçŸ¥")
        
        info.append("="*60)
        
        return '\n'.join(info)
    
    def _cmd_benchmark(self) -> str:
        """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
        if self.model is None:
            return "âŒ æ¨¡å‹å°šæœªåŠ è½½"
        
        self.logger.info("å¼€å§‹åŸºå‡†æµ‹è¯•...")
        
        test_prompts = [
            "ä½ å¥½",
            "ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±",
            "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·",
        ]
        
        results = []
        total_time = 0
        
        for prompt in test_prompts:
            start_time = time.time()
            try:
                response = self.generate_response(prompt)
                elapsed = time.time() - start_time
                total_time += elapsed
                
                results.append({
                    'prompt': prompt,
                    'response_length': len(response),
                    'time': elapsed
                })
            except Exception as e:
                results.append({
                    'prompt': prompt,
                    'error': str(e)
                })
        
        # ç”ŸæˆæŠ¥å‘Š
        report = [
            "\n" + "="*60,
            "âš¡ åŸºå‡†æµ‹è¯•ç»“æœ",
            "="*60,
        ]
        
        for i, result in enumerate(results, 1):
            report.append(f"\næµ‹è¯• {i}:")
            report.append(f"  æç¤º: {result['prompt']}")
            if 'error' in result:
                report.append(f"  âŒ é”™è¯¯: {result['error']}")
            else:
                report.append(f"  å“åº”é•¿åº¦: {result['response_length']} å­—ç¬¦")
                report.append(f"  ç”Ÿæˆæ—¶é—´: {result['time']:.3f} ç§’")
                report.append(f"  é€Ÿåº¦: {result['response_length']/result['time']:.1f} å­—ç¬¦/ç§’")
        
        if len([r for r in results if 'error' not in r]) > 0:
            avg_time = total_time / len([r for r in results if 'error' not in r])
            report.append(f"\nå¹³å‡ç”Ÿæˆæ—¶é—´: {avg_time:.3f} ç§’")
        
        report.append("="*60)
        
        return '\n'.join(report)
    
    def _cmd_export_session(self, args: List[str]) -> str:
        """å¯¼å‡ºä¼šè¯"""
        if not args:
            return "âŒ ç”¨æ³•: /export <æ–‡ä»¶å>"
        
        filename = args[0]
        if not filename.endswith('.json'):
            filename += '.json'
        
        try:
            session_data = {
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'config': {
                    'temperature': self.temperature,
                    'top_p': self.top_p,
                    'max_length': self.max_length,
                    'safety_enabled': self.safety_layer_enabled,
                    'custom_system_prompt': self.custom_system_prompt
                },
                'context': self.context,
                'stats': self.stats
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(session_data, f, ensure_ascii=False, indent=2)
            
            return f"âœ… ä¼šè¯å·²å¯¼å‡ºåˆ°: {filename}"
            
        except Exception as e:
            return f"âŒ å¯¼å‡ºå¤±è´¥: {e}"
    
    def _cmd_visualize(self) -> str:
        """å¯è§†åŒ–æ³¨æ„åŠ›å±‚"""
        if self.model is None:
            return "âŒ æ¨¡å‹å°šæœªåŠ è½½"
        
        try:
            import matplotlib.pyplot as plt
            import numpy as np
            
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ¨¡å‹ç»“æ„æ¥æå–æ³¨æ„åŠ›æƒé‡
            # è¿™åªæ˜¯ä¸€ä¸ªç¤ºä¾‹
            
            return "âš ï¸  æ³¨æ„åŠ›å¯è§†åŒ–åŠŸèƒ½éœ€è¦æ ¹æ®å…·ä½“æ¨¡å‹ç»“æ„å®ç°"
            
        except ImportError:
            return "âŒ éœ€è¦å®‰è£…matplotlibåº“: pip install matplotlib"
        except Exception as e:
            return f"âŒ å¯è§†åŒ–å¤±è´¥: {e}"
    
    def _cmd_override_params(self, args: List[str]) -> str:
        """è¦†ç›–æ¨¡å‹å‚æ•°"""
        if not args:
            return "âŒ ç”¨æ³•: /override <JSONæ ¼å¼å‚æ•°>"
        
        try:
            params_str = ' '.join(args)
            params = json.loads(params_str)
            
            self.stats['parameter_overrides'] += 1
            
            # åº”ç”¨å‚æ•°è¦†ç›–
            override_count = 0
            for key, value in params.items():
                if hasattr(self, key):
                    setattr(self, key, value)
                    override_count += 1
            
            return f"âœ… å·²è¦†ç›– {override_count} ä¸ªå‚æ•°"
            
        except json.JSONDecodeError:
            return "âŒ æ— æ•ˆçš„JSONæ ¼å¼"
        except Exception as e:
            return f"âŒ å‚æ•°è¦†ç›–å¤±è´¥: {e}"
    
    def _cmd_show_stats(self) -> str:
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        stats_text = [
            "\n" + "="*60,
            "ğŸ“Š ä¼šè¯ç»Ÿè®¡ä¿¡æ¯",
            "="*60,
            f"æ€»äº¤äº’æ¬¡æ•°: {self.stats['total_interactions']}",
            f"å¹³å‡ç”Ÿæˆæ—¶é—´: {self.stats['avg_generation_time']:.3f} ç§’",
            f"å®‰å…¨å±‚ç»•è¿‡æ¬¡æ•°: {self.stats['safety_bypasses']}",
            f"å‚æ•°è¦†ç›–æ¬¡æ•°: {self.stats['parameter_overrides']}",
            "="*60
        ]
        
        return '\n'.join(stats_text)
    
    # ==================== ç”Ÿæˆå“åº” ====================
    
    def generate_response(self, prompt: str) -> str:
        """
        ç”Ÿæˆå“åº”
        
        å‚æ•°:
            prompt: ç”¨æˆ·è¾“å…¥
            
        è¿”å›:
            ç”Ÿæˆçš„å“åº”æ–‡æœ¬
        """
        if self.model is None:
            return "âŒ æ¨¡å‹å°šæœªåŠ è½½ã€‚è¯·å…ˆåŠ è½½æ¨¡å‹ã€‚"
        
        try:
            start_time = time.time()
            
            # æ·»åŠ è‡ªå®šä¹‰ç³»ç»Ÿæç¤º
            if self.custom_system_prompt:
                full_prompt = f"{self.custom_system_prompt}\n\n{prompt}"
            else:
                full_prompt = prompt
            
            # ç¼–ç è¾“å…¥
            input_ids = self.tokenizer.encode(full_prompt)
            input_tensor = torch.tensor([input_ids]).to(self.device)
            
            # ç”Ÿæˆ
            with torch.no_grad():
                outputs = self.model.generate(
                    input_tensor,
                    max_length=self.max_length,
                    temperature=self.temperature,
                    top_p=self.top_p
                )
            
            # è§£ç è¾“å‡º
            generated_ids = outputs[0].cpu().tolist()
            response = self.tokenizer.decode(generated_ids)
            
            # åå¤„ç†
            if not self.raw_mode:
                response = self._post_process_response(response, full_prompt)
            
            # æ›´æ–°ç»Ÿè®¡
            elapsed = time.time() - start_time
            self.stats['total_interactions'] += 1
            self.stats['avg_generation_time'] = (
                (self.stats['avg_generation_time'] * (self.stats['total_interactions'] - 1) + elapsed)
                / self.stats['total_interactions']
            )
            
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            if self.advanced_debugging:
                debug_info = f"\n[è°ƒè¯•] ç”Ÿæˆæ—¶é—´: {elapsed:.3f}ç§’, é•¿åº¦: {len(response)}å­—ç¬¦"
                response += debug_info
            
            # æ·»åŠ è¯å…ƒæ¦‚ç‡
            if self.show_token_probabilities:
                # è¿™é‡Œéœ€è¦åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­è®°å½•æ¦‚ç‡
                response += "\n\n[è¯å…ƒæ¦‚ç‡] åŠŸèƒ½éœ€è¦æ¨¡å‹æ”¯æŒ"
            
            return response
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆå“åº”æ—¶å‡ºé”™: {e}")
            self.logger.error(traceback.format_exc())
            return f"âŒ ç”Ÿæˆå¤±è´¥: {e}"
    
    def _post_process_response(self, response: str, prompt: str) -> str:
        """åå¤„ç†å“åº”"""
        # ç§»é™¤æç¤ºéƒ¨åˆ†
        if prompt in response:
            response = response.replace(prompt, '').strip()
        
        # åº”ç”¨å®‰å…¨å±‚ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.safety_layer_enabled:
            response = self._apply_safety_filter(response)
        
        return response
    
    def _apply_safety_filter(self, text: str) -> str:
        """åº”ç”¨å®‰å…¨è¿‡æ»¤ï¼ˆç®€å•ç¤ºä¾‹ï¼‰"""
        # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„å®‰å…¨è¿‡æ»¤é€»è¾‘
        # è¿™åªæ˜¯ä¸€ä¸ªå ä½ç¬¦
        return text
    
    # ==================== ä¸»å¾ªç¯ ====================
    
    def start(self):
        """å¯åŠ¨ç®¡ç†å‘˜æ¨¡å¼ä¸»å¾ªç¯"""
        print(self.system_prompts['welcome'])
        
        # åŠ è½½æ¨¡å‹
        if not self.load_model():
            print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
        
        print("\nå‡†å¤‡å°±ç»ªï¼å¼€å§‹å¯¹è¯...\n")
        
        while True:
            try:
                user_input = input("ä½ : ").strip()
                
                if not user_input:
                    continue
                
                # å¤„ç†å‘½ä»¤
                if user_input.startswith('/'):
                    result = self.process_command(user_input)
                    if result:
                        print(result)
                    continue
                
                # ç”Ÿæˆå“åº”
                response = self.generate_response(user_input)
                print(f"\nAPTæ¨¡å‹: {response}\n")
                
                # ä¿å­˜åˆ°ä¸Šä¸‹æ–‡
                self.context.append({
                    'user': user_input,
                    'assistant': response,
                    'timestamp': time.time()
                })
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ é€€å‡ºç®¡ç†å‘˜æ¨¡å¼...")
                break
            except Exception as e:
                self.logger.error(f"å‘ç”Ÿé”™è¯¯: {e}")
                self.logger.error(traceback.format_exc())
                print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}\n")


# ==================== å¯åŠ¨å‡½æ•° ====================

def start_admin_mode(
    model_path: str = "apt_model",
    temperature: float = 0.7,
    top_p: float = 0.9,
    max_length: int = 100,
    admin_password: str = "aptadmin",
    tokenizer_type: Optional[str] = None,
    force_cpu: bool = False
):
    """
    å¯åŠ¨APTç®¡ç†å‘˜æ¨¡å¼
    
    å‚æ•°:
        model_path: æ¨¡å‹è·¯å¾„
        temperature: ç”Ÿæˆæ¸©åº¦
        top_p: top-pé‡‡æ ·å‚æ•°
        max_length: æœ€å¤§ç”Ÿæˆé•¿åº¦
        admin_password: ç®¡ç†å‘˜å¯†ç 
        tokenizer_type: åˆ†è¯å™¨ç±»å‹
        force_cpu: æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨CPU
    """
    admin_mode = APTAdminMode(
        model_path=model_path,
        temperature=temperature,
        top_p=top_p,
        max_length=max_length,
        admin_password=admin_password,
        tokenizer_type=tokenizer_type,
        force_cpu=force_cpu
    )
    
    admin_mode.start()


# ==================== ä¸»å…¥å£ ====================

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="APTæ¨¡å‹ç®¡ç†å‘˜æ¨¡å¼")
    parser.add_argument('--model-path', type=str, default="apt_model", help="æ¨¡å‹è·¯å¾„")
    parser.add_argument('--temperature', type=float, default=0.7, help="ç”Ÿæˆæ¸©åº¦")
    parser.add_argument('--top-p', type=float, default=0.9, help="Top-på‚æ•°")
    parser.add_argument('--max-length', type=int, default=100, help="æœ€å¤§ç”Ÿæˆé•¿åº¦")
    parser.add_argument('--password', type=str, default="aptadmin", help="ç®¡ç†å‘˜å¯†ç ")
    parser.add_argument('--tokenizer-type', type=str, 
                       choices=['gpt2', 'chinese-char', 'chinese-word'],
                       help="åˆ†è¯å™¨ç±»å‹")
    parser.add_argument('--force-cpu', action='store_true', help="å¼ºåˆ¶ä½¿ç”¨CPU")
    
    args = parser.parse_args()
    
    start_admin_mode(
        model_path=args.model_path,
        temperature=args.temperature,
        top_p=args.top_p,
        max_length=args.max_length,
        admin_password=args.password,
        tokenizer_type=args.tokenizer_type,
        force_cpu=args.force_cpu
    )
