# WebUIæ¥å£è®¾è®¡ï¼ˆä¼ç¬”ï¼‰

**æ—¥æœŸ**: 2025-11-30
**ç›®çš„**: ä¸ºå°†æ¥çš„WebUIå®ç°é¢„ç•™æ¥å£å’Œé’©å­
**çŠ¶æ€**: å·²åŸ‹ä¸‹ä¼ç¬”ï¼Œç­‰å¾…å®ç°

---

## ğŸ¯ è®¾è®¡ç†å¿µ

ä¸åœ¨ç°åœ¨å®ç°å®Œæ•´WebUIï¼Œä½†åœ¨ä»£ç æ¶æ„ä¸­**é¢„ç•™å¥½æ¥å£**ï¼Œè®©å°†æ¥æ·»åŠ WebUIæ—¶ï¼š
- âœ… ä¸éœ€è¦å¤§è§„æ¨¡é‡æ„è®­ç»ƒä»£ç 
- âœ… å¯ä»¥å³æ’å³ç”¨
- âœ… æ”¯æŒå¤šç§UIæ¡†æ¶ï¼ˆGradio/Streamlit/Flaskç­‰ï¼‰
- âœ… è§£è€¦è®­ç»ƒé€»è¾‘å’ŒUIé€»è¾‘

---

## ğŸ“¦ å·²å®ç°çš„ä¼ç¬”

### 1. è®­ç»ƒäº‹ä»¶ç³»ç»Ÿ (`training_events.py`)

**ä½ç½®**: `apt_model/training/training_events.py`

**æ ¸å¿ƒç»„ä»¶**:
```python
from apt_model.training.training_events import training_emitter

# è®­ç»ƒå™¨å‘å°„äº‹ä»¶
training_emitter.emit('batch_end', batch_idx=100, loss=2.5, lr=0.0001)

# WebUIè®¢é˜…äº‹ä»¶
def on_batch_update(event_data):
    # æ›´æ–°WebUIæ˜¾ç¤º
    update_loss_chart(event_data['loss'])

training_emitter.on('batch_end', on_batch_update)
```

**æ”¯æŒçš„äº‹ä»¶**:
- `training_start` - è®­ç»ƒå¼€å§‹
- `training_end` - è®­ç»ƒç»“æŸ
- `epoch_start` - Epochå¼€å§‹
- `epoch_end` - Epochç»“æŸ
- `batch_start` - Batchå¼€å§‹
- `batch_end` - Batchç»“æŸ
- `checkpoint_saved` - Checkpointä¿å­˜
- `checkpoint_loaded` - CheckpointåŠ è½½
- `metric_update` - æŒ‡æ ‡æ›´æ–°
- `error_occurred` - é”™è¯¯å‘ç”Ÿ

---

### 2. WebUIé’©å­ç¤ºä¾‹ç±» (`WebUIHooks`)

**ä½œç”¨**: å±•ç¤ºå¦‚ä½•è®¢é˜…è®­ç»ƒäº‹ä»¶

```python
from apt_model.training.training_events import WebUIHooks, training_emitter

# åˆ›å»ºWebUIé’©å­
webui_hooks = WebUIHooks()

# é™„åŠ åˆ°è®­ç»ƒäº‹ä»¶
webui_hooks.attach(training_emitter)

# è·å–å½“å‰è®­ç»ƒçŠ¶æ€ï¼ˆç”¨äºWebUI APIï¼‰
state = webui_hooks.get_current_state()
# {
#     'current_epoch': 3,
#     'total_epochs': 10,
#     'current_batch': 250,
#     'current_loss': 2.5432,
#     'learning_rate': 0.00009,
#     'is_training': True
# }
```

---

### 3. ä¾¿æ·å‡½æ•°

ä¸ºå¸¸ç”¨äº‹ä»¶æä¾›å¿«æ·å‘å°„å‡½æ•°ï¼š

```python
from apt_model.training.training_events import (
    emit_training_start,
    emit_epoch_end,
    emit_batch_end,
    emit_checkpoint_saved,
)

# åœ¨è®­ç»ƒå™¨ä¸­ä½¿ç”¨
emit_training_start(total_epochs=10)
emit_batch_end(batch_idx=100, loss=2.5, lr=0.0001)
emit_checkpoint_saved(checkpoint_path="./model.pt", epoch=3, step=1500)
```

---

## ğŸŒ å°†æ¥çš„WebUIå®ç°æ–¹æ¡ˆ

### æ–¹æ¡ˆ1: Gradioï¼ˆæœ€ç®€å•ï¼‰

**ç‰¹ç‚¹**:
- å¿«é€ŸåŸå‹
- è‡ªåŠ¨ç”Ÿæˆç•Œé¢
- é€‚åˆæ¼”ç¤ºå’Œæµ‹è¯•

**å®ç°ç¤ºä¾‹**:
```python
# webui/gradio_ui.py
import gradio as gr
from apt_model.training.training_events import training_emitter, WebUIHooks

# åˆ›å»ºé’©å­
hooks = WebUIHooks()
hooks.attach(training_emitter)

def get_training_status():
    """è·å–è®­ç»ƒçŠ¶æ€ï¼ˆGradioä¼šå®šæœŸè°ƒç”¨ï¼‰"""
    state = hooks.get_current_state()
    return (
        f"Epoch: {state['current_epoch']}/{state['total_epochs']}",
        f"Loss: {state['current_loss']:.4f}",
        state['is_training']
    )

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks() as demo:
    gr.Markdown("# APTæ¨¡å‹è®­ç»ƒç›‘æ§")

    with gr.Row():
        epoch_text = gr.Textbox(label="å½“å‰Epoch")
        loss_text = gr.Textbox(label="å½“å‰Loss")
        status_text = gr.Textbox(label="è®­ç»ƒçŠ¶æ€")

    # æ¯ç§’æ›´æ–°ä¸€æ¬¡
    demo.load(
        get_training_status,
        inputs=None,
        outputs=[epoch_text, loss_text, status_text],
        every=1
    )

demo.launch(server_name="0.0.0.0", server_port=7860)
```

---

### æ–¹æ¡ˆ2: Streamlitï¼ˆæœ€ç¾è§‚ï¼‰

**ç‰¹ç‚¹**:
- ç¾è§‚çš„ç•Œé¢
- ä¸°å¯Œçš„å›¾è¡¨ç»„ä»¶
- é€‚åˆæ•°æ®å±•ç¤º

**å®ç°ç¤ºä¾‹**:
```python
# webui/streamlit_ui.py
import streamlit as st
import pandas as pd
from apt_model.training.training_events import training_emitter

st.title("APTæ¨¡å‹è®­ç»ƒç›‘æ§")

# åˆ›å»ºå®æ—¶æ›´æ–°çš„å ä½ç¬¦
epoch_placeholder = st.empty()
loss_chart_placeholder = st.empty()
metrics_placeholder = st.empty()

def update_ui():
    """æ›´æ–°UIæ˜¾ç¤º"""
    # è·å–æœ€è¿‘çš„äº‹ä»¶å†å²
    batch_history = training_emitter.get_history('batch_end', limit=100)

    if batch_history:
        # æå–lossæ•°æ®
        losses = [e['loss'] for e in batch_history]
        batches = [e['batch_idx'] for e in batch_history]

        # æ›´æ–°epochæ˜¾ç¤º
        latest = batch_history[-1]
        epoch_placeholder.metric("å½“å‰Batch", latest['batch_idx'])

        # æ›´æ–°lossæ›²çº¿
        df = pd.DataFrame({'Batch': batches, 'Loss': losses})
        loss_chart_placeholder.line_chart(df.set_index('Batch'))

        # æ›´æ–°æŒ‡æ ‡è¡¨æ ¼
        metrics_placeholder.dataframe({
            'Loss': [latest['loss']],
            'Learning Rate': [latest['lr']],
        })

# å®šæœŸæ›´æ–°ï¼ˆStreamlitä¼šè‡ªåŠ¨é‡æ–°è¿è¡Œï¼‰
import time
while True:
    update_ui()
    time.sleep(1)
```

---

### æ–¹æ¡ˆ3: Flask + WebSocketï¼ˆæœ€çµæ´»ï¼‰

**ç‰¹ç‚¹**:
- å®Œå…¨è‡ªå®šä¹‰
- å®æ—¶åŒå‘é€šä¿¡
- é€‚åˆç”Ÿäº§ç¯å¢ƒ

**å®ç°ç¤ºä¾‹**:
```python
# webui/flask_ui.py
from flask import Flask, render_template
from flask_socketio import SocketIO, emit
from apt_model.training.training_events import training_emitter

app = Flask(__name__)
socketio = SocketIO(app, cors_allowed_origins="*")

# è®¢é˜…è®­ç»ƒäº‹ä»¶å¹¶è½¬å‘åˆ°WebSocketå®¢æˆ·ç«¯
def forward_to_websocket(event_data):
    """å°†è®­ç»ƒäº‹ä»¶è½¬å‘åˆ°WebSocket"""
    socketio.emit('training_update', event_data)

training_emitter.on('batch_end', forward_to_websocket)
training_emitter.on('epoch_end', forward_to_websocket)
training_emitter.on('checkpoint_saved', forward_to_websocket)

@app.route('/')
def index():
    """WebUIä¸»é¡µ"""
    return render_template('training_monitor.html')

@socketio.on('connect')
def handle_connect():
    """å®¢æˆ·ç«¯è¿æ¥"""
    # å‘é€å½“å‰è®­ç»ƒçŠ¶æ€
    history = training_emitter.get_history('batch_end', limit=50)
    emit('history', history)

if __name__ == '__main__':
    socketio.run(app, host='0.0.0.0', port=5000)
```

**å‰ç«¯HTML** (`templates/training_monitor.html`):
```html
<!DOCTYPE html>
<html>
<head>
    <title>APTè®­ç»ƒç›‘æ§</title>
    <script src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
</head>
<body>
    <h1>APTæ¨¡å‹è®­ç»ƒç›‘æ§</h1>
    <div id="status">
        <p>Epoch: <span id="epoch">-</span></p>
        <p>Batch: <span id="batch">-</span></p>
        <p>Loss: <span id="loss">-</span></p>
    </div>
    <div id="loss-chart"></div>

    <script>
        const socket = io();
        let losses = [];
        let batches = [];

        socket.on('training_update', (data) => {
            // æ›´æ–°çŠ¶æ€æ˜¾ç¤º
            if (data.event_name === 'batch_end') {
                document.getElementById('batch').textContent = data.batch_idx;
                document.getElementById('loss').textContent = data.loss.toFixed(4);

                // æ›´æ–°å›¾è¡¨
                losses.push(data.loss);
                batches.push(data.batch_idx);
                updateChart();
            }
        });

        function updateChart() {
            const trace = {
                x: batches,
                y: losses,
                type: 'scatter',
                mode: 'lines',
                name: 'Training Loss'
            };
            Plotly.newPlot('loss-chart', [trace]);
        }
    </script>
</body>
</html>
```

---

## ğŸ”Œ åœ¨è®­ç»ƒå™¨ä¸­é›†æˆäº‹ä»¶å‘å°„

### éœ€è¦åœ¨trainer.pyä¸­æ·»åŠ ï¼š

```python
# åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥
from apt_model.training.training_events import (
    emit_training_start,
    emit_training_end,
    emit_epoch_start,
    emit_epoch_end,
    emit_batch_end,
    emit_checkpoint_saved,
)

# åœ¨train_modelå‡½æ•°ä¸­

def train_model(...):
    # ... åˆå§‹åŒ–ä»£ç  ...

    # å‘å°„è®­ç»ƒå¼€å§‹äº‹ä»¶
    emit_training_start(total_epochs=epochs)

    for epoch in range(epochs):
        # å‘å°„epochå¼€å§‹äº‹ä»¶
        emit_epoch_start(epoch=epoch, total_epochs=epochs)

        for i, batch in enumerate(dataloader):
            # ... è®­ç»ƒbatch ...

            # å‘å°„batchç»“æŸäº‹ä»¶
            emit_batch_end(
                batch_idx=i,
                loss=loss_value,
                lr=scheduler.get_last_lr()[0]
            )

        # å‘å°„epochç»“æŸäº‹ä»¶
        emit_epoch_end(
            epoch=epoch,
            metrics={'avg_loss': avg_loss}
        )

        # Checkpointä¿å­˜æ—¶å‘å°„äº‹ä»¶
        if avg_loss < best_loss:
            checkpoint_path = save_model(...)
            emit_checkpoint_saved(
                checkpoint_path=checkpoint_path,
                epoch=epoch,
                step=global_step
            )

    # å‘å°„è®­ç»ƒç»“æŸäº‹ä»¶
    emit_training_end()
```

**æ”¹åŠ¨é‡**: çº¦10-15è¡Œä»£ç 
**ä¾µå…¥æ€§**: æä½ï¼Œåªéœ€æ·»åŠ äº‹ä»¶å‘å°„è°ƒç”¨
**å‘åå…¼å®¹**: å®Œå…¨å…¼å®¹ï¼Œä¸å½±å“ç°æœ‰åŠŸèƒ½

---

## ğŸš€ WebUIå¯åŠ¨æµç¨‹ï¼ˆå°†æ¥ï¼‰

### æ­¥éª¤1: å¯åŠ¨WebUIæœåŠ¡å™¨ï¼ˆç‹¬ç«‹è¿›ç¨‹ï¼‰

```bash
# å¯åŠ¨Gradio WebUI
python webui/gradio_ui.py

# æˆ–å¯åŠ¨Flask WebUI
python webui/flask_ui.py
```

### æ­¥éª¤2: å¯åŠ¨è®­ç»ƒï¼ˆæ­£å¸¸æµç¨‹ï¼‰

```bash
# è®­ç»ƒä¼šè‡ªåŠ¨å‘å°„äº‹ä»¶
python -m apt_model train --epochs 10
```

### æ­¥éª¤3: åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹

```
æ‰“å¼€ http://localhost:7860  (Gradio)
æˆ–   http://localhost:5000  (Flask)
```

**å…³é”®**: è®­ç»ƒå’ŒWebUIæ˜¯**è§£è€¦çš„**ï¼Œå¯ä»¥åˆ†åˆ«å¯åŠ¨/åœæ­¢

---

## ğŸ“Š WebUIåŠŸèƒ½è®¾æƒ³

### åŸºç¡€åŠŸèƒ½
- [ ] å®æ—¶æ˜¾ç¤ºè®­ç»ƒè¿›åº¦ï¼ˆEpoch/Batchï¼‰
- [ ] å®æ—¶Lossæ›²çº¿å›¾
- [ ] Learning Rateæ›²çº¿å›¾
- [ ] å½“å‰è®­ç»ƒå‚æ•°æ˜¾ç¤º

### é«˜çº§åŠŸèƒ½
- [ ] å¤šä¸ªè®­ç»ƒä»»åŠ¡å¹¶è¡Œç›‘æ§
- [ ] Checkpointåˆ—è¡¨å’Œç®¡ç†
- [ ] æ¨¡å‹æµ‹è¯•/æ¨ç†ç•Œé¢
- [ ] è®­ç»ƒæš‚åœ/æ¢å¤æ§åˆ¶
- [ ] GPU/CPUèµ„æºç›‘æ§
- [ ] è®­ç»ƒæ—¥å¿—å®æ—¶æŸ¥çœ‹

### ä¼ä¸šçº§åŠŸèƒ½
- [ ] å¤šç”¨æˆ·æƒé™ç®¡ç†
- [ ] è®­ç»ƒå†å²è®°å½•
- [ ] æ¨¡å‹ç‰ˆæœ¬å¯¹æ¯”
- [ ] A/Bæµ‹è¯•æ”¯æŒ
- [ ] äº‘ç«¯è®­ç»ƒè°ƒåº¦

---

## ğŸ¨ UIè®¾è®¡è‰å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  APTæ¨¡å‹è®­ç»ƒç›‘æ§                          [æš‚åœ] [åœæ­¢] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  è®­ç»ƒçŠ¶æ€: â—è¿è¡Œä¸­                                      â”‚
â”‚  å½“å‰Epoch: 3/10  |  å½“å‰Batch: 250/500                 â”‚
â”‚  å¹³å‡Loss: 2.5432  |  Learning Rate: 0.00009            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Lossæ›²çº¿                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚        ğŸ“ˆ                                        â”‚   â”‚
â”‚  â”‚    3.0 â—                                         â”‚   â”‚
â”‚  â”‚        â”‚  â—                                      â”‚   â”‚
â”‚  â”‚    2.5 â”‚    â—  â—                                 â”‚   â”‚
â”‚  â”‚        â”‚        â— â—â—â—                            â”‚   â”‚
â”‚  â”‚    2.0 â”‚            â—â—â—â—â—                        â”‚   â”‚
â”‚  â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚   â”‚
â”‚  â”‚        0        500       1000      1500         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æœ€è¿‘Checkpoint:                                        â”‚
â”‚  â€¢ epoch3_step1500.pt (2.5GB) - 2åˆ†é’Ÿå‰                â”‚
â”‚  â€¢ epoch2_step1000.pt (2.5GB) - 15åˆ†é’Ÿå‰               â”‚
â”‚  â€¢ epoch1_step500.pt (2.5GB) - 30åˆ†é’Ÿå‰         [åŠ è½½] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ å®æ–½å»ºè®®

### ç«‹å³å¯åšï¼ˆå·²å®Œæˆï¼‰âœ…
1. åˆ›å»ºtraining_events.pyï¼ˆäº‹ä»¶ç³»ç»Ÿï¼‰
2. åˆ›å»ºWebUIHooksç¤ºä¾‹ç±»
3. ç¼–å†™æ­¤æ–‡æ¡£

### çŸ­æœŸï¼ˆ1-2å‘¨ï¼‰
1. åœ¨trainer.pyä¸­é›†æˆäº‹ä»¶å‘å°„
2. åˆ›å»ºç®€å•çš„Gradio WebUIåŸå‹
3. æµ‹è¯•äº‹ä»¶ç³»ç»Ÿ

### ä¸­æœŸï¼ˆ1-2æœˆï¼‰
1. å®ç°å®Œæ•´çš„Flask WebUI
2. æ·»åŠ å›¾è¡¨å’Œç›‘æ§åŠŸèƒ½
3. æ”¯æŒè®­ç»ƒæ§åˆ¶ï¼ˆæš‚åœ/æ¢å¤ï¼‰

### é•¿æœŸï¼ˆ3-6æœˆï¼‰
1. ä¼ä¸šçº§åŠŸèƒ½
2. å¤šç”¨æˆ·æ”¯æŒ
3. äº‘ç«¯é›†æˆ

---

## ğŸ“ æ€»ç»“

### å·²åŸ‹ä¸‹çš„ä¼ç¬” âœ…

1. **è®­ç»ƒäº‹ä»¶ç³»ç»Ÿ** - å®Œæ•´çš„äº‹ä»¶å‘å°„/è®¢é˜…æœºåˆ¶
2. **WebUIé’©å­ç±»** - å±•ç¤ºå¦‚ä½•è®¢é˜…äº‹ä»¶
3. **ä¾¿æ·å‡½æ•°** - ç®€åŒ–äº‹ä»¶å‘å°„
4. **æ–‡æ¡£è¯´æ˜** - è¯¦ç»†çš„å®ç°æ–¹æ¡ˆ

### ä¼˜åŠ¿

- âœ… **è§£è€¦**: è®­ç»ƒé€»è¾‘å’ŒUIé€»è¾‘å®Œå…¨åˆ†ç¦»
- âœ… **çµæ´»**: æ”¯æŒä»»æ„UIæ¡†æ¶
- âœ… **å³æ’å³ç”¨**: å°†æ¥æ·»åŠ WebUIæ— éœ€ä¿®æ”¹è®­ç»ƒæ ¸å¿ƒä»£ç 
- âœ… **å‘åå…¼å®¹**: ä¸å½±å“ç°æœ‰åŠŸèƒ½
- âœ… **ä½ä¾µå…¥**: åªéœ€åœ¨trainerä¸­æ·»åŠ å‡ è¡Œäº‹ä»¶å‘å°„ä»£ç 

### ä¸‹ä¸€æ­¥

1. åœ¨trainer.pyä¸­æ·»åŠ äº‹ä»¶å‘å°„è°ƒç”¨ï¼ˆ10-15è¡Œä»£ç ï¼‰
2. åˆ›å»ºGradioåŸå‹éªŒè¯å¯è¡Œæ€§
3. é€æ­¥å®Œå–„WebUIåŠŸèƒ½

---

**ç»“è®º**: WebUIçš„"ä¼ç¬”"å·²ç»å®Œç¾åŸ‹ä¸‹ï¼Œéšæ—¶å¯ä»¥æ‰©å±•æˆå®Œæ•´çš„WebUIç³»ç»Ÿï¼Œæ— éœ€é‡æ„è®­ç»ƒä»£ç ã€‚
